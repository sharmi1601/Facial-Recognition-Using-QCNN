{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDzTsnG5-0LA"
      },
      "source": [
        "Building Ensemble Network of QCNN's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7ebj6sTKf4QC",
        "outputId": "290da333-0d47-4daa-bd08-4ab9fd5f95f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-2.0.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit)\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.11/dist-packages (from qiskit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.15.3)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.13.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit) (0.3.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from qiskit) (2.9.0.post0)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qiskit) (4.13.2)\n",
            "Collecting symengine<0.14,>=0.11 (from qiskit)\n",
            "  Downloading symengine-0.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.17.0)\n",
            "Collecting pbr>=2.0.0 (from stevedore>=3.0.0->qiskit)\n",
            "  Downloading pbr-6.1.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pbr>=2.0.0->stevedore>=3.0.0->qiskit) (75.2.0)\n",
            "Downloading qiskit-2.0.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.4.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading symengine-0.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pbr-6.1.1-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: symengine, rustworkx, pbr, stevedore, qiskit\n",
            "Successfully installed pbr-6.1.1 qiskit-2.0.1 rustworkx-0.16.0 stevedore-5.4.1 symengine-0.13.0\n"
          ]
        }
      ],
      "source": [
        "pip install qiskit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83_Q6kArAt3f"
      },
      "outputs": [],
      "source": [
        "def qcnn_circuit_1():\n",
        "    qc = QuantumCircuit(4)\n",
        "\n",
        "    # Encoding layer\n",
        "    for i in range(4):\n",
        "        pixel_param = Parameter(f'pixel_{i}')\n",
        "        qc.ry(pixel_param, i)\n",
        "\n",
        "    # First convolutional layer\n",
        "    for i in range(4):\n",
        "        theta = Parameter(f'theta_conv1_{i}')\n",
        "        qc.ry(theta, i)\n",
        "\n",
        "    # Entanglement\n",
        "    for i in range(4):\n",
        "        qc.cx(i, (i+1) % 4)\n",
        "\n",
        "    # First pooling layer\n",
        "    theta_p1 = Parameter('theta_pool1_0')\n",
        "    qc.crz(theta_p1, 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    theta_p2 = Parameter('theta_pool1_1')\n",
        "    qc.crz(theta_p2, 0, 2)\n",
        "\n",
        "    theta_p3 = Parameter('theta_pool1_2')\n",
        "    qc.crz(theta_p3, 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    theta_p4 = Parameter('theta_pool1_3')\n",
        "    qc.crz(theta_p4, 1, 3)\n",
        "\n",
        "    # Second convolutional layer\n",
        "    theta_c1 = Parameter('theta_conv2_0')\n",
        "    theta_c2 = Parameter('theta_conv2_1')\n",
        "    qc.ry(theta_c1, 2)\n",
        "    qc.ry(theta_c2, 3)\n",
        "\n",
        "    # Entanglement\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 2)\n",
        "\n",
        "    # Second pooling layer\n",
        "    theta_p5 = Parameter('theta_pool2_0')\n",
        "    qc.crz(theta_p5, 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    theta_p6 = Parameter('theta_pool2_1')\n",
        "    qc.crz(theta_p6, 2, 3)\n",
        "\n",
        "    # Final rotation\n",
        "    theta_f = Parameter('theta_final')\n",
        "    qc.ry(theta_f, 3)\n",
        "\n",
        "    return qc\n",
        "\n",
        "\n",
        "def qcnn_circuit_2():\n",
        "\n",
        "  qc = QuantumCircuit(4)\n",
        "\n",
        "  # Input encoding layer\n",
        "  for i in range(4):\n",
        "      pixel_param = Parameter(f'pixel_{i}')\n",
        "      qc.ry(pixel_param, i)\n",
        "\n",
        "  # First convolutional layer\n",
        "  for i in range(4):\n",
        "      theta = Parameter(f'theta_conv1_{i}')\n",
        "      qc.rx(theta, i)\n",
        "\n",
        "  # Entanglement\n",
        "  for i in range(4):\n",
        "      qc.cx(i, (i+1) % 4)\n",
        "\n",
        "  # First pooling layer\n",
        "  theta_p1 = Parameter('theta_pool1_0')\n",
        "  qc.crz(theta_p1, 0, 2)\n",
        "  qc.cx(0, 2)\n",
        "  theta_p2 = Parameter('theta_pool1_1')\n",
        "  qc.crz(theta_p2, 0, 2)\n",
        "\n",
        "  theta_p3 = Parameter('theta_pool1_2')\n",
        "  qc.crz(theta_p3, 1, 3)\n",
        "  qc.cx(1, 3)\n",
        "  theta_p4 = Parameter('theta_pool1_3')\n",
        "  qc.crz(theta_p4, 1, 3)\n",
        "\n",
        "  # Second convolutional layer\n",
        "  theta_c1 = Parameter('theta_conv2_0')\n",
        "  theta_c2 = Parameter('theta_conv2_1')\n",
        "  qc.rx(theta_c1, 2)\n",
        "  qc.rx(theta_c2, 3)\n",
        "\n",
        "  # Entanglement - different pattern\n",
        "  qc.cz(2, 3)  # CZ instead of CX\n",
        "  qc.cz(3, 2)  # CZ instead of CX\n",
        "\n",
        "  # Second pooling layer\n",
        "  theta_p5 = Parameter('theta_pool2_0')\n",
        "  qc.crz(theta_p5, 2, 3)\n",
        "  qc.cx(2, 3)\n",
        "  theta_p6 = Parameter('theta_pool2_1')\n",
        "  qc.crz(theta_p6, 2, 3)\n",
        "\n",
        "  # Final rotation\n",
        "  theta_f = Parameter('theta_final')\n",
        "  qc.rx(theta_f, 3)\n",
        "\n",
        "  return qc\n",
        "\n",
        "\n",
        "\n",
        "def create_qcnn_circuit_3():\n",
        "\n",
        "    qc = QuantumCircuit(4)\n",
        "\n",
        "    # Input encoding layer\n",
        "    for i in range(4):\n",
        "        pixel_param = Parameter(f'pixel_{i}')\n",
        "        qc.ry(pixel_param, i)\n",
        "\n",
        "    # First convolutional layer\n",
        "    for i in range(4):\n",
        "        theta = Parameter(f'theta_conv1_{i}')\n",
        "        qc.rz(theta, i)\n",
        "\n",
        "    # Entanglement - different pattern\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(0, 2)\n",
        "    qc.cx(1, 3)\n",
        "\n",
        "    # First pooling layer\n",
        "    theta_p1 = Parameter('theta_pool1_0')\n",
        "    qc.crz(theta_p1, 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    theta_p2 = Parameter('theta_pool1_1')\n",
        "    qc.crz(theta_p2, 0, 2)\n",
        "\n",
        "    theta_p3 = Parameter('theta_pool1_2')\n",
        "    qc.crz(theta_p3, 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    theta_p4 = Parameter('theta_pool1_3')\n",
        "    qc.crz(theta_p4, 1, 3)\n",
        "\n",
        "    # Second convolutional layer\n",
        "    theta_c1 = Parameter('theta_conv2_0')\n",
        "    theta_c2 = Parameter('theta_conv2_1')\n",
        "    qc.rz(theta_c1, 2)\n",
        "    qc.rz(theta_c2, 3)\n",
        "\n",
        "    # Entanglement\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 2)\n",
        "\n",
        "    # Second pooling layer\n",
        "    theta_p5 = Parameter('theta_pool2_0')\n",
        "    qc.crz(theta_p5, 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    theta_p6 = Parameter('theta_pool2_1')\n",
        "    qc.crz(theta_p6, 2, 3)\n",
        "\n",
        "    # Final rotation\n",
        "    theta_f = Parameter('theta_final')\n",
        "    qc.rz(theta_f, 3)\n",
        "\n",
        "    return qc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfpbFcnYVFuH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNlfDc3wVFkR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XfERmofHTmL4",
        "outputId": "d94dbcbc-d36e-4f53-f749-9bab974c0623"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-2.1.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit)\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.11/dist-packages (from qiskit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.15.3)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit) (0.3.7)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qiskit) (4.14.0)\n",
            "Collecting pbr>=2.0.0 (from stevedore>=3.0.0->qiskit)\n",
            "  Downloading pbr-6.1.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pbr>=2.0.0->stevedore>=3.0.0->qiskit) (75.2.0)\n",
            "Downloading qiskit-2.1.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.4.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pbr-6.1.1-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rustworkx, pbr, stevedore, qiskit\n",
            "Successfully installed pbr-6.1.1 qiskit-2.1.0 rustworkx-0.16.0 stevedore-5.4.1\n"
          ]
        }
      ],
      "source": [
        "pip install qiskit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ROu_UDNJTmIb",
        "outputId": "1fdddfee-737e-4248-fcef-a3b27ad38c56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting qiskit-aer\n",
            "  Downloading qiskit_aer-0.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: qiskit>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (1.15.3)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.0->qiskit-aer) (1.17.0)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (0.16.0)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (0.3.7)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (4.14.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from stevedore>=3.0.0->qiskit>=1.1.0->qiskit-aer) (6.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pbr>=2.0.0->stevedore>=3.0.0->qiskit>=1.1.0->qiskit-aer) (75.2.0)\n",
            "Downloading qiskit_aer-0.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: qiskit-aer\n",
            "Successfully installed qiskit-aer-0.17.1\n"
          ]
        }
      ],
      "source": [
        "pip install qiskit-aer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAdfDE-yghzW"
      },
      "source": [
        "## **Model trained and tested on 9 Subjects after Resizing Input Image to 48x48 and using SVM Classifier. Measuring one qubit**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8LorF0sTmFz",
        "outputId": "72e8b2a7-9ddf-44bf-e367-914b6e31d675"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Qiskit version: 2.0.2\n",
            "Starting 1-Qubit QCNN Ensemble for 5-Class Classification\n",
            "Shape of X_train: (72, 576, 4)\n",
            "Shape of y_train: (72,)\n",
            "Training QCNN 1...\n",
            "Training QCNN 2...\n",
            "Training QCNN 3...\n",
            "Extracting features...\n",
            "Training classifiers...\n",
            "SVM Classifier trained for 9 classes\n",
            "SVM Classifier trained for 9 classes\n",
            "SVM Classifier trained for 9 classes\n",
            "Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\n",
            "Performing ensemble prediction...\n",
            "Evaluating results...\n",
            "Accuracy: 85.18518518518519\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      1.00      0.86         3\n",
            "           1       1.00      1.00      1.00         3\n",
            "           2       1.00      0.67      0.80         3\n",
            "           3       1.00      0.67      0.80         3\n",
            "           4       1.00      1.00      1.00         3\n",
            "           5       0.67      0.67      0.67         3\n",
            "           6       1.00      0.67      0.80         3\n",
            "           7       0.75      1.00      0.86         3\n",
            "           8       0.75      1.00      0.86         3\n",
            "\n",
            "    accuracy                           0.85        27\n",
            "   macro avg       0.88      0.85      0.85        27\n",
            "weighted avg       0.88      0.85      0.85        27\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import mode\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit_aer import Aer\n",
        "from qiskit.circuit import Parameter\n",
        "import pickle\n",
        "\n",
        "\n",
        "def prepare_dataset(dataset_path='/content/dataset'):\n",
        "    train_dir = os.path.join(dataset_path, 'train')\n",
        "    test_dir = os.path.join(dataset_path, 'test')\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    subjects = [f'subject0{i}' for i in range(1, 10)]\n",
        "    test_ratio = 0.2\n",
        "\n",
        "    for subject in subjects:\n",
        "        all_items = [f for f in os.listdir(dataset_path)]\n",
        "        subject_files = [item for item in all_items if item.startswith(subject)]\n",
        "        train_files, test_files = train_test_split(subject_files, test_size=test_ratio, random_state=42)\n",
        "\n",
        "        for file in train_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(train_dir, file))\n",
        "        for file in test_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(test_dir, file))\n",
        "\n",
        "    X_train, y_train = process_folder(train_dir)\n",
        "    X_test, y_test = process_folder(test_dir)\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "def process_folder(folder_path):\n",
        "    processed_images = []\n",
        "    labels = []\n",
        "    image_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path)]\n",
        "\n",
        "    subject_ids = set(os.path.basename(file).split('.')[0] for file in image_files)\n",
        "    subject_to_label = {subject: i for i, subject in enumerate(sorted(subject_ids))}\n",
        "\n",
        "    for file in image_files:\n",
        "        file_name = os.path.basename(file)\n",
        "        subject_id = file_name.split('.')[0]\n",
        "        label = subject_to_label[subject_id]\n",
        "\n",
        "        img = Image.open(file).convert('L').resize((48, 48))\n",
        "        img_array = np.array(img).astype(np.float32) / 255.0 * 2 * np.pi\n",
        "\n",
        "        patches = [img_array[i:i+2, j:j+2].flatten() for i in range(0, 48, 2) for j in range(0, 48, 2) if i+2 <= 48 and j+2 <= 48]\n",
        "        processed_images.append(patches)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(processed_images), np.array(labels)\n",
        "\n",
        "def create_qcnn_circuit_1():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'theta_conv1_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.cx(i, (i+1) % 4)\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.ry(Parameter('theta_conv2_0'), 2)\n",
        "    qc.ry(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.ry(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "def create_qcnn_circuit_2():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.rx(Parameter(f'theta_conv1_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.cx(i, (i+1) % 4)\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.rx(Parameter('theta_conv2_0'), 2)\n",
        "    qc.rx(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cz(2, 3)\n",
        "    qc.cz(3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.rx(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "def create_qcnn_circuit_3():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.rz(Parameter(f'theta_conv1_{i}'), i)\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(0, 2)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.rz(Parameter('theta_conv2_0'), 2)\n",
        "    qc.rz(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.rz(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "\n",
        "def execute_circuit(circuit, parameters, backend):\n",
        "    # parameters is a dictionary of {Parameter: value}\n",
        "    bound = circuit.assign_parameters(parameters)\n",
        "    meas = QuantumCircuit(4, 1)\n",
        "    meas.compose(bound, inplace=True)\n",
        "    meas.measure(3, 0)\n",
        "    job = backend.run(meas, shots=1024)\n",
        "    result = job.result()\n",
        "    return result.get_counts()\n",
        "\n",
        "# Change this part in the extract_features_from_image function:\n",
        "def extract_features_from_image(image_patches, circuit, params, backend):\n",
        "    input_params = list(circuit.parameters)[:4]\n",
        "    weight_params = list(circuit.parameters)[4:]\n",
        "    features = []\n",
        "    for patch in image_patches:\n",
        "        # Create a dictionary binding each pixel value to its corresponding input parameter\n",
        "        bindings = {input_params[i]: float(patch[i]) for i in range(4)}\n",
        "        # Add the weight parameters to the bindings dictionary\n",
        "        for i, param in enumerate(weight_params):\n",
        "            bindings[param] = float(params[i])\n",
        "\n",
        "        bound = circuit.assign_parameters(bindings)\n",
        "        meas_circuit = QuantumCircuit(4, 1)\n",
        "        meas_circuit.compose(bound, inplace=True)\n",
        "        meas_circuit.measure(3, 0)\n",
        "        job = backend.run(meas_circuit, shots=1024)\n",
        "        result = job.result()\n",
        "        counts = result.get_counts()\n",
        "        zero = counts.get('0', 0)\n",
        "        one = counts.get('1', 0)\n",
        "        expectation = (zero - one) / 1024\n",
        "        features.append(expectation)\n",
        "    return features\n",
        "\n",
        "\n",
        "def extract_all_features(X, circuit, params, backend):\n",
        "    # X contains a list of images, where each image is a list of patches.\n",
        "    all_features = []\n",
        "    for image_patches in X:\n",
        "         # extract_features_from_image already handles all patches for a single image\n",
        "        image_features = extract_features_from_image(image_patches, circuit, params, backend)\n",
        "        all_features.append(image_features)\n",
        "    return all_features\n",
        "\n",
        "\n",
        "def train_classifier(X_features, y_labels):\n",
        "    X_features_reshaped = np.array(X_features) # This should create a (num_images, num_patches) array\n",
        "\n",
        "    # Changed from LogisticRegression to SVC (Support Vector Classifier)\n",
        "    # Using RBF kernel which often works well for image classification\n",
        "    clf = SVC(kernel='rbf', probability=True, C=1.0, gamma='scale')\n",
        "    clf.fit(X_features_reshaped, y_labels)\n",
        "\n",
        "    # Verify the classifier is trained for the correct number of classes\n",
        "    n_classes = len(np.unique(y_labels))\n",
        "    print(f\"SVM Classifier trained for {n_classes} classes\")\n",
        "\n",
        "    return clf\n",
        "\n",
        "def cost_function(params, circuit, input_params, weight_params, x_batch, y_batch, backend):\n",
        "    cost = 0\n",
        "    # We need to iterate through each image in the batch.\n",
        "    for i in range(len(x_batch)):\n",
        "        # We need to process each patch for this image to calculate the cost.\n",
        "        image_patches = x_batch[i]\n",
        "        # Calculate cost for this image by averaging the cost over its patches.\n",
        "        image_cost = 0\n",
        "        for patch in image_patches:\n",
        "            # Create a dictionary binding each pixel value to its corresponding input parameter\n",
        "            param_dict = {input_params[j]: float(patch[j]) for j in range(4)}\n",
        "            # Add the weight parameters to the bindings dictionary\n",
        "            for j, param in enumerate(weight_params):\n",
        "                param_dict[param] = float(params[j])\n",
        "\n",
        "            counts = execute_circuit(circuit, param_dict, backend)\n",
        "            prob_one = counts.get('1', 0) / 1024\n",
        "            image_cost += (1 - prob_one)\n",
        "\n",
        "        # Average cost over all patches in the image\n",
        "        cost += image_cost / len(image_patches)\n",
        "\n",
        "    # Average cost over all images in the batch\n",
        "    return cost / len(x_batch)\n",
        "\n",
        "\n",
        "def train_qcnn(circuit, X_train, y_train, backend, maxiter=50):\n",
        "    all_params = list(circuit.parameters)\n",
        "    # Ensure there are at least 4 input parameters and some weight parameters\n",
        "    if len(all_params) < 5:\n",
        "         raise ValueError(\"Circuit must have at least 4 input parameters and 1 weight parameter.\")\n",
        "    input_params = all_params[:4]\n",
        "    weight_params = all_params[4:]\n",
        "    initial_params = np.random.rand(len(weight_params)) * 2 * np.pi - np.pi\n",
        "    # Pass necessary parameters to the cost function\n",
        "    objective = lambda p: cost_function(p, circuit, input_params, weight_params, X_train, y_train, backend)\n",
        "    result = minimize(objective, initial_params, method='COBYLA', options={'maxiter': maxiter})\n",
        "    return result.x\n",
        "\n",
        "def ensemble_predict(X_test, circuits, param_list, classifiers, backend):\n",
        "    all_preds = []\n",
        "    for circuit, params, clf in zip(circuits, param_list, classifiers):\n",
        "        # extract_all_features returns a list of feature lists (one per image)\n",
        "        features = extract_all_features(X_test, circuit, params, backend)\n",
        "        # Convert features to a NumPy array for the classifier\n",
        "        features_array = np.array(features)\n",
        "        preds = clf.predict(features_array)\n",
        "        all_preds.append(preds)\n",
        "\n",
        "    final_preds = []\n",
        "    for i in range(len(X_test)):\n",
        "        votes = [model_preds[i] for model_preds in all_preds]\n",
        "\n",
        "        # Simple fix: convert to a list and use the most common value\n",
        "        votes_list = list(votes)\n",
        "        # Count occurrences of each value\n",
        "        from collections import Counter\n",
        "        most_common = Counter(votes_list).most_common(1)[0][0]\n",
        "        final_preds.append(most_common)\n",
        "\n",
        "    return final_preds\n",
        "\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred) * 100)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "def main():\n",
        "    print(\"Starting 1-Qubit QCNN Ensemble for 5-Class Classification\")\n",
        "    X_train, y_train, X_test, y_test = prepare_dataset()\n",
        "\n",
        "    # Check the shapes of X_train and y_train\n",
        "    print(f\"Shape of X_train: {X_train.shape}\")\n",
        "    print(f\"Shape of y_train: {y_train.shape}\")\n",
        "\n",
        "    backend = Aer.get_backend('qasm_simulator')\n",
        "\n",
        "    circuit1 = create_qcnn_circuit_1()\n",
        "    circuit2 = create_qcnn_circuit_2()\n",
        "    circuit3 = create_qcnn_circuit_3()\n",
        "\n",
        "\n",
        "    print(\"Training QCNN 1...\")\n",
        "    params1 = train_qcnn(circuit1, X_train, y_train, backend)\n",
        "    print(\"Training QCNN 2...\")\n",
        "    params2 = train_qcnn(circuit2, X_train, y_train, backend)\n",
        "    print(\"Training QCNN 3...\")\n",
        "    params3 = train_qcnn(circuit3, X_train, y_train, backend)\n",
        "\n",
        "    print(\"Extracting features...\")\n",
        "    feat1 = extract_all_features(X_train, circuit1, params1, backend)\n",
        "    feat2 = extract_all_features(X_train, circuit2, params2, backend)\n",
        "    feat3 = extract_all_features(X_train, circuit3, params3, backend)\n",
        "\n",
        "    print(\"Training classifiers...\")\n",
        "    clf1 = train_classifier(feat1, y_train)\n",
        "    clf2 = train_classifier(feat2, y_train)\n",
        "    clf3 = train_classifier(feat3, y_train)\n",
        "\n",
        "    try:\n",
        "        with open('qcnn_ensemble_models.pkl', 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'params1': params1,\n",
        "                'params2': params2,\n",
        "                'params3': params3,\n",
        "                'clf1': clf1,\n",
        "                'clf2': clf2,\n",
        "                'clf3': clf3\n",
        "            }, f)\n",
        "        print(\"Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving models: {e}\")\n",
        "\n",
        "    print(\"Performing ensemble prediction...\")\n",
        "    final_preds = ensemble_predict(X_test, [circuit1, circuit2, circuit3], [params1, params2, params3], [clf1, clf2, clf3], backend)\n",
        "\n",
        "    print(\"Evaluating results...\")\n",
        "    evaluate(y_test, final_preds)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import qiskit\n",
        "    print(f\"Qiskit version: {qiskit.__version__}\")\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3twC1IXJCfXh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyS5QHw81AAr"
      },
      "source": [
        "# **Measuring 2 Qubits for 15 Subjects got an accuracy of 80% for 64x64 input**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YETLjvtSoUTC",
        "outputId": "cf4376c0-3283-4daf-a84b-8bb5e95ca5b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Qiskit version: 2.1.0\n",
            "Starting 1-Qubit QCNN Ensemble for 5-Class Classification\n",
            "Shape of X_train: (135, 1024, 4)\n",
            "Shape of y_train: (135,)\n",
            "Training QCNN 1...\n",
            "Training QCNN 2...\n",
            "Training QCNN 3...\n",
            "Extracting features...\n",
            "Training classifiers...\n",
            "SVM Classifier trained for 15 classes\n",
            "SVM Classifier trained for 15 classes\n",
            "SVM Classifier trained for 15 classes\n",
            "Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\n",
            "Performing ensemble prediction...\n",
            "Evaluating results...\n",
            "Accuracy: 80.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      1.00      0.80         2\n",
            "           1       1.00      0.50      0.67         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      0.50      0.67         2\n",
            "           4       1.00      1.00      1.00         2\n",
            "           5       0.25      0.50      0.33         2\n",
            "           6       0.67      1.00      0.80         2\n",
            "           7       1.00      0.50      0.67         2\n",
            "           8       1.00      0.50      0.67         2\n",
            "           9       1.00      1.00      1.00         2\n",
            "          10       1.00      1.00      1.00         2\n",
            "          11       0.67      1.00      0.80         2\n",
            "          12       1.00      1.00      1.00         2\n",
            "          13       1.00      1.00      1.00         2\n",
            "          14       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.80        30\n",
            "   macro avg       0.88      0.80      0.80        30\n",
            "weighted avg       0.88      0.80      0.80        30\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import mode\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit_aer import Aer\n",
        "from qiskit.circuit import Parameter\n",
        "import pickle\n",
        "\n",
        "\n",
        "def prepare_dataset(dataset_path='/content/dataset'):\n",
        "    train_dir = os.path.join(dataset_path, 'train')\n",
        "    test_dir = os.path.join(dataset_path, 'test')\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    subjects = [f'subject{i:02d}' for i in range(1, 16)]\n",
        "    # Changed test_size to 2 to ensure 2 images per subject for testing\n",
        "    test_size_per_subject = 2\n",
        "\n",
        "    for subject in subjects:\n",
        "        all_items = [f for f in os.listdir(dataset_path)]\n",
        "        subject_files = [item for item in all_items if item.startswith(subject)]\n",
        "        # Ensure there are enough files for the split\n",
        "        if len(subject_files) < test_size_per_subject:\n",
        "            print(f\"Warning: Not enough files for subject {subject} to create test set. Skipping.\")\n",
        "            continue\n",
        "        train_files, test_files = train_test_split(subject_files, test_size=test_size_per_subject, random_state=42)\n",
        "\n",
        "        for file in train_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(train_dir, file))\n",
        "        for file in test_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(test_dir, file))\n",
        "\n",
        "    X_train, y_train = process_folder(train_dir)\n",
        "    X_test, y_test = process_folder(test_dir)\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "def process_folder(folder_path):\n",
        "    processed_images = []\n",
        "    labels = []\n",
        "    image_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path)]\n",
        "\n",
        "    subject_ids = set(os.path.basename(file).split('.')[0] for file in image_files)\n",
        "    subject_to_label = {subject: i for i, subject in enumerate(sorted(subject_ids))}\n",
        "\n",
        "    for file in image_files:\n",
        "        file_name = os.path.basename(file)\n",
        "        subject_id = file_name.split('.')[0]\n",
        "        label = subject_to_label[subject_id]\n",
        "\n",
        "        img = Image.open(file).convert('L').resize((64, 64))\n",
        "        img_array = np.array(img).astype(np.float32) / 255.0 * 2 * np.pi\n",
        "\n",
        "        patches = [img_array[i:i+2, j:j+2].flatten() for i in range(0, 64, 2) for j in range(0, 64, 2) if i+2 <= 64 and j+2 <= 64]\n",
        "        processed_images.append(patches)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(processed_images), np.array(labels)\n",
        "\n",
        "def create_qcnn_circuit_1():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'theta_conv1_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.cx(i, (i+1) % 4)\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.ry(Parameter('theta_conv2_0'), 2)\n",
        "    qc.ry(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.ry(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "def create_qcnn_circuit_2():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.rx(Parameter(f'theta_conv1_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.cx(i, (i+1) % 4)\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.rx(Parameter('theta_conv2_0'), 2)\n",
        "    qc.rx(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cz(2, 3)\n",
        "    qc.cz(3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.rx(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "def create_qcnn_circuit_3():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.rz(Parameter(f'theta_conv1_{i}'), i)\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(0, 2)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.rz(Parameter('theta_conv2_0'), 2)\n",
        "    qc.rz(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.rz(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "\n",
        "def execute_circuit(circuit, parameters, backend):\n",
        "    # parameters is a dictionary of {Parameter: value}\n",
        "    bound = circuit.assign_parameters(parameters)\n",
        "    meas = QuantumCircuit(4, 2)\n",
        "    meas.compose(bound, inplace=True)\n",
        "    meas.measure([3, 2], [0, 1])\n",
        "    job = backend.run(meas, shots=1024)\n",
        "    result = job.result()\n",
        "    return result.get_counts()\n",
        "\n",
        "# Change this part in the extract_features_from_image function:\n",
        "def extract_features_from_image(image_patches, circuit, params, backend):\n",
        "    input_params = list(circuit.parameters)[:4]\n",
        "    weight_params = list(circuit.parameters)[4:]\n",
        "    features = []\n",
        "    for patch in image_patches:\n",
        "        # Create a dictionary binding each pixel value to its corresponding input parameter\n",
        "        bindings = {input_params[i]: float(patch[i]) for i in range(4)}\n",
        "        # Add the weight parameters to the bindings dictionary\n",
        "        for i, param in enumerate(weight_params):\n",
        "            bindings[param] = float(params[i])\n",
        "\n",
        "        bound = circuit.assign_parameters(bindings)\n",
        "        meas_circuit = QuantumCircuit(4, 2)\n",
        "        meas_circuit.compose(bound, inplace=True)\n",
        "        meas_circuit.measure([3, 2], [0, 1])\n",
        "        job = backend.run(meas_circuit, shots=1024)\n",
        "        result = job.result()\n",
        "        counts = result.get_counts()\n",
        "        c00 = counts.get('00', 0)\n",
        "        c01 = counts.get('01', 0)\n",
        "        c10 = counts.get('10', 0)\n",
        "        c11 = counts.get('11', 0)\n",
        "        expectation = (c00 + c11 - c01 - c10) / 1024\n",
        "        features.append(expectation)\n",
        "    return features\n",
        "\n",
        "\n",
        "def extract_all_features(X, circuit, params, backend):\n",
        "    # X contains a list of images, where each image is a list of patches.\n",
        "    all_features = []\n",
        "    for image_patches in X:\n",
        "         # extract_features_from_image already handles all patches for a single image\n",
        "        image_features = extract_features_from_image(image_patches, circuit, params, backend)\n",
        "        all_features.append(image_features)\n",
        "    return all_features\n",
        "\n",
        "\n",
        "def train_classifier(X_features, y_labels):\n",
        "    X_features_reshaped = np.array(X_features) # This should create a (num_images, num_patches) array\n",
        "\n",
        "    # Changed from LogisticRegression to SVC (Support Vector Classifier)\n",
        "    # Using RBF kernel which often works well for image classification\n",
        "    clf = SVC(kernel='rbf', probability=True, C=1.0, gamma='scale')\n",
        "    clf.fit(X_features_reshaped, y_labels)\n",
        "\n",
        "    # Verify the classifier is trained for the correct number of classes\n",
        "    n_classes = len(np.unique(y_labels))\n",
        "    print(f\"SVM Classifier trained for {n_classes} classes\")\n",
        "\n",
        "    return clf\n",
        "\n",
        "def cost_function(params, circuit, input_params, weight_params, x_batch, y_batch, backend):\n",
        "    cost = 0\n",
        "    # We need to iterate through each image in the batch.\n",
        "    for i in range(len(x_batch)):\n",
        "        # We need to process each patch for this image to calculate the cost.\n",
        "        image_patches = x_batch[i]\n",
        "        # Calculate cost for this image by averaging the cost over its patches.\n",
        "        image_cost = 0\n",
        "        for patch in image_patches:\n",
        "            # Create a dictionary binding each pixel value to its corresponding input parameter\n",
        "            param_dict = {input_params[j]: float(patch[j]) for j in range(4)}\n",
        "            # Add the weight parameters to the bindings dictionary\n",
        "            for j, param in enumerate(weight_params):\n",
        "                param_dict[param] = float(params[j])\n",
        "\n",
        "            counts = execute_circuit(circuit, param_dict, backend)\n",
        "            # Calculate expectation value for Z_3 Z_2\n",
        "            c00 = counts.get(\"00\", 0)\n",
        "            c01 = counts.get(\"01\", 0)\n",
        "            c10 = counts.get(\"10\", 0)\n",
        "            c11 = counts.get(\"11\", 0)\n",
        "            expectation = (c00 + c11 - c01 - c10) / 1024\n",
        "            image_cost += (1 - expectation)\n",
        "\n",
        "        # Average cost over all patches in the image\n",
        "        cost += image_cost / len(image_patches)\n",
        "\n",
        "    # Average cost over all images in the batch\n",
        "    return cost / len(x_batch)\n",
        "\n",
        "\n",
        "def train_qcnn(circuit, X_train, y_train, backend, maxiter=50):\n",
        "    all_params = list(circuit.parameters)\n",
        "    # Ensure there are at least 4 input parameters and some weight parameters\n",
        "    if len(all_params) < 5:\n",
        "         raise ValueError(\"Circuit must have at least 4 input parameters and 1 weight parameter.\")\n",
        "    input_params = all_params[:4]\n",
        "    weight_params = all_params[4:]\n",
        "    initial_params = np.random.rand(len(weight_params)) * 2 * np.pi - np.pi\n",
        "    # Pass necessary parameters to the cost function\n",
        "    objective = lambda p: cost_function(p, circuit, input_params, weight_params, X_train, y_train, backend)\n",
        "    result = minimize(objective, initial_params, method='COBYLA', options={'maxiter': maxiter})\n",
        "    return result.x\n",
        "\n",
        "def ensemble_predict(X_test, circuits, param_list, classifiers, backend):\n",
        "    all_preds = []\n",
        "    for circuit, params, clf in zip(circuits, param_list, classifiers):\n",
        "        # extract_all_features returns a list of feature lists (one per image)\n",
        "        features = extract_all_features(X_test, circuit, params, backend)\n",
        "        # Convert features to a NumPy array for the classifier\n",
        "        features_array = np.array(features)\n",
        "        preds = clf.predict(features_array)\n",
        "        all_preds.append(preds)\n",
        "\n",
        "    final_preds = []\n",
        "    for i in range(len(X_test)):\n",
        "        votes = [model_preds[i] for model_preds in all_preds]\n",
        "\n",
        "        # Simple fix: convert to a list and use the most common value\n",
        "        votes_list = list(votes)\n",
        "        # Count occurrences of each value\n",
        "        from collections import Counter\n",
        "        most_common = Counter(votes_list).most_common(1)[0][0]\n",
        "        final_preds.append(most_common)\n",
        "\n",
        "    return final_preds\n",
        "\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred) * 100)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "def main():\n",
        "    print(\"Starting 1-Qubit QCNN Ensemble for 5-Class Classification\")\n",
        "    X_train, y_train, X_test, y_test = prepare_dataset()\n",
        "\n",
        "    # Check the shapes of X_train and y_train\n",
        "    print(f\"Shape of X_train: {X_train.shape}\")\n",
        "    print(f\"Shape of y_train: {y_train.shape}\")\n",
        "\n",
        "    backend = Aer.get_backend('qasm_simulator')\n",
        "\n",
        "    circuit1 = create_qcnn_circuit_1()\n",
        "    circuit2 = create_qcnn_circuit_2()\n",
        "    circuit3 = create_qcnn_circuit_3()\n",
        "\n",
        "\n",
        "    print(\"Training QCNN 1...\")\n",
        "    params1 = train_qcnn(circuit1, X_train, y_train, backend)\n",
        "    print(\"Training QCNN 2...\")\n",
        "    params2 = train_qcnn(circuit2, X_train, y_train, backend)\n",
        "    print(\"Training QCNN 3...\")\n",
        "    params3 = train_qcnn(circuit3, X_train, y_train, backend)\n",
        "\n",
        "    print(\"Extracting features...\")\n",
        "    feat1 = extract_all_features(X_train, circuit1, params1, backend)\n",
        "    feat2 = extract_all_features(X_train, circuit2, params2, backend)\n",
        "    feat3 = extract_all_features(X_train, circuit3, params3, backend)\n",
        "\n",
        "    print(\"Training classifiers...\")\n",
        "    clf1 = train_classifier(feat1, y_train)\n",
        "    clf2 = train_classifier(feat2, y_train)\n",
        "    clf3 = train_classifier(feat3, y_train)\n",
        "\n",
        "    try:\n",
        "        with open('qcnn_ensemble_models.pkl', 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'params1': params1,\n",
        "                'params2': params2,\n",
        "                'params3': params3,\n",
        "                'clf1': clf1,\n",
        "                'clf2': clf2,\n",
        "                'clf3': clf3\n",
        "            }, f)\n",
        "        print(\"Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving models: {e}\")\n",
        "\n",
        "    print(\"Performing ensemble prediction...\")\n",
        "    final_preds = ensemble_predict(X_test, [circuit1, circuit2, circuit3], [params1, params2, params3], [clf1, clf2, clf3], backend)\n",
        "\n",
        "    print(\"Evaluating results...\")\n",
        "    evaluate(y_test, final_preds)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import qiskit\n",
        "    print(f\"Qiskit version: {qiskit.__version__}\")\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_01aAkP2Byl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y6YPSGhHzYp"
      },
      "source": [
        "# **Achieved 80% for 48x48 inputs with 3 qubit measurement with 15 classes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic8BFBOV2lmq",
        "outputId": "553b48f2-72fa-4d90-f3d3-5e5ac9c53536"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Qiskit version: 2.1.0\n",
            "Starting 3-Qubit QCNN Ensemble for 15-Class Classification\n",
            "Shape of X_train: (120, 576, 4)\n",
            "Shape of y_train: (120,)\n",
            "Training QCNN 1...\n",
            "Training QCNN 2...\n",
            "Training QCNN 3...\n",
            "Extracting features...\n",
            "Training classifiers...\n",
            "SVM Classifier trained for 15 classes\n",
            "SVM Classifier trained for 15 classes\n",
            "SVM Classifier trained for 15 classes\n",
            "Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\n",
            "Performing ensemble prediction...\n",
            "Evaluating results...\n",
            "Accuracy: 80.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      1.00      0.75         3\n",
            "           1       1.00      1.00      1.00         3\n",
            "           2       1.00      0.33      0.50         3\n",
            "           3       1.00      1.00      1.00         3\n",
            "           4       1.00      1.00      1.00         3\n",
            "           5       0.50      1.00      0.67         3\n",
            "           6       1.00      0.67      0.80         3\n",
            "           7       0.50      0.33      0.40         3\n",
            "           8       1.00      0.33      0.50         3\n",
            "           9       1.00      1.00      1.00         3\n",
            "          10       1.00      1.00      1.00         3\n",
            "          11       0.75      1.00      0.86         3\n",
            "          12       1.00      1.00      1.00         3\n",
            "          13       1.00      1.00      1.00         3\n",
            "          14       0.33      0.33      0.33         3\n",
            "\n",
            "    accuracy                           0.80        45\n",
            "   macro avg       0.85      0.80      0.79        45\n",
            "weighted avg       0.85      0.80      0.79        45\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import mode\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit_aer import Aer\n",
        "from qiskit.circuit import Parameter\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "def prepare_dataset(dataset_path='/content/dataset'):\n",
        "    train_dir = os.path.join(dataset_path, 'train')\n",
        "    test_dir = os.path.join(dataset_path, 'test')\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    subjects = [f'subject{i:02d}' for i in range(1, 16)]\n",
        "    # Changed test_size to 2 to ensure 2 images per subject for testing\n",
        "    test_size_per_subject = 3\n",
        "\n",
        "    for subject in subjects:\n",
        "        all_items = [f for f in os.listdir(dataset_path)]\n",
        "        subject_files = [item for item in all_items if item.startswith(subject)]\n",
        "        # Ensure there are enough files for the split\n",
        "        if len(subject_files) < test_size_per_subject:\n",
        "            print(f\"Warning: Not enough files for subject {subject} to create test set. Skipping.\")\n",
        "            continue\n",
        "        train_files, test_files = train_test_split(subject_files, test_size=test_size_per_subject, random_state=42)\n",
        "\n",
        "        for file in train_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(train_dir, file))\n",
        "        for file in test_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(test_dir, file))\n",
        "\n",
        "    X_train, y_train = process_folder(train_dir)\n",
        "    X_test, y_test = process_folder(test_dir)\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "def process_folder(folder_path):\n",
        "    processed_images = []\n",
        "    labels = []\n",
        "    image_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path)]\n",
        "\n",
        "    subject_ids = set(os.path.basename(file).split('.')[0] for file in image_files)\n",
        "    subject_to_label = {subject: i for i, subject in enumerate(sorted(subject_ids))}\n",
        "\n",
        "    for file in image_files:\n",
        "        file_name = os.path.basename(file)\n",
        "        subject_id = file_name.split('.')[0]\n",
        "        label = subject_to_label[subject_id]\n",
        "\n",
        "        img = Image.open(file).convert('L').resize((48, 48))\n",
        "        img_array = np.array(img).astype(np.float32) / 255.0 * 2 * np.pi\n",
        "\n",
        "        patches = [img_array[i:i+2, j:j+2].flatten() for i in range(0, 48, 2) for j in range(0, 48, 2) if i+2 <= 48 and j+2 <= 48]\n",
        "        processed_images.append(patches)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(processed_images), np.array(labels)\n",
        "\n",
        "def create_qcnn_circuit_1():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'theta_conv1_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.cx(i, (i+1) % 4)\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.ry(Parameter('theta_conv2_0'), 2)\n",
        "    qc.ry(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.ry(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "def create_qcnn_circuit_2():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.rx(Parameter(f'theta_conv1_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.cx(i, (i+1) % 4)\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.rx(Parameter('theta_conv2_0'), 2)\n",
        "    qc.rx(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cz(2, 3)\n",
        "    qc.cz(3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.rx(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "def create_qcnn_circuit_3():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.rx(Parameter(f'theta_conv1_{i}'), i)\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(1, 2)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 0) # Circular entanglement\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.rx(Parameter('theta_conv2_0'), 2)\n",
        "    qc.rx(Parameter('theta_conv2_1'), 3)\n",
        "    qc.crx(Parameter('theta_crx_0'), 2, 3)\n",
        "    qc.crx(Parameter('theta_crx_1'), 3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.rx(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "\n",
        "def execute_circuit(circuit, parameters, backend):\n",
        "    # parameters is a dictionary of {Parameter: value}\n",
        "    bound = circuit.assign_parameters(parameters)\n",
        "    meas = QuantumCircuit(4, 3)\n",
        "    meas.compose(bound, inplace=True)\n",
        "    meas.measure([3, 2, 1], [0, 1, 2])\n",
        "    job = backend.run(meas, shots=1024)\n",
        "    result = job.result()\n",
        "    return result.get_counts()\n",
        "\n",
        "def extract_features_from_image(image_patches, circuit, params, backend):\n",
        "    input_params = list(circuit.parameters)[:4]\n",
        "    weight_params = list(circuit.parameters)[4:]\n",
        "    features = []\n",
        "    for patch in image_patches:\n",
        "        bindings = {input_params[i]: float(patch[i]) for i in range(4)}\n",
        "        for i, param in enumerate(weight_params):\n",
        "            bindings[param] = float(params[i])\n",
        "\n",
        "        bound = circuit.assign_parameters(bindings)\n",
        "        meas_circuit = QuantumCircuit(4, 3)\n",
        "        meas_circuit.compose(bound, inplace=True)\n",
        "        meas_circuit.measure([3, 2, 1], [0, 1, 2])\n",
        "        job = backend.run(meas_circuit, shots=1024)\n",
        "        result = job.result()\n",
        "        counts = result.get_counts()\n",
        "\n",
        "        # Compute expectation value for Z⊗Z⊗Z on qubits 3,2,1\n",
        "        expectation = 0\n",
        "        for bitstring, count in counts.items():\n",
        "            bit_values = [1 if b == '0' else -1 for b in bitstring]\n",
        "            zz_product = bit_values[0] * bit_values[1] * bit_values[2]\n",
        "            expectation += zz_product * count / 1024\n",
        "\n",
        "        features.append(expectation)\n",
        "    return features\n",
        "\n",
        "\n",
        "def extract_all_features(X, circuit, params, backend):\n",
        "    # X contains a list of images, where each image is a list of patches.\n",
        "    all_features = []\n",
        "    for image_patches in X:\n",
        "         # extract_features_from_image already handles all patches for a single image\n",
        "        image_features = extract_features_from_image(image_patches, circuit, params, backend)\n",
        "        all_features.append(image_features)\n",
        "    return all_features\n",
        "\n",
        "\n",
        "def train_classifier(X_features, y_labels):\n",
        "    X_features_reshaped = np.array(X_features) # This should create a (num_images, num_patches) array\n",
        "\n",
        "    # Changed from LogisticRegression to SVC (Support Vector Classifier)\n",
        "    # Using RBF kernel which often works well for image classification\n",
        "    clf = SVC(kernel='rbf', probability=True, C=1.0, gamma='scale')\n",
        "    clf.fit(X_features_reshaped, y_labels)\n",
        "\n",
        "    # Verify the classifier is trained for the correct number of classes\n",
        "    n_classes = len(np.unique(y_labels))\n",
        "    print(f\"SVM Classifier trained for {n_classes} classes\")\n",
        "\n",
        "    return clf\n",
        "\n",
        "def cost_function(params, circuit, input_params, weight_params, x_batch, y_batch, backend):\n",
        "    cost = 0\n",
        "    # We need to iterate through each image in the batch.\n",
        "    for i in range(len(x_batch)):\n",
        "        # We need to process each patch for this image to calculate the cost.\n",
        "        image_patches = x_batch[i]\n",
        "        # Calculate cost for this image by averaging the cost over its patches.\n",
        "        image_cost = 0\n",
        "        for patch in image_patches:\n",
        "            # Create a dictionary binding each pixel value to its corresponding input parameter\n",
        "            param_dict = {input_params[j]: float(patch[j]) for j in range(4)}\n",
        "            # Add the weight parameters to the bindings dictionary\n",
        "            for j, param in enumerate(weight_params):\n",
        "                param_dict[param] = float(params[j])\n",
        "\n",
        "            counts = execute_circuit(circuit, param_dict, backend)\n",
        "            expectation = 0\n",
        "            for bitstring, count in counts.items():\n",
        "              if len(bitstring) < 3:\n",
        "                continue\n",
        "              bit_values = [1 if b == '0' else -1 for b in bitstring[:3]]\n",
        "              zz_product = bit_values[0] * bit_values[1] * bit_values[2]\n",
        "              expectation += zz_product * count / 1024\n",
        "            image_cost += (1 - expectation)\n",
        "\n",
        "        # Average cost over all patches in the image\n",
        "        cost += image_cost / len(image_patches)\n",
        "\n",
        "    # Average cost over all images in the batch\n",
        "    return cost / len(x_batch)\n",
        "\n",
        "\n",
        "def train_qcnn(circuit, X_train, y_train, backend, maxiter=50):\n",
        "    all_params = list(circuit.parameters)\n",
        "    # Ensure there are at least 4 input parameters and some weight parameters\n",
        "    if len(all_params) < 5:\n",
        "         raise ValueError(\"Circuit must have at least 4 input parameters and 1 weight parameter.\")\n",
        "    input_params = all_params[:4]\n",
        "    weight_params = all_params[4:]\n",
        "    initial_params = np.random.rand(len(weight_params)) * 2 * np.pi - np.pi\n",
        "    # Pass necessary parameters to the cost function\n",
        "    objective = lambda p: cost_function(p, circuit, input_params, weight_params, X_train, y_train, backend)\n",
        "    result = minimize(objective, initial_params, method='COBYLA', options={'maxiter': maxiter})\n",
        "    return result.x\n",
        "\n",
        "def ensemble_predict(X_test, circuits, param_list, classifiers, backend):\n",
        "    all_preds = []\n",
        "    all_probs = []\n",
        "\n",
        "    for circuit, params, clf in zip(circuits, param_list, classifiers):\n",
        "        # extract_all_features returns a list of feature lists (one per image)\n",
        "        features = extract_all_features(X_test, circuit, params, backend)\n",
        "        features_array = np.array(features)\n",
        "        preds = clf.predict(features_array)\n",
        "        probs = clf.predict_proba(features_array)  # Shape: (num_samples, num_classes)\n",
        "        all_preds.append(preds)\n",
        "        all_probs.append(probs)\n",
        "\n",
        "    final_preds = []\n",
        "    for i in range(len(X_test)):\n",
        "        votes = [model_preds[i] for model_preds in all_preds]\n",
        "        probs_for_sample = [model_probs[i] for model_probs in all_probs]  # list of np.arrays\n",
        "        from collections import Counter\n",
        "        vote_counts = Counter(votes)\n",
        "        # Check if we have a tie (3 unique votes)\n",
        "        if len(vote_counts) == 3:\n",
        "            # Resolve tie using highest confidence\n",
        "            best_class = None\n",
        "            best_conf = -1\n",
        "            for pred, prob_dist in zip(votes, probs_for_sample):\n",
        "                conf = prob_dist[pred]  # Get the confidence of the predicted class\n",
        "                if conf > best_conf:\n",
        "                    best_conf = conf\n",
        "                    best_class = pred\n",
        "            final_preds.append(best_class)\n",
        "        else:\n",
        "            most_common = vote_counts.most_common(1)[0][0]\n",
        "            final_preds.append(most_common)\n",
        "\n",
        "    return final_preds\n",
        "\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred) * 100)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "def main():\n",
        "    print(\"Starting 3-Qubit QCNN Ensemble for 15-Class Classification\")\n",
        "    X_train, y_train, X_test, y_test = prepare_dataset()\n",
        "\n",
        "    # Check the shapes of X_train and y_train\n",
        "    print(f\"Shape of X_train: {X_train.shape}\")\n",
        "    print(f\"Shape of y_train: {y_train.shape}\")\n",
        "\n",
        "    backend = Aer.get_backend('qasm_simulator')\n",
        "\n",
        "    circuit1 = create_qcnn_circuit_1()\n",
        "    circuit2 = create_qcnn_circuit_2()\n",
        "    circuit3 = create_qcnn_circuit_3()\n",
        "\n",
        "\n",
        "    print(\"Training QCNN 1...\")\n",
        "    params1 = train_qcnn(circuit1, X_train, y_train, backend)\n",
        "    print(\"Training QCNN 2...\")\n",
        "    params2 = train_qcnn(circuit2, X_train, y_train, backend)\n",
        "    print(\"Training QCNN 3...\")\n",
        "    params3 = train_qcnn(circuit3, X_train, y_train, backend)\n",
        "\n",
        "    print(\"Extracting features...\")\n",
        "    feat1 = extract_all_features(X_train, circuit1, params1, backend)\n",
        "    feat2 = extract_all_features(X_train, circuit2, params2, backend)\n",
        "    feat3 = extract_all_features(X_train, circuit3, params3, backend)\n",
        "\n",
        "    print(\"Training classifiers...\")\n",
        "    clf1 = train_classifier(feat1, y_train)\n",
        "    clf2 = train_classifier(feat2, y_train)\n",
        "    clf3 = train_classifier(feat3, y_train)\n",
        "\n",
        "    try:\n",
        "        with open('qcnn_ensemble_models.pkl', 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'params1': params1,\n",
        "                'params2': params2,\n",
        "                'params3': params3,\n",
        "                'clf1': clf1,\n",
        "                'clf2': clf2,\n",
        "                'clf3': clf3\n",
        "            }, f)\n",
        "        print(\"Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving models: {e}\")\n",
        "\n",
        "    print(\"Performing ensemble prediction...\")\n",
        "    final_preds = ensemble_predict(X_test, [circuit1, circuit2, circuit3], [params1, params2, params3], [clf1, clf2, clf3], backend)\n",
        "\n",
        "    print(\"Evaluating results...\")\n",
        "    evaluate(y_test, final_preds)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import qiskit\n",
        "    print(f\"Qiskit version: {qiskit.__version__}\")\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pTAkF4V7G5GE",
        "outputId": "43b0afc7-f43a-488b-dcf0-d558ca492991"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-2.1.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit)\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.11/dist-packages (from qiskit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.15.3)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit) (0.3.7)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qiskit) (4.14.0)\n",
            "Collecting pbr>=2.0.0 (from stevedore>=3.0.0->qiskit)\n",
            "  Downloading pbr-6.1.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pbr>=2.0.0->stevedore>=3.0.0->qiskit) (75.2.0)\n",
            "Downloading qiskit-2.1.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.4.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pbr-6.1.1-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rustworkx, pbr, stevedore, qiskit\n",
            "Successfully installed pbr-6.1.1 qiskit-2.1.0 rustworkx-0.16.0 stevedore-5.4.1\n"
          ]
        }
      ],
      "source": [
        "pip install qiskit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "THJ9da61E3zz",
        "outputId": "b1f4d0b4-389c-41f7-aaf9-3d4a1861362e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting qiskit-aer\n",
            "  Downloading qiskit_aer-0.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: qiskit>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (1.15.3)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.0->qiskit-aer) (1.17.0)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (0.16.0)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (0.3.7)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (4.14.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from stevedore>=3.0.0->qiskit>=1.1.0->qiskit-aer) (6.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pbr>=2.0.0->stevedore>=3.0.0->qiskit>=1.1.0->qiskit-aer) (75.2.0)\n",
            "Downloading qiskit_aer-0.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: qiskit-aer\n",
            "Successfully installed qiskit-aer-0.17.1\n"
          ]
        }
      ],
      "source": [
        "pip install qiskit-aer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXqhRRLXDd-Q"
      },
      "source": [
        "# **4x48 input for 15 classes classification by measuring 4 qubits**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgZ773jSE3lk",
        "outputId": "899c2528-7f4d-44a5-80a8-ffcbacba7561"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Qiskit version: 2.1.0\n",
            "Starting 3-Qubit QCNN Ensemble for 15-Class Classification\n",
            "Shape of X_train: (120, 576, 4)\n",
            "Shape of y_train: (120,)\n",
            "Training QCNN 1...\n",
            "Training QCNN 2...\n",
            "Training QCNN 3...\n",
            "Extracting features...\n",
            "Training classifiers...\n",
            "SVM Classifier trained for 15 classes\n",
            "SVM Classifier trained for 15 classes\n",
            "SVM Classifier trained for 15 classes\n",
            "Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\n",
            "Performing ensemble prediction...\n",
            "Evaluating results...\n",
            "Accuracy: 75.55555555555556\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         3\n",
            "           1       1.00      0.33      0.50         3\n",
            "           2       0.75      1.00      0.86         3\n",
            "           3       1.00      0.67      0.80         3\n",
            "           4       1.00      0.67      0.80         3\n",
            "           5       0.60      1.00      0.75         3\n",
            "           6       1.00      0.67      0.80         3\n",
            "           7       0.50      0.67      0.57         3\n",
            "           8       1.00      0.33      0.50         3\n",
            "           9       1.00      0.67      0.80         3\n",
            "          10       1.00      1.00      1.00         3\n",
            "          11       0.75      1.00      0.86         3\n",
            "          12       1.00      0.67      0.80         3\n",
            "          13       1.00      0.67      0.80         3\n",
            "          14       0.60      1.00      0.75         3\n",
            "\n",
            "    accuracy                           0.76        45\n",
            "   macro avg       0.85      0.76      0.75        45\n",
            "weighted avg       0.85      0.76      0.75        45\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import mode\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit_aer import Aer\n",
        "from qiskit.circuit import Parameter\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "def prepare_dataset(dataset_path='/content/dataset'):\n",
        "    train_dir = os.path.join(dataset_path, 'train')\n",
        "    test_dir = os.path.join(dataset_path, 'test')\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    subjects = [f'subject{i:02d}' for i in range(1, 16)]\n",
        "    # Changed test_size to 2 to ensure 2 images per subject for testing\n",
        "    test_size_per_subject = 3\n",
        "\n",
        "    for subject in subjects:\n",
        "        all_items = [f for f in os.listdir(dataset_path)]\n",
        "        subject_files = [item for item in all_items if item.startswith(subject)]\n",
        "        # Ensure there are enough files for the split\n",
        "        if len(subject_files) < test_size_per_subject:\n",
        "            print(f\"Warning: Not enough files for subject {subject} to create test set. Skipping.\")\n",
        "            continue\n",
        "        train_files, test_files = train_test_split(subject_files, test_size=test_size_per_subject, random_state=42)\n",
        "\n",
        "        for file in train_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(train_dir, file))\n",
        "        for file in test_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(test_dir, file))\n",
        "\n",
        "    X_train, y_train = process_folder(train_dir)\n",
        "    X_test, y_test = process_folder(test_dir)\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "def process_folder(folder_path):\n",
        "    processed_images = []\n",
        "    labels = []\n",
        "    image_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path)]\n",
        "\n",
        "    subject_ids = set(os.path.basename(file).split('.')[0] for file in image_files)\n",
        "    subject_to_label = {subject: i for i, subject in enumerate(sorted(subject_ids))}\n",
        "\n",
        "    for file in image_files:\n",
        "        file_name = os.path.basename(file)\n",
        "        subject_id = file_name.split('.')[0]\n",
        "        label = subject_to_label[subject_id]\n",
        "\n",
        "        img = Image.open(file).convert('L').resize((48, 48))\n",
        "        img_array = np.array(img).astype(np.float32) / 255.0 * 2 * np.pi\n",
        "\n",
        "        patches = [img_array[i:i+2, j:j+2].flatten() for i in range(0, 48, 2) for j in range(0, 48, 2) if i+2 <= 48 and j+2 <= 48]\n",
        "        processed_images.append(patches)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(processed_images), np.array(labels)\n",
        "\n",
        "def create_qcnn_circuit_1():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'theta_conv1_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.cx(i, (i+1) % 4)\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.ry(Parameter('theta_conv2_0'), 2)\n",
        "    qc.ry(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.ry(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "def create_qcnn_circuit_2():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.rx(Parameter(f'theta_conv1_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.cx(i, (i+1) % 4)\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.rx(Parameter('theta_conv2_0'), 2)\n",
        "    qc.rx(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cz(2, 3)\n",
        "    qc.cz(3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.rx(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "def create_qcnn_circuit_3():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.rz(Parameter(f'theta_conv1_{i}'), i)\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(0, 2)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.rz(Parameter('theta_conv2_0'), 2)\n",
        "    qc.rz(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.rz(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "\n",
        "def execute_circuit(circuit, parameters, backend):\n",
        "    # parameters is a dictionary of {Parameter: value}\n",
        "    bound = circuit.assign_parameters(parameters)\n",
        "    meas = QuantumCircuit(4, 4)\n",
        "    meas.compose(bound, inplace=True)\n",
        "    meas.measure([3, 2, 1, 0], [0, 1, 2, 3])\n",
        "    job = backend.run(meas, shots=1024)\n",
        "    result = job.result()\n",
        "    return result.get_counts()\n",
        "\n",
        "def extract_features_from_image(image_patches, circuit, params, backend):\n",
        "    input_params = list(circuit.parameters)[:4]\n",
        "    weight_params = list(circuit.parameters)[4:]\n",
        "    features = []\n",
        "    for patch in image_patches:\n",
        "        bindings = {input_params[i]: float(patch[i]) for i in range(4)}\n",
        "        for i, param in enumerate(weight_params):\n",
        "            bindings[param] = float(params[i])\n",
        "\n",
        "        bound = circuit.assign_parameters(bindings)\n",
        "        meas_circuit = QuantumCircuit(4, 4)\n",
        "        meas_circuit.compose(bound, inplace=True)\n",
        "        meas_circuit.measure([3, 2, 1, 0], [0, 1, 2, 3])\n",
        "        job = backend.run(meas_circuit, shots=1024)\n",
        "        result = job.result()\n",
        "        counts = result.get_counts()\n",
        "\n",
        "        # Compute expectation value for Z⊗Z⊗Z⊗Z on qubits 3,2,1,0\n",
        "        expectation = 0\n",
        "        for bitstring, count in counts.items():\n",
        "            bit_values = [1 if b == '0' else -1 for b in bitstring]\n",
        "            zz_product = bit_values[0] * bit_values[1] * bit_values[2] * bit_values[3]\n",
        "            expectation += zz_product * count / 1024\n",
        "\n",
        "        features.append(expectation)\n",
        "    return features\n",
        "\n",
        "\n",
        "def extract_all_features(X, circuit, params, backend):\n",
        "    # X contains a list of images, where each image is a list of patches.\n",
        "    all_features = []\n",
        "    for image_patches in X:\n",
        "         # extract_features_from_image already handles all patches for a single image\n",
        "        image_features = extract_features_from_image(image_patches, circuit, params, backend)\n",
        "        all_features.append(image_features)\n",
        "    return all_features\n",
        "\n",
        "\n",
        "def train_classifier(X_features, y_labels):\n",
        "    X_features_reshaped = np.array(X_features) # This should create a (num_images, num_patches) array\n",
        "\n",
        "    # Changed from LogisticRegression to SVC (Support Vector Classifier)\n",
        "    # Using RBF kernel which often works well for image classification\n",
        "    clf = SVC(kernel='rbf', probability=True, C=1.0, gamma='scale')\n",
        "    clf.fit(X_features_reshaped, y_labels)\n",
        "\n",
        "    # Verify the classifier is trained for the correct number of classes\n",
        "    n_classes = len(np.unique(y_labels))\n",
        "    print(f\"SVM Classifier trained for {n_classes} classes\")\n",
        "\n",
        "    return clf\n",
        "\n",
        "def cost_function(params, circuit, input_params, weight_params, x_batch, y_batch, backend):\n",
        "    cost = 0\n",
        "    # We need to iterate through each image in the batch.\n",
        "    for i in range(len(x_batch)):\n",
        "        # We need to process each patch for this image to calculate the cost.\n",
        "        image_patches = x_batch[i]\n",
        "        # Calculate cost for this image by averaging the cost over its patches.\n",
        "        image_cost = 0\n",
        "        for patch in image_patches:\n",
        "            # Create a dictionary binding each pixel value to its corresponding input parameter\n",
        "            param_dict = {input_params[j]: float(patch[j]) for j in range(4)}\n",
        "            # Add the weight parameters to the bindings dictionary\n",
        "            for j, param in enumerate(weight_params):\n",
        "                param_dict[param] = float(params[j])\n",
        "\n",
        "            counts = execute_circuit(circuit, param_dict, backend)\n",
        "            expectation = 0\n",
        "            for bitstring, count in counts.items():\n",
        "              if len(bitstring) < 4:\n",
        "                continue\n",
        "              bit_values = [1 if b == '0' else -1 for b in bitstring[:4]]\n",
        "              zz_product = bit_values[0] * bit_values[1] * bit_values[2] * bit_values[3]\n",
        "              expectation += zz_product * count / 1024\n",
        "            image_cost += (1 - expectation)\n",
        "\n",
        "        # Average cost over all patches in the image\n",
        "        cost += image_cost / len(image_patches)\n",
        "\n",
        "    # Average cost over all images in the batch\n",
        "    return cost / len(x_batch)\n",
        "\n",
        "\n",
        "def train_qcnn(circuit, X_train, y_train, backend, maxiter=50):\n",
        "    all_params = list(circuit.parameters)\n",
        "    # Ensure there are at least 4 input parameters and some weight parameters\n",
        "    if len(all_params) < 5:\n",
        "         raise ValueError(\"Circuit must have at least 4 input parameters and 1 weight parameter.\")\n",
        "    input_params = all_params[:4]\n",
        "    weight_params = all_params[4:]\n",
        "    initial_params = np.random.rand(len(weight_params)) * 2 * np.pi - np.pi\n",
        "    # Pass necessary parameters to the cost function\n",
        "    objective = lambda p: cost_function(p, circuit, input_params, weight_params, X_train, y_train, backend)\n",
        "    result = minimize(objective, initial_params, method='COBYLA', options={'maxiter': maxiter})\n",
        "    return result.x\n",
        "\n",
        "def ensemble_predict(X_test, circuits, param_list, classifiers, backend):\n",
        "    all_preds = []\n",
        "    for circuit, params, clf in zip(circuits, param_list, classifiers):\n",
        "        # extract_all_features returns a list of feature lists (one per image)\n",
        "        features = extract_all_features(X_test, circuit, params, backend)\n",
        "        # Convert features to a NumPy array for the classifier\n",
        "        features_array = np.array(features)\n",
        "        preds = clf.predict(features_array)\n",
        "        all_preds.append(preds)\n",
        "\n",
        "    final_preds = []\n",
        "    for i in range(len(X_test)):\n",
        "        votes = [model_preds[i] for model_preds in all_preds]\n",
        "\n",
        "        # Simple fix: convert to a list and use the most common value\n",
        "        votes_list = list(votes)\n",
        "        # Count occurrences of each value\n",
        "        from collections import Counter\n",
        "        most_common = Counter(votes_list).most_common(1)[0][0]\n",
        "        final_preds.append(most_common)\n",
        "\n",
        "    return final_preds\n",
        "\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred) * 100)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "def main():\n",
        "    print(\"Starting 3-Qubit QCNN Ensemble for 15-Class Classification\")\n",
        "    X_train, y_train, X_test, y_test = prepare_dataset()\n",
        "\n",
        "    # Check the shapes of X_train and y_train\n",
        "    print(f\"Shape of X_train: {X_train.shape}\")\n",
        "    print(f\"Shape of y_train: {y_train.shape}\")\n",
        "\n",
        "    backend = Aer.get_backend('qasm_simulator')\n",
        "\n",
        "    circuit1 = create_qcnn_circuit_1()\n",
        "    circuit2 = create_qcnn_circuit_2()\n",
        "    circuit3 = create_qcnn_circuit_3()\n",
        "\n",
        "\n",
        "    print(\"Training QCNN 1...\")\n",
        "    params1 = train_qcnn(circuit1, X_train, y_train, backend)\n",
        "    print(\"Training QCNN 2...\")\n",
        "    params2 = train_qcnn(circuit2, X_train, y_train, backend)\n",
        "    print(\"Training QCNN 3...\")\n",
        "    params3 = train_qcnn(circuit3, X_train, y_train, backend)\n",
        "\n",
        "    print(\"Extracting features...\")\n",
        "    feat1 = extract_all_features(X_train, circuit1, params1, backend)\n",
        "    feat2 = extract_all_features(X_train, circuit2, params2, backend)\n",
        "    feat3 = extract_all_features(X_train, circuit3, params3, backend)\n",
        "\n",
        "    print(\"Training classifiers...\")\n",
        "    clf1 = train_classifier(feat1, y_train)\n",
        "    clf2 = train_classifier(feat2, y_train)\n",
        "    clf3 = train_classifier(feat3, y_train)\n",
        "\n",
        "    try:\n",
        "        with open('qcnn_ensemble_models.pkl', 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'params1': params1,\n",
        "                'params2': params2,\n",
        "                'params3': params3,\n",
        "                'clf1': clf1,\n",
        "                'clf2': clf2,\n",
        "                'clf3': clf3\n",
        "            }, f)\n",
        "        print(\"Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving models: {e}\")\n",
        "\n",
        "    print(\"Performing ensemble prediction...\")\n",
        "    final_preds = ensemble_predict(X_test, [circuit1, circuit2, circuit3], [params1, params2, params3], [clf1, clf2, clf3], backend)\n",
        "\n",
        "    print(\"Evaluating results...\")\n",
        "    evaluate(y_test, final_preds)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import qiskit\n",
        "    print(f\"Qiskit version: {qiskit.__version__}\")\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqTLZeQLME7s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8uVZvHmTs53_",
        "outputId": "428b77bc-0fe5-4f5e-914b-1d13afc77e11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-2.1.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit)\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.11/dist-packages (from qiskit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.15.3)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit) (0.3.7)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qiskit) (4.14.0)\n",
            "Collecting pbr>=2.0.0 (from stevedore>=3.0.0->qiskit)\n",
            "  Downloading pbr-6.1.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pbr>=2.0.0->stevedore>=3.0.0->qiskit) (75.2.0)\n",
            "Downloading qiskit-2.1.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.4.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pbr-6.1.1-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rustworkx, pbr, stevedore, qiskit\n",
            "Successfully installed pbr-6.1.1 qiskit-2.1.0 rustworkx-0.16.0 stevedore-5.4.1\n"
          ]
        }
      ],
      "source": [
        "pip install qiskit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IjZ8Sr9hs5qh",
        "outputId": "38f4aeb0-2b1e-45cf-9b73-dfe1d8501602"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting qiskit-aer\n",
            "  Downloading qiskit_aer-0.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: qiskit>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (1.15.3)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.0->qiskit-aer) (1.17.0)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (0.16.0)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (0.3.7)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (4.14.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from stevedore>=3.0.0->qiskit>=1.1.0->qiskit-aer) (6.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pbr>=2.0.0->stevedore>=3.0.0->qiskit>=1.1.0->qiskit-aer) (75.2.0)\n",
            "Downloading qiskit_aer-0.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m114.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: qiskit-aer\n",
            "Successfully installed qiskit-aer-0.17.1\n"
          ]
        }
      ],
      "source": [
        "pip install qiskit-aer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7VVB82tDTHO"
      },
      "source": [
        "# **7 Subjects with 64x64 input and 75 iterations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "xS_IGz6m78cn",
        "outputId": "f78eba77-6939-44fb-de8c-396c1a680621"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Qiskit version: 2.1.0\n",
            "Starting 1-Qubit QCNN Ensemble for 5-Class Classification\n",
            "Shape of X_train: (56, 1024, 4)\n",
            "Shape of y_train: (56,)\n",
            "Training QCNN 1...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-2174821402.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Qiskit version: {qiskit.__version__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3-2174821402.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training QCNN 1...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0mparams1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_qcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training QCNN 2...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0mparams2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_qcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3-2174821402.py\u001b[0m in \u001b[0;36mtrain_qcnn\u001b[0;34m(circuit, X_train, y_train, backend, maxiter)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;31m# Pass necessary parameters to the cost function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'COBYLA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'maxiter'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    742\u001b[0m                             **options)\n\u001b[1;32m    743\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cobyla'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         res = _minimize_cobyla(fun, x0, args, constraints, callback=callback,\n\u001b[0m\u001b[1;32m    745\u001b[0m                                bounds=bounds, **options)\n\u001b[1;32m    746\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cobyqa'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_cobyla_py.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_module_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_cobyla_py.py\u001b[0m in \u001b[0;36m_minimize_cobyla\u001b[0;34m(fun, x0, args, constraints, rhobeg, tol, maxiter, disp, catol, callback, bounds, **unknown_options)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m     \u001b[0msf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_scalar_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_jac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalcfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;31m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;31m# calculation reduces overall function evaluations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m     sf = ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0m\u001b[1;32m    292\u001b[0m                         finite_diff_rel_step, bounds, epsilon=epsilon)\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Initial function evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Initial gradient evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lowest_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lowest_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Make sure the function returns a true scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3-2174821402.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0minitial_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;31m# Pass necessary parameters to the cost function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'COBYLA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'maxiter'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3-2174821402.py\u001b[0m in \u001b[0;36mcost_function\u001b[0;34m(params, circuit, input_params, weight_params, x_batch, y_batch, backend)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mparam_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m             \u001b[0;31m# Calculate expectation value for Z_3 Z_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0mc00\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"00\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3-2174821402.py\u001b[0m in \u001b[0;36mexecute_circuit\u001b[0;34m(circuit, parameters, backend)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mmeas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit_aer/jobs/utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_future\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJobError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job not submitted yet!. You have to .submit() first!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit_aer/jobs/aerjob.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCancelledError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mjob\u001b[0m \u001b[0mcancelled\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \"\"\"\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mrequires_submit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import mode\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit_aer import Aer\n",
        "from qiskit.circuit import Parameter\n",
        "import pickle\n",
        "\n",
        "\n",
        "def prepare_dataset(dataset_path='/content/dataset'):\n",
        "    train_dir = os.path.join(dataset_path, 'train')\n",
        "    test_dir = os.path.join(dataset_path, 'test')\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    subjects = [f'subject{i:02d}' for i in range(1, 8)]\n",
        "    # Changed test_size to 2 to ensure 2 images per subject for testing\n",
        "    test_size_per_subject = 3\n",
        "\n",
        "    for subject in subjects:\n",
        "        all_items = [f for f in os.listdir(dataset_path)]\n",
        "        subject_files = [item for item in all_items if item.startswith(subject)]\n",
        "        # Ensure there are enough files for the split\n",
        "        if len(subject_files) < test_size_per_subject:\n",
        "            print(f\"Warning: Not enough files for subject {subject} to create test set. Skipping.\")\n",
        "            continue\n",
        "        train_files, test_files = train_test_split(subject_files, test_size=test_size_per_subject, random_state=42)\n",
        "\n",
        "        for file in train_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(train_dir, file))\n",
        "        for file in test_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(test_dir, file))\n",
        "\n",
        "    X_train, y_train = process_folder(train_dir)\n",
        "    X_test, y_test = process_folder(test_dir)\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "def process_folder(folder_path):\n",
        "    processed_images = []\n",
        "    labels = []\n",
        "    image_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path)]\n",
        "\n",
        "    subject_ids = set(os.path.basename(file).split('.')[0] for file in image_files)\n",
        "    subject_to_label = {subject: i for i, subject in enumerate(sorted(subject_ids))}\n",
        "\n",
        "    for file in image_files:\n",
        "        file_name = os.path.basename(file)\n",
        "        subject_id = file_name.split('.')[0]\n",
        "        label = subject_to_label[subject_id]\n",
        "\n",
        "        img = Image.open(file).convert('L').resize((48, 48))\n",
        "        img_array = np.array(img).astype(np.float32) / 255.0 * 2 * np.pi\n",
        "\n",
        "        patches = [img_array[i:i+2, j:j+2].flatten() for i in range(0, 48, 2) for j in range(0, 48, 2) if i+2 <= 48 and j+2 <= 48]\n",
        "        processed_images.append(patches)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(processed_images), np.array(labels)\n",
        "\n",
        "def create_qcnn_circuit_1():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'theta_conv1_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.cx(i, (i+1) % 4)\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.ry(Parameter('theta_conv2_0'), 2)\n",
        "    qc.ry(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.ry(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "def create_qcnn_circuit_2():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.rx(Parameter(f'theta_conv1_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.cx(i, (i+1) % 4)\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.rx(Parameter('theta_conv2_0'), 2)\n",
        "    qc.rx(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cz(2, 3)\n",
        "    qc.cz(3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.rx(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "def create_qcnn_circuit_3():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.rx(Parameter(f'theta_conv1_{i}'), i) # Changed rz to rx\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(1, 2)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 0) # Circular entanglement\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.rx(Parameter('theta_conv2_0'), 2) # Changed rz to rx\n",
        "    qc.rx(Parameter('theta_conv2_1'), 3) # Changed rz to rx\n",
        "    qc.crx(Parameter('theta_crx_0'), 2, 3) # Changed cx to crx\n",
        "    qc.crx(Parameter('theta_crx_1'), 3, 2) # Changed cx to crx\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.rx(Parameter('theta_final'), 3) # Changed rz to rx\n",
        "    return qc\n",
        "\n",
        "\n",
        "def execute_circuit(circuit, parameters, backend):\n",
        "    # parameters is a dictionary of {Parameter: value}\n",
        "    bound = circuit.assign_parameters(parameters)\n",
        "    meas = QuantumCircuit(4, 2)\n",
        "    meas.compose(bound, inplace=True)\n",
        "    meas.measure([3, 2], [0, 1])\n",
        "    job = backend.run(meas, shots=1024)\n",
        "    result = job.result()\n",
        "    return result.get_counts()\n",
        "\n",
        "# Change this part in the extract_features_from_image function:\n",
        "def extract_features_from_image(image_patches, circuit, params, backend):\n",
        "    input_params = list(circuit.parameters)[:4]\n",
        "    weight_params = list(circuit.parameters)[4:]\n",
        "    features = []\n",
        "    for patch in image_patches:\n",
        "        # Create a dictionary binding each pixel value to its corresponding input parameter\n",
        "        bindings = {input_params[i]: float(patch[i]) for i in range(4)}\n",
        "        # Add the weight parameters to the bindings dictionary\n",
        "        for i, param in enumerate(weight_params):\n",
        "            bindings[param] = float(params[i])\n",
        "\n",
        "        bound = circuit.assign_parameters(bindings)\n",
        "        meas_circuit = QuantumCircuit(4, 2)\n",
        "        meas_circuit.compose(bound, inplace=True)\n",
        "        meas_circuit.measure([3, 2], [0, 1])\n",
        "        job = backend.run(meas_circuit, shots=1024)\n",
        "        result = job.result()\n",
        "        counts = result.get_counts()\n",
        "        c00 = counts.get('00', 0)\n",
        "        c01 = counts.get('01', 0)\n",
        "        c10 = counts.get('10', 0)\n",
        "        c11 = counts.get('11', 0)\n",
        "        expectation = (c00 + c11 - c01 - c10) / 1024\n",
        "        features.append(expectation)\n",
        "    return features\n",
        "\n",
        "\n",
        "def extract_all_features(X, circuit, params, backend):\n",
        "    # X contains a list of images, where each image is a list of patches.\n",
        "    all_features = []\n",
        "    for image_patches in X:\n",
        "         # extract_features_from_image already handles all patches for a single image\n",
        "        image_features = extract_features_from_image(image_patches, circuit, params, backend)\n",
        "        all_features.append(image_features)\n",
        "    return all_features\n",
        "\n",
        "\n",
        "def train_classifier(X_features, y_labels):\n",
        "    X_features_reshaped = np.array(X_features) # This should create a (num_images, num_patches) array\n",
        "\n",
        "    # Changed from LogisticRegression to SVC (Support Vector Classifier)\n",
        "    # Using RBF kernel which often works well for image classification\n",
        "    clf = SVC(kernel='rbf', probability=True, C=1.0, gamma='scale')\n",
        "    clf.fit(X_features_reshaped, y_labels)\n",
        "\n",
        "    # Verify the classifier is trained for the correct number of classes\n",
        "    n_classes = len(np.unique(y_labels))\n",
        "    print(f\"SVM Classifier trained for {n_classes} classes\")\n",
        "\n",
        "    return clf\n",
        "\n",
        "def cost_function(params, circuit, input_params, weight_params, x_batch, y_batch, backend):\n",
        "    cost = 0\n",
        "    # We need to iterate through each image in the batch.\n",
        "    for i in range(len(x_batch)):\n",
        "        # We need to process each patch for this image to calculate the cost.\n",
        "        image_patches = x_batch[i]\n",
        "        # Calculate cost for this image by averaging the cost over its patches.\n",
        "        image_cost = 0\n",
        "        for patch in image_patches:\n",
        "            # Create a dictionary binding each pixel value to its corresponding input parameter\n",
        "            param_dict = {input_params[j]: float(patch[j]) for j in range(4)}\n",
        "            # Add the weight parameters to the bindings dictionary\n",
        "            for j, param in enumerate(weight_params):\n",
        "                param_dict[param] = float(params[j])\n",
        "\n",
        "            counts = execute_circuit(circuit, param_dict, backend)\n",
        "            # Calculate expectation value for Z_3 Z_2\n",
        "            c00 = counts.get(\"00\", 0)\n",
        "            c01 = counts.get(\"01\", 0)\n",
        "            c10 = counts.get(\"10\", 0)\n",
        "            c11 = counts.get(\"11\", 0)\n",
        "            expectation = (c00 + c11 - c01 - c10) / 1024\n",
        "            image_cost += (1 - expectation)\n",
        "\n",
        "        # Average cost over all patches in the image\n",
        "        cost += image_cost / len(image_patches)\n",
        "\n",
        "    # Average cost over all images in the batch\n",
        "    return cost / len(x_batch)\n",
        "\n",
        "\n",
        "def train_qcnn(circuit, X_train, y_train, backend, maxiter=50):\n",
        "    all_params = list(circuit.parameters)\n",
        "    # Ensure there are at least 4 input parameters and some weight parameters\n",
        "    if len(all_params) < 5:\n",
        "         raise ValueError(\"Circuit must have at least 4 input parameters and 1 weight parameter.\")\n",
        "    input_params = all_params[:4]\n",
        "    weight_params = all_params[4:]\n",
        "    initial_params = np.random.rand(len(weight_params)) * 2 * np.pi - np.pi\n",
        "    # Pass necessary parameters to the cost function\n",
        "    objective = lambda p: cost_function(p, circuit, input_params, weight_params, X_train, y_train, backend)\n",
        "    result = minimize(objective, initial_params, method='COBYLA', options={'maxiter': maxiter})\n",
        "    return result.x\n",
        "\n",
        "def ensemble_predict(X_test, circuits, param_list, classifiers, backend):\n",
        "    all_preds = []\n",
        "    for circuit, params, clf in zip(circuits, param_list, classifiers):\n",
        "        # extract_all_features returns a list of feature lists (one per image)\n",
        "        features = extract_all_features(X_test, circuit, params, backend)\n",
        "        # Convert features to a NumPy array for the classifier\n",
        "        features_array = np.array(features)\n",
        "        preds = clf.predict(features_array)\n",
        "        all_preds.append(preds)\n",
        "\n",
        "    final_preds = []\n",
        "    for i in range(len(X_test)):\n",
        "        votes = [model_preds[i] for model_preds in all_preds]\n",
        "\n",
        "        # Simple fix: convert to a list and use the most common value\n",
        "        votes_list = list(votes)\n",
        "        # Count occurrences of each value\n",
        "        from collections import Counter\n",
        "        most_common = Counter(votes_list).most_common(1)[0][0]\n",
        "        final_preds.append(most_common)\n",
        "\n",
        "    return final_preds\n",
        "\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred) * 100)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "def main():\n",
        "    print(\"Starting 1-Qubit QCNN Ensemble for 5-Class Classification\")\n",
        "    X_train, y_train, X_test, y_test = prepare_dataset()\n",
        "\n",
        "    # Check the shapes of X_train and y_train\n",
        "    print(f\"Shape of X_train: {X_train.shape}\")\n",
        "    print(f\"Shape of y_train: {y_train.shape}\")\n",
        "\n",
        "    backend = Aer.get_backend('qasm_simulator')\n",
        "\n",
        "    circuit1 = create_qcnn_circuit_1()\n",
        "    circuit2 = create_qcnn_circuit_2()\n",
        "    circuit3 = create_qcnn_circuit_3()\n",
        "\n",
        "\n",
        "    print(\"Training QCNN 1...\")\n",
        "    params1 = train_qcnn(circuit1, X_train, y_train, backend)\n",
        "    print(\"Training QCNN 2...\")\n",
        "    params2 = train_qcnn(circuit2, X_train, y_train, backend)\n",
        "    print(\"Training QCNN 3...\")\n",
        "    params3 = train_qcnn(circuit3, X_train, y_train, backend)\n",
        "\n",
        "    print(\"Extracting features...\")\n",
        "    feat1 = extract_all_features(X_train, circuit1, params1, backend)\n",
        "    feat2 = extract_all_features(X_train, circuit2, params2, backend)\n",
        "    feat3 = extract_all_features(X_train, circuit3, params3, backend)\n",
        "\n",
        "    print(\"Training classifiers...\")\n",
        "    clf1 = train_classifier(feat1, y_train)\n",
        "    clf2 = train_classifier(feat2, y_train)\n",
        "    clf3 = train_classifier(feat3, y_train)\n",
        "\n",
        "    try:\n",
        "        with open('qcnn_ensemble_models.pkl', 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'params1': params1,\n",
        "                'params2': params2,\n",
        "                'params3': params3,\n",
        "                'clf1': clf1,\n",
        "                'clf2': clf2,\n",
        "                'clf3': clf3\n",
        "            }, f)\n",
        "        print(\"Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving models: {e}\")\n",
        "\n",
        "    print(\"Performing ensemble prediction...\")\n",
        "    final_preds = ensemble_predict(X_test, [circuit1, circuit2, circuit3], [params1, params2, params3], [clf1, clf2, clf3], backend)\n",
        "\n",
        "    print(\"Evaluating results...\")\n",
        "    evaluate(y_test, final_preds)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import qiskit\n",
        "    print(f\"Qiskit version: {qiskit.__version__}\")\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZGGXJgoCjBD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dC3PIPHTBYw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LH_BZ1T5TBVY",
        "outputId": "30c7a3e0-b425-4856-d2a1-d65723b72111"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Qiskit version: 2.1.0\n",
            "Starting 1-Qubit QCNN Ensemble for 5-Class Classification\n",
            "Shape of X_train: (56, 576, 4)\n",
            "Shape of y_train: (56,)\n",
            "Training QCNN 1...\n",
            "Current cost: 1.1589713929191474\n",
            "Current cost: 1.218106345524864\n",
            "Current cost: 1.1358508760966959\n",
            "Current cost: 1.208797878689236\n",
            "Current cost: 0.9219454205225385\n",
            "Current cost: 0.9784690614730595\n",
            "Current cost: 0.7791036575559582\n",
            "Current cost: 0.7865131317623073\n",
            "Current cost: 0.7760587419782367\n",
            "Current cost: 0.7759282551114521\n",
            "Current cost: 0.7760950118776354\n",
            "Current cost: 0.780853029281374\n",
            "Current cost: 0.7800378345307848\n",
            "Current cost: 0.9625279865567645\n",
            "Current cost: 1.0079448033892917\n",
            "Current cost: 0.45476683359297504\n",
            "Current cost: 0.38439838469974585\n",
            "Current cost: 0.4939584883432539\n",
            "Current cost: 0.5001714797247022\n",
            "Current cost: 0.47678351023840543\n",
            "Current cost: 0.8419568500821554\n",
            "Current cost: 0.3997831798735118\n",
            "Current cost: 0.3961815606980097\n",
            "Current cost: 0.3878748454744855\n",
            "Current cost: 0.38803887745690735\n",
            "Current cost: 0.3839326283288379\n",
            "Current cost: 0.3858532375759548\n",
            "Current cost: 0.38738287062872023\n",
            "Current cost: 0.3841250586131263\n",
            "Current cost: 0.4093983362591457\n",
            "Current cost: 0.42254814269050733\n",
            "Current cost: 0.4150879269554502\n",
            "Current cost: 0.38582193283807664\n",
            "Current cost: 0.3879398769802518\n",
            "Current cost: 0.492327130030072\n",
            "Current cost: 0.39258103143601175\n",
            "Current cost: 0.395461672828311\n",
            "Current cost: 0.3784359523228238\n",
            "Current cost: 0.3767378670828684\n",
            "Current cost: 0.44620713733491435\n",
            "Current cost: 0.37365534948924245\n",
            "Current cost: 0.34573479304237964\n",
            "Current cost: 0.36397389003208697\n",
            "Current cost: 0.35380451262943335\n",
            "Current cost: 0.3415071396600632\n",
            "Current cost: 0.34632467845129583\n",
            "Current cost: 0.35134603106786344\n",
            "Current cost: 0.3412024482848151\n",
            "Current cost: 0.3434032258533296\n",
            "Current cost: 0.3423535180470301\n",
            "Current cost: 0.3413121662442646\n",
            "Training QCNN 2...\n",
            "Current cost: 1.4499949500674292\n",
            "Current cost: 1.449889894515749\n",
            "Current cost: 1.0834290640694753\n",
            "Current cost: 1.058363475496807\n",
            "Current cost: 1.0289977542937745\n",
            "Current cost: 1.013116624620226\n",
            "Current cost: 1.0175378587510848\n",
            "Current cost: 1.011705489385696\n",
            "Current cost: 1.013082110692584\n",
            "Current cost: 1.015908740815662\n",
            "Current cost: 1.0219363863506017\n",
            "Current cost: 1.0203992450048054\n",
            "Current cost: 1.0001342410132998\n",
            "Current cost: 0.898446098206535\n",
            "Current cost: 0.9020552256750681\n",
            "Current cost: 0.96743665422712\n",
            "Current cost: 0.7514727758982823\n",
            "Current cost: 0.683181641593812\n",
            "Current cost: 0.7991340273902532\n",
            "Current cost: 0.9403987460666229\n",
            "Current cost: 0.43562607538132464\n",
            "Current cost: 0.4497040037124876\n",
            "Current cost: 0.4331066192142546\n",
            "Current cost: 0.4768320719401043\n",
            "Current cost: 0.5421185569157676\n",
            "Current cost: 0.6896606929718503\n",
            "Current cost: 0.47539683750697537\n",
            "Current cost: 0.4210723392547123\n",
            "Current cost: 0.4349470592680432\n",
            "Current cost: 0.7118659852043033\n",
            "Current cost: 0.4216083344959077\n",
            "Current cost: 0.44793204655722957\n",
            "Current cost: 0.4230316404312376\n",
            "Current cost: 0.5157329619876923\n",
            "Current cost: 0.4224616762191529\n",
            "Current cost: 0.4148902287558904\n",
            "Current cost: 0.4277626522003658\n",
            "Current cost: 0.38632807655939966\n",
            "Current cost: 0.45793799748496417\n",
            "Current cost: 0.44625127883184523\n",
            "Current cost: 0.4253452240474641\n",
            "Current cost: 0.6274068923223586\n",
            "Current cost: 0.40980420793805816\n",
            "Current cost: 0.37070598299541174\n",
            "Current cost: 0.3665586804586743\n",
            "Current cost: 0.37059269254169763\n",
            "Current cost: 0.38756694490947424\n",
            "Current cost: 0.36643291655040916\n",
            "Current cost: 0.37176386515299475\n",
            "Current cost: 0.36695407685779385\n",
            "Current cost: 0.3664191715301028\n",
            "Training QCNN 3...\n",
            "Current cost: 0.5031840612017918\n",
            "Current cost: 0.50336177765377\n",
            "Current cost: 0.5033795190235923\n",
            "Current cost: 0.5032008337596106\n",
            "Current cost: 0.5032335311647446\n",
            "Current cost: 0.503337617904421\n",
            "Current cost: 0.5032269916837178\n",
            "Current cost: 0.5031597198001924\n",
            "Current cost: 0.5033344692654079\n",
            "Current cost: 0.5031988961356025\n",
            "Current cost: 0.5031710427904884\n",
            "Current cost: 0.5033172123015871\n",
            "Current cost: 0.5032862103174603\n",
            "Current cost: 0.5032818506634426\n",
            "Current cost: 0.5034111265152221\n",
            "Current cost: 0.5031571766686819\n",
            "Current cost: 0.5031850905645461\n",
            "Current cost: 0.5032876635354662\n",
            "Current cost: 0.5032694377596416\n",
            "Current cost: 0.5032868158249627\n",
            "Current cost: 0.5031787327357702\n",
            "Current cost: 0.5033052838037883\n",
            "Current cost: 0.503264654250372\n",
            "Current cost: 0.5032962617420014\n",
            "Current cost: 0.5032614450606089\n",
            "Current cost: 0.5030646551223029\n",
            "Current cost: 0.5030545431470113\n",
            "Current cost: 0.503173040965247\n",
            "Current cost: 0.5033652895972844\n",
            "Current cost: 0.5032611423068576\n",
            "Current cost: 0.5032869974772136\n",
            "Current cost: 0.5031982906281002\n",
            "Current cost: 0.5032676212371342\n",
            "Current cost: 0.5032519991435701\n",
            "Current cost: 0.5032440064445376\n",
            "Current cost: 0.5031663198319692\n",
            "Current cost: 0.5031945970323349\n",
            "Current cost: 0.5032711331806485\n",
            "Current cost: 0.5032644725981212\n",
            "Current cost: 0.5033550565204923\n",
            "Current cost: 0.5033508785187252\n",
            "Current cost: 0.5032188173324342\n",
            "Current cost: 0.5032381330217636\n",
            "Current cost: 0.5033080691383\n",
            "Current cost: 0.503059387207031\n",
            "Current cost: 0.5032717992389013\n",
            "Current cost: 0.5033648657420324\n",
            "Current cost: 0.5031700739784847\n",
            "Current cost: 0.5034106421092202\n",
            "Current cost: 0.5031447637648808\n",
            "Current cost: 0.5032398284427705\n",
            "Extracting features...\n",
            "Training classifiers...\n",
            "SVM Classifier trained for 7 classes\n",
            "SVM Classifier trained for 7 classes\n",
            "SVM Classifier trained for 7 classes\n",
            "Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\n",
            "Performing ensemble prediction...\n",
            "Evaluating results...\n",
            "Accuracy: 90.47619047619048\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         3\n",
            "           1       1.00      1.00      1.00         3\n",
            "           2       1.00      0.33      0.50         3\n",
            "           3       0.75      1.00      0.86         3\n",
            "           4       1.00      1.00      1.00         3\n",
            "           5       0.75      1.00      0.86         3\n",
            "           6       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.90        21\n",
            "   macro avg       0.93      0.90      0.89        21\n",
            "weighted avg       0.93      0.90      0.89        21\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import mode\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit_aer import Aer\n",
        "from qiskit.circuit import Parameter\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def prepare_dataset(dataset_path='/content/dataset'):\n",
        "    train_dir = os.path.join(dataset_path, 'train')\n",
        "    test_dir = os.path.join(dataset_path, 'test')\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    subjects = [f'subject{i:02d}' for i in range(1, 8)]\n",
        "    # Changed test_size to 2 to ensure 2 images per subject for testing\n",
        "    test_size_per_subject = 3\n",
        "\n",
        "    for subject in subjects:\n",
        "        all_items = [f for f in os.listdir(dataset_path)]\n",
        "        subject_files = [item for item in all_items if item.startswith(subject)]\n",
        "        # Ensure there are enough files for the split\n",
        "        if len(subject_files) < test_size_per_subject:\n",
        "            print(f\"Warning: Not enough files for subject {subject} to create test set. Skipping.\")\n",
        "            continue\n",
        "        train_files, test_files = train_test_split(subject_files, test_size=test_size_per_subject, random_state=42)\n",
        "\n",
        "        for file in train_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(train_dir, file))\n",
        "        for file in test_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(test_dir, file))\n",
        "\n",
        "    X_train, y_train = process_folder(train_dir)\n",
        "    X_test, y_test = process_folder(test_dir)\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "def process_folder(folder_path):\n",
        "    processed_images = []\n",
        "    labels = []\n",
        "    image_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path)]\n",
        "\n",
        "    subject_ids = set(os.path.basename(file).split('.')[0] for file in image_files)\n",
        "    subject_to_label = {subject: i for i, subject in enumerate(sorted(subject_ids))}\n",
        "\n",
        "    for file in image_files:\n",
        "        file_name = os.path.basename(file)\n",
        "        subject_id = file_name.split('.')[0]\n",
        "        label = subject_to_label[subject_id]\n",
        "\n",
        "        img = Image.open(file).convert('L').resize((48, 48))\n",
        "        img_array = np.array(img).astype(np.float32) / 255.0 * 2 * np.pi\n",
        "\n",
        "        patches = [img_array[i:i+2, j:j+2].flatten() for i in range(0, 48, 2) for j in range(0, 48, 2) if i+2 <= 48 and j+2 <= 48]\n",
        "        processed_images.append(patches)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(processed_images), np.array(labels)\n",
        "\n",
        "def create_qcnn_circuit_1():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'theta_conv1_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.cx(i, (i+1) % 4)\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.ry(Parameter('theta_conv2_0'), 2)\n",
        "    qc.ry(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.ry(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "def create_qcnn_circuit_2():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.rx(Parameter(f'theta_conv1_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.cx(i, (i+1) % 4)\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.rx(Parameter('theta_conv2_0'), 2)\n",
        "    qc.rx(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cz(2, 3)\n",
        "    qc.cz(3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.rx(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "def create_qcnn_circuit_3():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.rz(Parameter(f'theta_conv1_{i}'), i)\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(0, 2)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.rz(Parameter('theta_conv2_0'), 2)\n",
        "    qc.rz(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.rz(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "\n",
        "def execute_circuit(circuit, parameters, backend):\n",
        "    # parameters is a dictionary of {Parameter: value}\n",
        "    bound = circuit.assign_parameters(parameters)\n",
        "    meas = QuantumCircuit(4, 2)\n",
        "    meas.compose(bound, inplace=True)\n",
        "    meas.measure([3, 2], [0, 1])\n",
        "    job = backend.run(meas, shots=1024)\n",
        "    result = job.result()\n",
        "    return result.get_counts()\n",
        "\n",
        "# Change this part in the extract_features_from_image function:\n",
        "def extract_features_from_image(image_patches, circuit, params, backend):\n",
        "    input_params = list(circuit.parameters)[:4]\n",
        "    weight_params = list(circuit.parameters)[4:]\n",
        "    features = []\n",
        "    for patch in image_patches:\n",
        "        # Create a dictionary binding each pixel value to its corresponding input parameter\n",
        "        bindings = {input_params[i]: float(patch[i]) for i in range(4)}\n",
        "        # Add the weight parameters to the bindings dictionary\n",
        "        for i, param in enumerate(weight_params):\n",
        "            bindings[param] = float(params[i])\n",
        "\n",
        "        bound = circuit.assign_parameters(bindings)\n",
        "        meas_circuit = QuantumCircuit(4, 2)\n",
        "        meas_circuit.compose(bound, inplace=True)\n",
        "        meas_circuit.measure([3, 2], [0, 1])\n",
        "        job = backend.run(meas_circuit, shots=1024)\n",
        "        result = job.result()\n",
        "        counts = result.get_counts()\n",
        "        c00 = counts.get('00', 0)\n",
        "        c01 = counts.get('01', 0)\n",
        "        c10 = counts.get('10', 0)\n",
        "        c11 = counts.get('11', 0)\n",
        "        expectation = (c00 + c11 - c01 - c10) / 1024\n",
        "        features.append(expectation)\n",
        "    return features\n",
        "\n",
        "\n",
        "def extract_all_features(X, circuit, params, backend):\n",
        "    # X contains a list of images, where each image is a list of patches.\n",
        "    all_features = []\n",
        "    for image_patches in X:\n",
        "         # extract_features_from_image already handles all patches for a single image\n",
        "        image_features = extract_features_from_image(image_patches, circuit, params, backend)\n",
        "        all_features.append(image_features)\n",
        "    return all_features\n",
        "\n",
        "\n",
        "def train_classifier(X_features, y_labels):\n",
        "    X_features_reshaped = np.array(X_features) # This should create a (num_images, num_patches) array\n",
        "\n",
        "    # Changed from LogisticRegression to SVC (Support Vector Classifier)\n",
        "    # Using RBF kernel which often works well for image classification\n",
        "    clf = SVC(kernel='rbf', probability=True, C=1.0, gamma='scale')\n",
        "    clf.fit(X_features_reshaped, y_labels)\n",
        "\n",
        "    # Verify the classifier is trained for the correct number of classes\n",
        "    n_classes = len(np.unique(y_labels))\n",
        "    print(f\"SVM Classifier trained for {n_classes} classes\")\n",
        "\n",
        "    # Calculate and return training accuracy\n",
        "    y_pred_train = clf.predict(X_features_reshaped)\n",
        "    train_accuracy = accuracy_score(y_labels, y_pred_train)\n",
        "    return clf, train_accuracy\n",
        "\n",
        "def cost_function(params, circuit, input_params, weight_params, x_batch, y_batch, backend):\n",
        "    cost = 0\n",
        "    # We need to iterate through each image in the batch.\n",
        "    for i in range(len(x_batch)):\n",
        "        # We need to process each patch for this image to calculate the cost.\n",
        "        image_patches = x_batch[i]\n",
        "        # Calculate cost for this image by averaging the cost over its patches.\n",
        "        image_cost = 0\n",
        "        for patch in image_patches:\n",
        "            # Create a dictionary binding each pixel value to its corresponding input parameter\n",
        "            param_dict = {input_params[j]: float(patch[j]) for j in range(4)}\n",
        "            # Add the weight parameters to the bindings dictionary\n",
        "            for j, param in enumerate(weight_params):\n",
        "                param_dict[param] = float(params[j])\n",
        "\n",
        "            counts = execute_circuit(circuit, param_dict, backend)\n",
        "            # Calculate expectation value for Z_3 Z_2\n",
        "            c00 = counts.get(\"00\", 0)\n",
        "            c01 = counts.get(\"01\", 0)\n",
        "            c10 = counts.get(\"10\", 0)\n",
        "            c11 = counts.get(\"11\", 0)\n",
        "            expectation = (c00 + c11 - c01 - c10) / 1024\n",
        "            image_cost += (1 - expectation)\n",
        "\n",
        "        # Average cost over all patches in the image\n",
        "        cost += image_cost / len(image_patches)\n",
        "\n",
        "    # Average cost over all images in the batch\n",
        "    return cost / len(x_batch)\n",
        "\n",
        "\n",
        "def train_qcnn(circuit, X_train, y_train, backend, maxiter=50):\n",
        "    all_params = list(circuit.parameters)\n",
        "    # Ensure there are at least 4 input parameters and some weight parameters\n",
        "    if len(all_params) < 5:\n",
        "         raise ValueError(\"Circuit must have at least 4 input parameters and 1 weight parameter.\")\n",
        "    input_params = all_params[:4]\n",
        "    weight_params = all_params[4:]\n",
        "    initial_params = np.random.rand(len(weight_params)) * 2 * np.pi - np.pi\n",
        "\n",
        "    cost_history = []\n",
        "\n",
        "    def callback_function(current_params):\n",
        "        current_cost = cost_function(current_params, circuit, input_params, weight_params, X_train, y_train, backend)\n",
        "        cost_history.append(current_cost)\n",
        "        print(f\"Current cost: {current_cost}\")\n",
        "\n",
        "    # Pass necessary parameters to the cost function\n",
        "    objective = lambda p: cost_function(p, circuit, input_params, weight_params, X_train, y_train, backend)\n",
        "    result = minimize(objective, initial_params, method='COBYLA', options={'maxiter': maxiter}, callback=callback_function)\n",
        "    return result.x, cost_history\n",
        "\n",
        "def ensemble_predict(X_test, circuits, param_list, classifiers, backend):\n",
        "    all_preds = []\n",
        "    for circuit, params, clf in zip(circuits, param_list, classifiers):\n",
        "        # extract_all_features returns a list of feature lists (one per image)\n",
        "        features = extract_all_features(X_test, circuit, params, backend)\n",
        "        # Convert features to a NumPy array for the classifier\n",
        "        features_array = np.array(features)\n",
        "        preds = clf.predict(features_array)\n",
        "        all_preds.append(preds)\n",
        "\n",
        "    final_preds = []\n",
        "    for i in range(len(X_test)):\n",
        "        votes = [model_preds[i] for model_preds in all_preds]\n",
        "\n",
        "        # Simple fix: convert to a list and use the most common value\n",
        "        votes_list = list(votes)\n",
        "        # Count occurrences of each value\n",
        "        from collections import Counter\n",
        "        most_common = Counter(votes_list).most_common(1)[0][0]\n",
        "        final_preds.append(most_common)\n",
        "\n",
        "    return final_preds\n",
        "\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred) * 100)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "def plot_cost_history(cost_history, title='QCNN Cost Function History', filename='cost_history.png'):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(cost_history, marker='o')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Optimization Iteration')\n",
        "    plt.ylabel('Cost')\n",
        "    plt.grid(True)\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "\n",
        "def plot_accuracy_history(accuracy_history, title='Classifier Training Accuracy', filename='training_accuracy.png'):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(range(len(accuracy_history)), [acc * 100 for acc in accuracy_history])\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Classifier Index')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.ylim(0, 100)\n",
        "    plt.grid(axis='y')\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "\n",
        "def main():\n",
        "    print(\"Starting 1-Qubit QCNN Ensemble for 5-Class Classification\")\n",
        "    X_train, y_train, X_test, y_test = prepare_dataset()\n",
        "\n",
        "    # Check the shapes of X_train and y_train\n",
        "    print(f\"Shape of X_train: {X_train.shape}\")\n",
        "    print(f\"Shape of y_train: {y_train.shape}\")\n",
        "\n",
        "    backend = Aer.get_backend('qasm_simulator')\n",
        "\n",
        "    circuit1 = create_qcnn_circuit_1()\n",
        "    circuit2 = create_qcnn_circuit_2()\n",
        "    circuit3 = create_qcnn_circuit_3()\n",
        "\n",
        "    all_cost_histories = []\n",
        "    all_training_accuracies = []\n",
        "\n",
        "    print(\"Training QCNN 1...\")\n",
        "    params1, cost_history1 = train_qcnn(circuit1, X_train, y_train, backend)\n",
        "    all_cost_histories.append(cost_history1)\n",
        "    print(\"Training QCNN 2...\")\n",
        "    params2, cost_history2 = train_qcnn(circuit2, X_train, y_train, backend)\n",
        "    all_cost_histories.append(cost_history2)\n",
        "    print(\"Training QCNN 3...\")\n",
        "    params3, cost_history3 = train_qcnn(circuit3, X_train, y_train, backend)\n",
        "    all_cost_histories.append(cost_history3)\n",
        "\n",
        "    print(\"Extracting features...\")\n",
        "    feat1 = extract_all_features(X_train, circuit1, params1, backend)\n",
        "    feat2 = extract_all_features(X_train, circuit2, params2, backend)\n",
        "    feat3 = extract_all_features(X_train, circuit3, params3, backend)\n",
        "\n",
        "    print(\"Training classifiers...\")\n",
        "    clf1, acc1 = train_classifier(feat1, y_train)\n",
        "    all_training_accuracies.append(acc1)\n",
        "    clf2, acc2 = train_classifier(feat2, y_train)\n",
        "    all_training_accuracies.append(acc2)\n",
        "    clf3, acc3 = train_classifier(feat3, y_train)\n",
        "    all_training_accuracies.append(acc3)\n",
        "\n",
        "    # Plotting cost histories\n",
        "    plot_cost_history(all_cost_histories[0], title='QCNN 1 Cost Function History', filename='cost_history_qcnn1.png')\n",
        "    plot_cost_history(all_cost_histories[1], title='QCNN 2 Cost Function History', filename='cost_history_qcnn2.png')\n",
        "    plot_cost_history(all_cost_histories[2], title='QCNN 3 Cost Function History', filename='cost_history_qcnn3.png')\n",
        "\n",
        "    # Plotting training accuracies\n",
        "    plot_accuracy_history(all_training_accuracies, title='Individual Classifier Training Accuracy', filename='training_accuracy_classifiers.png')\n",
        "\n",
        "    try:\n",
        "        with open('qcnn_ensemble_models.pkl', 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'params1': params1,\n",
        "                'params2': params2,\n",
        "                'params3': params3,\n",
        "                'clf1': clf1,\n",
        "                'clf2': clf2,\n",
        "                'clf3': clf3\n",
        "            }, f)\n",
        "        print(\"Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving models: {e}\")\n",
        "\n",
        "    print(\"Performing ensemble prediction...\")\n",
        "    final_preds = ensemble_predict(X_test, [circuit1, circuit2, circuit3], [params1, params2, params3], [clf1, clf2, clf3], backend)\n",
        "\n",
        "    print(\"Evaluating results...\")\n",
        "    evaluate(y_test, final_preds)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import qiskit\n",
        "    print(f\"Qiskit version: {qiskit.__version__}\")\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUNsxTDG_brx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqO2dlph_boY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2F041byx_bl9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8nCZGCU_bjc",
        "outputId": "7d13acfb-cf7f-46ce-ea03-c76d2fb678d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Qiskit version: 2.1.0\n",
            "Starting 1-Qubit QCNN Ensemble for 5-Class Classification\n",
            "Shape of X_train: (56, 576, 4)\n",
            "Shape of y_train: (56,)\n",
            "Training QCNN 1...\n",
            "Training QCNN 2...\n",
            "Training QCNN 3...\n",
            "Extracting features...\n",
            "Training classifiers...\n",
            "SVM Classifier trained for 7 classes\n",
            "SVM Classifier trained for 7 classes\n",
            "SVM Classifier trained for 7 classes\n",
            "Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\n",
            "Performing ensemble prediction...\n",
            "Evaluating results...\n",
            "Accuracy: 90.47619047619048\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      1.00      0.86         3\n",
            "           1       1.00      1.00      1.00         3\n",
            "           2       1.00      0.33      0.50         3\n",
            "           3       1.00      1.00      1.00         3\n",
            "           4       1.00      1.00      1.00         3\n",
            "           5       0.75      1.00      0.86         3\n",
            "           6       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.90        21\n",
            "   macro avg       0.93      0.90      0.89        21\n",
            "weighted avg       0.93      0.90      0.89        21\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import mode\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit_aer import Aer\n",
        "from qiskit.circuit import Parameter\n",
        "import pickle\n",
        "\n",
        "\n",
        "def prepare_dataset(dataset_path='/content/dataset'):\n",
        "    train_dir = os.path.join(dataset_path, 'train')\n",
        "    test_dir = os.path.join(dataset_path, 'test')\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    subjects = [f'subject{i:02d}' for i in range(1, 8)]\n",
        "    # Changed test_size to 2 to ensure 2 images per subject for testing\n",
        "    test_size_per_subject = 3\n",
        "\n",
        "    for subject in subjects:\n",
        "        all_items = [f for f in os.listdir(dataset_path)]\n",
        "        subject_files = [item for item in all_items if item.startswith(subject)]\n",
        "        # Ensure there are enough files for the split\n",
        "        if len(subject_files) < test_size_per_subject:\n",
        "            print(f\"Warning: Not enough files for subject {subject} to create test set. Skipping.\")\n",
        "            continue\n",
        "        train_files, test_files = train_test_split(subject_files, test_size=test_size_per_subject, random_state=42)\n",
        "\n",
        "        for file in train_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(train_dir, file))\n",
        "        for file in test_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(test_dir, file))\n",
        "\n",
        "    X_train, y_train = process_folder(train_dir)\n",
        "    X_test, y_test = process_folder(test_dir)\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "def process_folder(folder_path):\n",
        "    processed_images = []\n",
        "    labels = []\n",
        "    image_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path)]\n",
        "\n",
        "    subject_ids = set(os.path.basename(file).split('.')[0] for file in image_files)\n",
        "    subject_to_label = {subject: i for i, subject in enumerate(sorted(subject_ids))}\n",
        "\n",
        "    for file in image_files:\n",
        "        file_name = os.path.basename(file)\n",
        "        subject_id = file_name.split('.')[0]\n",
        "        label = subject_to_label[subject_id]\n",
        "\n",
        "        img = Image.open(file).convert('L').resize((48, 48))\n",
        "        img_array = np.array(img).astype(np.float32) / 255.0 * 2 * np.pi\n",
        "\n",
        "        patches = [img_array[i:i+2, j:j+2].flatten() for i in range(0, 48, 2) for j in range(0, 48, 2) if i+2 <= 48 and j+2 <= 48]\n",
        "        processed_images.append(patches)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(processed_images), np.array(labels)\n",
        "\n",
        "def create_qcnn_circuit_1():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'theta_conv1_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.cx(i, (i+1) % 4)\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.ry(Parameter('theta_conv2_0'), 2)\n",
        "    qc.ry(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.ry(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "def create_qcnn_circuit_2():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.rx(Parameter(f'theta_conv1_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.cx(i, (i+1) % 4)\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.rx(Parameter('theta_conv2_0'), 2)\n",
        "    qc.rx(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cz(2, 3)\n",
        "    qc.cz(3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.rx(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "def create_qcnn_circuit_3():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.rx(Parameter(f'theta_conv1_{i}'), i)\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(1, 2)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 0) # Circular entanglement\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.rx(Parameter('theta_conv2_0'), 2)\n",
        "    qc.rx(Parameter('theta_conv2_1'), 3)\n",
        "    qc.crx(Parameter('theta_crx_0'), 2, 3)\n",
        "    qc.crx(Parameter('theta_crx_1'), 3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.rx(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "\n",
        "def execute_circuit(circuit, parameters, backend):\n",
        "    # parameters is a dictionary of {Parameter: value}\n",
        "    bound = circuit.assign_parameters(parameters)\n",
        "    meas = QuantumCircuit(4, 2)\n",
        "    meas.compose(bound, inplace=True)\n",
        "    meas.measure([3, 2], [0, 1])\n",
        "    job = backend.run(meas, shots=1024)\n",
        "    result = job.result()\n",
        "    return result.get_counts()\n",
        "\n",
        "# Change this part in the extract_features_from_image function:\n",
        "def extract_features_from_image(image_patches, circuit, params, backend):\n",
        "    input_params = list(circuit.parameters)[:4]\n",
        "    weight_params = list(circuit.parameters)[4:]\n",
        "    features = []\n",
        "    for patch in image_patches:\n",
        "        bindings = {input_params[i]: float(patch[i]) for i in range(4)}\n",
        "        for i, param in enumerate(weight_params):\n",
        "            bindings[param] = float(params[i])\n",
        "\n",
        "        bound = circuit.assign_parameters(bindings)\n",
        "        meas_circuit = QuantumCircuit(4, 2)\n",
        "        meas_circuit.compose(bound, inplace=True)\n",
        "        meas_circuit.measure([3, 2], [0, 1])\n",
        "        job = backend.run(meas_circuit, shots=1024)\n",
        "        result = job.result()\n",
        "        counts = result.get_counts()\n",
        "        c00 = counts.get('00', 0)\n",
        "        c01 = counts.get('01', 0)\n",
        "        c10 = counts.get('10', 0)\n",
        "        c11 = counts.get('11', 0)\n",
        "        expectation = (c00 + c11 - c01 - c10) / 1024\n",
        "        features.append(expectation)\n",
        "    return features\n",
        "\n",
        "\n",
        "def extract_all_features(X, circuit, params, backend):\n",
        "    # X contains a list of images, where each image is a list of patches.\n",
        "    all_features = []\n",
        "    for image_patches in X:\n",
        "         # extract_features_from_image already handles all patches for a single image\n",
        "        image_features = extract_features_from_image(image_patches, circuit, params, backend)\n",
        "        all_features.append(image_features)\n",
        "    return all_features\n",
        "\n",
        "\n",
        "def train_classifier(X_features, y_labels):\n",
        "    X_features_reshaped = np.array(X_features) # This should create a (num_images, num_patches) array\n",
        "    clf = SVC(kernel='rbf', probability=True, C=1.0, gamma='scale')\n",
        "    clf.fit(X_features_reshaped, y_labels)\n",
        "\n",
        "    # Verify the classifier is trained for the correct number of classes\n",
        "    n_classes = len(np.unique(y_labels))\n",
        "    print(f\"SVM Classifier trained for {n_classes} classes\")\n",
        "\n",
        "    return clf\n",
        "\n",
        "def cost_function(params, circuit, input_params, weight_params, x_batch, y_batch, backend):\n",
        "    cost = 0\n",
        "    for i in range(len(x_batch)):\n",
        "        image_patches = x_batch[i]\n",
        "        image_cost = 0\n",
        "        for patch in image_patches:\n",
        "            param_dict = {input_params[j]: float(patch[j]) for j in range(4)}\n",
        "            for j, param in enumerate(weight_params):\n",
        "                param_dict[param] = float(params[j])\n",
        "\n",
        "            counts = execute_circuit(circuit, param_dict, backend)\n",
        "            # Calculate expectation value for Z_3 Z_2\n",
        "            c00 = counts.get(\"00\", 0)\n",
        "            c01 = counts.get(\"01\", 0)\n",
        "            c10 = counts.get(\"10\", 0)\n",
        "            c11 = counts.get(\"11\", 0)\n",
        "            expectation = (c00 + c11 - c01 - c10) / 1024\n",
        "            image_cost += (1 - expectation)\n",
        "\n",
        "        # Average cost over all patches in the image\n",
        "        cost += image_cost / len(image_patches)\n",
        "\n",
        "    # Average cost over all images in the batch\n",
        "    return cost / len(x_batch)\n",
        "\n",
        "\n",
        "def train_qcnn(circuit, X_train, y_train, backend, maxiter=50):\n",
        "    all_params = list(circuit.parameters)\n",
        "    # Ensure there are at least 4 input parameters and some weight parameters\n",
        "    if len(all_params) < 5:\n",
        "         raise ValueError(\"Circuit must have at least 4 input parameters and 1 weight parameter.\")\n",
        "    input_params = all_params[:4]\n",
        "    weight_params = all_params[4:]\n",
        "    initial_params = np.random.rand(len(weight_params)) * 2 * np.pi - np.pi\n",
        "    # Pass necessary parameters to the cost function\n",
        "    objective = lambda p: cost_function(p, circuit, input_params, weight_params, X_train, y_train, backend)\n",
        "    result = minimize(objective, initial_params, method='COBYLA', options={'maxiter': maxiter})\n",
        "    return result.x\n",
        "\n",
        "\n",
        "def ensemble_predict(X_test, circuits, param_list, classifiers, backend):\n",
        "    all_preds = []\n",
        "    all_probs = []\n",
        "\n",
        "    for circuit, params, clf in zip(circuits, param_list, classifiers):\n",
        "        # extract_all_features returns a list of feature lists (one per image)\n",
        "        features = extract_all_features(X_test, circuit, params, backend)\n",
        "        features_array = np.array(features)\n",
        "        preds = clf.predict(features_array)\n",
        "        probs = clf.predict_proba(features_array)  # Shape: (num_samples, num_classes)\n",
        "        all_preds.append(preds)\n",
        "        all_probs.append(probs)\n",
        "\n",
        "    final_preds = []\n",
        "    for i in range(len(X_test)):\n",
        "        votes = [model_preds[i] for model_preds in all_preds]\n",
        "        probs_for_sample = [model_probs[i] for model_probs in all_probs]  # list of np.arrays\n",
        "        from collections import Counter\n",
        "        vote_counts = Counter(votes)\n",
        "        # Check if we have a tie (3 unique votes)\n",
        "        if len(vote_counts) == 3:\n",
        "            # Resolve tie using highest confidence\n",
        "            best_class = None\n",
        "            best_conf = -1\n",
        "            for pred, prob_dist in zip(votes, probs_for_sample):\n",
        "                conf = prob_dist[pred]  # Get the confidence of the predicted class\n",
        "                if conf > best_conf:\n",
        "                    best_conf = conf\n",
        "                    best_class = pred\n",
        "            final_preds.append(best_class)\n",
        "        else:\n",
        "            # No tie, select majority class\n",
        "            most_common = vote_counts.most_common(1)[0][0]\n",
        "            final_preds.append(most_common)\n",
        "\n",
        "    return final_preds\n",
        "\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred) * 100)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "def main():\n",
        "    print(\"Starting 1-Qubit QCNN Ensemble for 5-Class Classification\")\n",
        "    X_train, y_train, X_test, y_test = prepare_dataset()\n",
        "\n",
        "    # Check the shapes of X_train and y_train\n",
        "    print(f\"Shape of X_train: {X_train.shape}\")\n",
        "    print(f\"Shape of y_train: {y_train.shape}\")\n",
        "\n",
        "    backend = Aer.get_backend('qasm_simulator')\n",
        "\n",
        "    circuit1 = create_qcnn_circuit_1()\n",
        "    circuit2 = create_qcnn_circuit_2()\n",
        "    circuit3 = create_qcnn_circuit_3()\n",
        "\n",
        "\n",
        "    print(\"Training QCNN 1...\")\n",
        "    params1 = train_qcnn(circuit1, X_train, y_train, backend)\n",
        "    print(\"Training QCNN 2...\")\n",
        "    params2 = train_qcnn(circuit2, X_train, y_train, backend)\n",
        "    print(\"Training QCNN 3...\")\n",
        "    params3 = train_qcnn(circuit3, X_train, y_train, backend)\n",
        "\n",
        "    print(\"Extracting features...\")\n",
        "    feat1 = extract_all_features(X_train, circuit1, params1, backend)\n",
        "    feat2 = extract_all_features(X_train, circuit2, params2, backend)\n",
        "    feat3 = extract_all_features(X_train, circuit3, params3, backend)\n",
        "\n",
        "    print(\"Training classifiers...\")\n",
        "    clf1 = train_classifier(feat1, y_train)\n",
        "    clf2 = train_classifier(feat2, y_train)\n",
        "    clf3 = train_classifier(feat3, y_train)\n",
        "\n",
        "    try:\n",
        "        with open('qcnn_ensemble_models.pkl', 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'params1': params1,\n",
        "                'params2': params2,\n",
        "                'params3': params3,\n",
        "                'clf1': clf1,\n",
        "                'clf2': clf2,\n",
        "                'clf3': clf3\n",
        "            }, f)\n",
        "        print(\"Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving models: {e}\")\n",
        "\n",
        "    print(\"Performing ensemble prediction...\")\n",
        "    final_preds = ensemble_predict(X_test, [circuit1, circuit2, circuit3], [params1, params2, params3], [clf1, clf2, clf3], backend)\n",
        "\n",
        "    print(\"Evaluating results...\")\n",
        "    evaluate(y_test, final_preds)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import qiskit\n",
        "    print(f\"Qiskit version: {qiskit.__version__}\")\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hkj9Vos0QX96"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final Code for Paper**"
      ],
      "metadata": {
        "id": "UdU_rBkhaMwm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yfeQ9_IQYmA",
        "outputId": "5c982922-2ff8-411a-f48a-b3438368b90e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Qiskit version: 2.1.0\n",
            "Starting 1-Qubit QCNN Ensemble for 5-Class Classification\n",
            "Shape of X_train: (56, 576, 4)\n",
            "Shape of y_train: (56,)\n",
            "Training QCNN 1...\n",
            "Training QCNN 2...\n",
            "Training QCNN 3...\n",
            "Extracting features...\n",
            "Training classifiers...\n",
            "SVM Classifier trained for 7 classes\n",
            "SVM Classifier trained for 7 classes\n",
            "SVM Classifier trained for 7 classes\n",
            "Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\n",
            "Performing ensemble prediction...\n",
            "Evaluating results...\n",
            "Accuracy: 95.23809523809523\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         3\n",
            "           1       1.00      1.00      1.00         3\n",
            "           2       1.00      0.67      0.80         3\n",
            "           3       0.75      1.00      0.86         3\n",
            "           4       1.00      1.00      1.00         3\n",
            "           5       1.00      1.00      1.00         3\n",
            "           6       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.95        21\n",
            "   macro avg       0.96      0.95      0.95        21\n",
            "weighted avg       0.96      0.95      0.95        21\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import mode\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit_aer import Aer\n",
        "from qiskit.circuit import Parameter\n",
        "import pickle\n",
        "\n",
        "\n",
        "def prepare_dataset(dataset_path='/content/dataset'):\n",
        "    train_dir = os.path.join(dataset_path, 'train')\n",
        "    test_dir = os.path.join(dataset_path, 'test')\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    subjects = [f'subject{i:02d}' for i in range(1, 8)]\n",
        "    # Changed test_size to 2 to ensure 2 images per subject for testing\n",
        "    test_size_per_subject = 3\n",
        "\n",
        "    for subject in subjects:\n",
        "        all_items = [f for f in os.listdir(dataset_path)]\n",
        "        subject_files = [item for item in all_items if item.startswith(subject)]\n",
        "        # Ensure there are enough files for the split\n",
        "        if len(subject_files) < test_size_per_subject:\n",
        "            print(f\"Warning: Not enough files for subject {subject} to create test set. Skipping.\")\n",
        "            continue\n",
        "        train_files, test_files = train_test_split(subject_files, test_size=test_size_per_subject, random_state=42)\n",
        "\n",
        "        for file in train_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(train_dir, file))\n",
        "        for file in test_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(test_dir, file))\n",
        "\n",
        "    X_train, y_train = process_folder(train_dir)\n",
        "    X_test, y_test = process_folder(test_dir)\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "def process_folder(folder_path):\n",
        "    processed_images = []\n",
        "    labels = []\n",
        "    image_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path)]\n",
        "\n",
        "    subject_ids = set(os.path.basename(file).split('.')[0] for file in image_files)\n",
        "    subject_to_label = {subject: i for i, subject in enumerate(sorted(subject_ids))}\n",
        "\n",
        "    for file in image_files:\n",
        "        file_name = os.path.basename(file)\n",
        "        subject_id = file_name.split('.')[0]\n",
        "        label = subject_to_label[subject_id]\n",
        "\n",
        "        img = Image.open(file).convert('L').resize((48, 48))\n",
        "        img_array = np.array(img).astype(np.float32) / 255.0 * 2 * np.pi\n",
        "\n",
        "        patches = [img_array[i:i+2, j:j+2].flatten() for i in range(0, 48, 2) for j in range(0, 48, 2) if i+2 <= 48 and j+2 <= 48]\n",
        "        processed_images.append(patches)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(processed_images), np.array(labels)\n",
        "\n",
        "def create_qcnn_circuit_1():\n",
        "    qc = QuantumCircuit(4)\n",
        "    # --- Encoding Layer ---\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 1 ---\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'theta_conv1_{i}'), i)\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(1, 2)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 0)\n",
        "    for i in range(4):\n",
        "        qc.rz(Parameter(f'phi_conv1_{i}'), i)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 1 ---\n",
        "    qc.crx(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.crx(Parameter('theta_pool1_1'), 1, 3)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 2 ---\n",
        "    qc.ry(Parameter('theta_conv2_0'), 2)\n",
        "    qc.ry(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cz(2, 3)\n",
        "    qc.rz(Parameter('phi_conv2_0'), 2)\n",
        "    qc.rz(Parameter('phi_conv2_1'), 3)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 2 ---\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.ry(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "def create_qcnn_circuit_2():\n",
        "    qc = QuantumCircuit(4)\n",
        "    # --- Encoding Layer ---\n",
        "    for i in range(4):\n",
        "        qc.h(i)\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 1 ---\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(2, 3)\n",
        "    qc.ry(Parameter('theta_conv1_0'), 0)\n",
        "    qc.ry(Parameter('theta_conv1_1'), 2)\n",
        "    qc.ccx(0, 2, 1)\n",
        "    qc.ry(Parameter('theta_conv1_2'), 1)\n",
        "    qc.ccx(1, 2, 3)\n",
        "    qc.ry(Parameter('theta_conv1_3'), 3)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 1 ---\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 1)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 2, 3)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 2 ---\n",
        "    qc.ry(Parameter('theta_conv2_0'), 1)\n",
        "    qc.ry(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.rz(Parameter('phi_conv2_0'), 1)\n",
        "    qc.rz(Parameter('phi_conv2_1'), 3)\n",
        "    qc.barrier()\n",
        "    # --- Final Measurement Prep ---\n",
        "    qc.ry(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "def create_qcnn_circuit_3():\n",
        "    qc = QuantumCircuit(4)\n",
        "    # --- Encoding Layer ---\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 1 ---\n",
        "    qc.ry(Parameter('theta_conv1_0'), 0)\n",
        "    qc.rz(Parameter('phi_conv1_0'), 0)\n",
        "    qc.ry(Parameter('theta_conv1_1'), 1)\n",
        "    qc.rz(Parameter('phi_conv1_1'), 1)\n",
        "    qc.ry(Parameter('theta_conv1_2'), 2)\n",
        "    qc.rz(Parameter('phi_conv1_2'), 2)\n",
        "    qc.ry(Parameter('theta_conv1_3'), 3)\n",
        "    qc.rz(Parameter('phi_conv1_3'), 3)\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(1, 2)\n",
        "    qc.cx(2, 3)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 1 ---\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 1)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 2, 3)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 2 ---\n",
        "    qc.ry(Parameter('theta_conv2_0'), 1)\n",
        "    qc.rz(Parameter('phi_conv2_0'), 1)\n",
        "    qc.ry(Parameter('theta_conv2_1'), 3)\n",
        "    qc.rz(Parameter('phi_conv2_1'), 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 2 ---\n",
        "    qc.crx(Parameter('theta_pool2_0'), 1, 3)\n",
        "    qc.barrier()\n",
        "    # --- Final Measurement Prep ---\n",
        "    qc.ry(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "\n",
        "def execute_circuit(circuit, parameters, backend):\n",
        "    # parameters is a dictionary of {Parameter: value}\n",
        "    bound = circuit.assign_parameters(parameters)\n",
        "    meas = QuantumCircuit(4, 2)\n",
        "    meas.compose(bound, inplace=True)\n",
        "    meas.measure([3, 2], [0, 1])\n",
        "    job = backend.run(meas, shots=1024)\n",
        "    result = job.result()\n",
        "    return result.get_counts()\n",
        "\n",
        "# Change this part in the extract_features_from_image function:\n",
        "def extract_features_from_image(image_patches, circuit, params, backend):\n",
        "    input_params = list(circuit.parameters)[:4]\n",
        "    weight_params = list(circuit.parameters)[4:]\n",
        "    features = []\n",
        "    for patch in image_patches:\n",
        "        bindings = {input_params[i]: float(patch[i]) for i in range(4)}\n",
        "        for i, param in enumerate(weight_params):\n",
        "            bindings[param] = float(params[i])\n",
        "\n",
        "        bound = circuit.assign_parameters(bindings)\n",
        "        meas_circuit = QuantumCircuit(4, 2)\n",
        "        meas_circuit.compose(bound, inplace=True)\n",
        "        meas_circuit.measure([3, 2], [0, 1])\n",
        "        job = backend.run(meas_circuit, shots=1024)\n",
        "        result = job.result()\n",
        "        counts = result.get_counts()\n",
        "        c00 = counts.get('00', 0)\n",
        "        c01 = counts.get('01', 0)\n",
        "        c10 = counts.get('10', 0)\n",
        "        c11 = counts.get('11', 0)\n",
        "        expectation = (c00 + c11 - c01 - c10) / 1024\n",
        "        features.append(expectation)\n",
        "    return features\n",
        "\n",
        "\n",
        "def extract_all_features(X, circuit, params, backend):\n",
        "    # X contains a list of images, where each image is a list of patches.\n",
        "    all_features = []\n",
        "    for image_patches in X:\n",
        "         # extract_features_from_image already handles all patches for a single image\n",
        "        image_features = extract_features_from_image(image_patches, circuit, params, backend)\n",
        "        all_features.append(image_features)\n",
        "    return all_features\n",
        "\n",
        "\n",
        "def train_classifier(X_features, y_labels):\n",
        "    X_features_reshaped = np.array(X_features) # This should create a (num_images, num_patches) array\n",
        "    clf = SVC(kernel='rbf', probability=True, C=1.0, gamma='scale')\n",
        "    clf.fit(X_features_reshaped, y_labels)\n",
        "\n",
        "    # Verify the classifier is trained for the correct number of classes\n",
        "    n_classes = len(np.unique(y_labels))\n",
        "    print(f\"SVM Classifier trained for {n_classes} classes\")\n",
        "\n",
        "    return clf\n",
        "\n",
        "def cost_function(params, circuit, input_params, weight_params, x_batch, y_batch, backend):\n",
        "    cost = 0\n",
        "    for i in range(len(x_batch)):\n",
        "        image_patches = x_batch[i]\n",
        "        image_cost = 0\n",
        "        for patch in image_patches:\n",
        "            param_dict = {input_params[j]: float(patch[j]) for j in range(4)}\n",
        "            for j, param in enumerate(weight_params):\n",
        "                param_dict[param] = float(params[j])\n",
        "\n",
        "            counts = execute_circuit(circuit, param_dict, backend)\n",
        "            # Calculate expectation value for Z_3 Z_2\n",
        "            c00 = counts.get(\"00\", 0)\n",
        "            c01 = counts.get(\"01\", 0)\n",
        "            c10 = counts.get(\"10\", 0)\n",
        "            c11 = counts.get(\"11\", 0)\n",
        "            expectation = (c00 + c11 - c01 - c10) / 1024\n",
        "            image_cost += (1 - expectation)\n",
        "\n",
        "        # Average cost over all patches in the image\n",
        "        cost += image_cost / len(image_patches)\n",
        "\n",
        "    # Average cost over all images in the batch\n",
        "    return cost / len(x_batch)\n",
        "\n",
        "\n",
        "def train_qcnn(circuit, X_train, y_train, backend, maxiter=50):\n",
        "    all_params = list(circuit.parameters)\n",
        "    # Ensure there are at least 4 input parameters and some weight parameters\n",
        "    if len(all_params) < 5:\n",
        "         raise ValueError(\"Circuit must have at least 4 input parameters and 1 weight parameter.\")\n",
        "    input_params = all_params[:4]\n",
        "    weight_params = all_params[4:]\n",
        "    initial_params = np.random.rand(len(weight_params)) * 2 * np.pi - np.pi\n",
        "    # Pass necessary parameters to the cost function\n",
        "    objective = lambda p: cost_function(p, circuit, input_params, weight_params, X_train, y_train, backend)\n",
        "    result = minimize(objective, initial_params, method='COBYLA', options={'maxiter': maxiter})\n",
        "    return result.x\n",
        "\n",
        "\n",
        "def ensemble_predict(X_test, circuits, param_list, classifiers, backend):\n",
        "    all_preds = []\n",
        "    all_probs = []\n",
        "\n",
        "    for circuit, params, clf in zip(circuits, param_list, classifiers):\n",
        "        # extract_all_features returns a list of feature lists (one per image)\n",
        "        features = extract_all_features(X_test, circuit, params, backend)\n",
        "        features_array = np.array(features)\n",
        "        preds = clf.predict(features_array)\n",
        "        probs = clf.predict_proba(features_array)  # Shape: (num_samples, num_classes)\n",
        "        all_preds.append(preds)\n",
        "        all_probs.append(probs)\n",
        "\n",
        "    final_preds = []\n",
        "    for i in range(len(X_test)):\n",
        "        votes = [model_preds[i] for model_preds in all_preds]\n",
        "        probs_for_sample = [model_probs[i] for model_probs in all_probs]  # list of np.arrays\n",
        "        from collections import Counter\n",
        "        vote_counts = Counter(votes)\n",
        "        # Check if we have a tie (3 unique votes)\n",
        "        if len(vote_counts) == 3:\n",
        "            # Resolve tie using highest confidence\n",
        "            best_class = None\n",
        "            best_conf = -1\n",
        "            for pred, prob_dist in zip(votes, probs_for_sample):\n",
        "                conf = prob_dist[pred]  # Get the confidence of the predicted class\n",
        "                if conf > best_conf:\n",
        "                    best_conf = conf\n",
        "                    best_class = pred\n",
        "            final_preds.append(best_class)\n",
        "        else:\n",
        "            # No tie, select majority class\n",
        "            most_common = vote_counts.most_common(1)[0][0]\n",
        "            final_preds.append(most_common)\n",
        "\n",
        "    return final_preds\n",
        "\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred) * 100)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "def main():\n",
        "    print(\"Starting 1-Qubit QCNN Ensemble for 5-Class Classification\")\n",
        "    X_train, y_train, X_test, y_test = prepare_dataset()\n",
        "\n",
        "    # Check the shapes of X_train and y_train\n",
        "    print(f\"Shape of X_train: {X_train.shape}\")\n",
        "    print(f\"Shape of y_train: {y_train.shape}\")\n",
        "\n",
        "    backend = Aer.get_backend('qasm_simulator')\n",
        "\n",
        "    circuit1 = create_qcnn_circuit_1()\n",
        "    circuit2 = create_qcnn_circuit_2()\n",
        "    circuit3 = create_qcnn_circuit_3()\n",
        "\n",
        "\n",
        "    print(\"Training QCNN 1...\")\n",
        "    params1 = train_qcnn(circuit1, X_train, y_train, backend)\n",
        "    print(\"Training QCNN 2...\")\n",
        "    params2 = train_qcnn(circuit2, X_train, y_train, backend)\n",
        "    print(\"Training QCNN 3...\")\n",
        "    params3 = train_qcnn(circuit3, X_train, y_train, backend)\n",
        "\n",
        "    print(\"Extracting features...\")\n",
        "    feat1 = extract_all_features(X_train, circuit1, params1, backend)\n",
        "    feat2 = extract_all_features(X_train, circuit2, params2, backend)\n",
        "    feat3 = extract_all_features(X_train, circuit3, params3, backend)\n",
        "\n",
        "    print(\"Training classifiers...\")\n",
        "    clf1 = train_classifier(feat1, y_train)\n",
        "    clf2 = train_classifier(feat2, y_train)\n",
        "    clf3 = train_classifier(feat3, y_train)\n",
        "\n",
        "    try:\n",
        "        with open('qcnn_ensemble_models.pkl', 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'params1': params1,\n",
        "                'params2': params2,\n",
        "                'params3': params3,\n",
        "                'clf1': clf1,\n",
        "                'clf2': clf2,\n",
        "                'clf3': clf3\n",
        "            }, f)\n",
        "        print(\"Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving models: {e}\")\n",
        "\n",
        "    print(\"Performing ensemble prediction...\")\n",
        "    final_preds = ensemble_predict(X_test, [circuit1, circuit2, circuit3], [params1, params2, params3], [clf1, clf2, clf3], backend)\n",
        "\n",
        "    print(\"Evaluating results...\")\n",
        "    evaluate(y_test, final_preds)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import qiskit\n",
        "    print(f\"Qiskit version: {qiskit.__version__}\")\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lb9BA4qWCiu6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import mode\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit_aer import Aer\n",
        "from qiskit.circuit import Parameter\n",
        "import pickle\n",
        "\n",
        "EPS = 1e-12  # numerical stability for log\n",
        "\n",
        "\n",
        "def prepare_dataset(dataset_path='/content/dataset'):\n",
        "    train_dir = os.path.join(dataset_path, 'train')\n",
        "    test_dir = os.path.join(dataset_path, 'test')\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    subjects = [f'subject{i:02d}' for i in range(1, 8)]\n",
        "    # Changed test_size to 3 to ensure 3 images per subject for testing\n",
        "    test_size_per_subject = 3\n",
        "\n",
        "    for subject in subjects:\n",
        "        all_items = [f for f in os.listdir(dataset_path)]\n",
        "        subject_files = [item for item in all_items if item.startswith(subject)]\n",
        "        # Ensure there are enough files for the split\n",
        "        if len(subject_files) < test_size_per_subject:\n",
        "            print(f\"Warning: Not enough files for subject {subject} to create test set. Skipping.\")\n",
        "            continue\n",
        "        train_files, test_files = train_test_split(subject_files, test_size=test_size_per_subject, random_state=42)\n",
        "\n",
        "        for file in train_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(train_dir, file))\n",
        "        for file in test_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(test_dir, file))\n",
        "\n",
        "    X_train, y_train = process_folder(train_dir)\n",
        "    X_test, y_test = process_folder(test_dir)\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "\n",
        "def process_folder(folder_path):\n",
        "    processed_images = []\n",
        "    labels = []\n",
        "    image_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path)]\n",
        "\n",
        "    subject_ids = set(os.path.basename(file).split('.')[0] for file in image_files)\n",
        "    subject_to_label = {subject: i for i, subject in enumerate(sorted(subject_ids))}\n",
        "\n",
        "    for file in image_files:\n",
        "        file_name = os.path.basename(file)\n",
        "        subject_id = file_name.split('.')[0]\n",
        "        label = subject_to_label[subject_id]\n",
        "\n",
        "        img = Image.open(file).convert('L').resize((48, 48))\n",
        "        img_array = np.array(img).astype(np.float32) / 255.0 * 2 * np.pi\n",
        "\n",
        "        patches = [img_array[i:i+2, j:j+2].flatten() for i in range(0, 48, 2) for j in range(0, 48, 2) if i+2 <= 48 and j+2 <= 48]\n",
        "        processed_images.append(patches)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(processed_images), np.array(labels)\n",
        "\n",
        "\n",
        "def create_qcnn_circuit_1():\n",
        "    qc = QuantumCircuit(4)\n",
        "    # --- Encoding Layer ---\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 1 ---\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'theta_conv1_{i}'), i)\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(1, 2)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 0)\n",
        "    for i in range(4):\n",
        "        qc.rz(Parameter(f'phi_conv1_{i}'), i)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 1 ---\n",
        "    qc.crx(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.crx(Parameter('theta_pool1_1'), 1, 3)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 2 ---\n",
        "    qc.ry(Parameter('theta_conv2_0'), 2)\n",
        "    qc.ry(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cz(2, 3)\n",
        "    qc.rz(Parameter('phi_conv2_0'), 2)\n",
        "    qc.rz(Parameter('phi_conv2_1'), 3)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 2 ---\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.ry(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "\n",
        "def create_qcnn_circuit_2():\n",
        "    qc = QuantumCircuit(4)\n",
        "    # --- Encoding Layer ---\n",
        "    for i in range(4):\n",
        "        qc.h(i)\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 1 ---\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(2, 3)\n",
        "    qc.ry(Parameter('theta_conv1_0'), 0)\n",
        "    qc.ry(Parameter('theta_conv1_1'), 2)\n",
        "    qc.ccx(0, 2, 1)\n",
        "    qc.ry(Parameter('theta_conv1_2'), 1)\n",
        "    qc.ccx(1, 2, 3)\n",
        "    qc.ry(Parameter('theta_conv1_3'), 3)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 1 ---\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 1)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 2, 3)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 2 ---\n",
        "    qc.ry(Parameter('theta_conv2_0'), 1)\n",
        "    qc.ry(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.rz(Parameter('phi_conv2_0'), 1)\n",
        "    qc.rz(Parameter('phi_conv2_1'), 3)\n",
        "    qc.barrier()\n",
        "    # --- Final Measurement Prep ---\n",
        "    qc.ry(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "\n",
        "def create_qcnn_circuit_3():\n",
        "    qc = QuantumCircuit(4)\n",
        "    # --- Encoding Layer ---\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 1 ---\n",
        "    qc.ry(Parameter('theta_conv1_0'), 0)\n",
        "    qc.rz(Parameter('phi_conv1_0'), 0)\n",
        "    qc.ry(Parameter('theta_conv1_1'), 1)\n",
        "    qc.rz(Parameter('phi_conv1_1'), 1)\n",
        "    qc.ry(Parameter('theta_conv1_2'), 2)\n",
        "    qc.rz(Parameter('phi_conv1_2'), 2)\n",
        "    qc.ry(Parameter('theta_conv1_3'), 3)\n",
        "    qc.rz(Parameter('phi_conv1_3'), 3)\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(1, 2)\n",
        "    qc.cx(2, 3)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 1 ---\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 1)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 2, 3)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 2 ---\n",
        "    qc.ry(Parameter('theta_conv2_0'), 1)\n",
        "    qc.rz(Parameter('phi_conv2_0'), 1)\n",
        "    qc.ry(Parameter('theta_conv2_1'), 3)\n",
        "    qc.rz(Parameter('phi_conv2_1'), 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 2 ---\n",
        "    qc.crx(Parameter('theta_pool2_0'), 1, 3)\n",
        "    qc.barrier()\n",
        "    # --- Final Measurement Prep ---\n",
        "    qc.ry(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "\n",
        "def execute_circuit(circuit, parameters, backend):\n",
        "    # parameters is a dictionary of {Parameter: value}\n",
        "    bound = circuit.assign_parameters(parameters)\n",
        "    meas = QuantumCircuit(4, 2)\n",
        "    meas.compose(bound, inplace=True)\n",
        "    meas.measure([3, 2], [0, 1])\n",
        "    job = backend.run(meas, shots=1024)\n",
        "    result = job.result()\n",
        "    return result.get_counts()\n",
        "\n",
        "\n",
        "def extract_features_from_image(image_patches, circuit, params, backend):\n",
        "    input_params = list(circuit.parameters)[:4]\n",
        "    weight_params = list(circuit.parameters)[4:]\n",
        "    features = []\n",
        "    for patch in image_patches:\n",
        "        bindings = {input_params[i]: float(patch[i]) for i in range(4)}\n",
        "        # reuse same weight params for all patches (as earlier)\n",
        "        for i, param in enumerate(weight_params):\n",
        "            bindings[param] = float(params[i])\n",
        "\n",
        "        bound = circuit.assign_parameters(bindings)\n",
        "        meas_circuit = QuantumCircuit(4, 2)\n",
        "        meas_circuit.compose(bound, inplace=True)\n",
        "        meas_circuit.measure([3, 2], [0, 1])\n",
        "        job = backend.run(meas_circuit, shots=1024)\n",
        "        result = job.result()\n",
        "        counts = result.get_counts()\n",
        "        c00 = counts.get('00', 0)\n",
        "        c01 = counts.get('01', 0)\n",
        "        c10 = counts.get('10', 0)\n",
        "        c11 = counts.get('11', 0)\n",
        "        expectation = (c00 + c11 - c01 - c10) / 1024\n",
        "        features.append(expectation)\n",
        "    return features\n",
        "\n",
        "\n",
        "def extract_all_features(X, circuit, params, backend):\n",
        "    # X contains a list/array of images, where each image is a list of patches.\n",
        "    all_features = []\n",
        "    for image_patches in X:\n",
        "        image_features = extract_features_from_image(image_patches, circuit, params, backend)\n",
        "        all_features.append(image_features)\n",
        "    return all_features\n",
        "\n",
        "\n",
        "def train_classifier(X_features, y_labels):\n",
        "    X_features_reshaped = np.array(X_features)  # (num_images, num_patches)\n",
        "    clf = SVC(kernel='rbf', probability=True, C=1.0, gamma='scale')\n",
        "    clf.fit(X_features_reshaped, y_labels)\n",
        "\n",
        "    n_classes = len(np.unique(y_labels))\n",
        "    print(f\"SVM Classifier trained for {n_classes} classes\")\n",
        "\n",
        "    return clf\n",
        "\n",
        "\n",
        "def _cross_entropy_from_probs(probs, y_true):\n",
        "    \"\"\"\n",
        "    probs: np.array shape (n_samples, n_classes)\n",
        "    y_true: array shape (n_samples,)\n",
        "    \"\"\"\n",
        "    n = probs.shape[0]\n",
        "    # clamp\n",
        "    clipped = np.clip(probs, EPS, 1.0)\n",
        "    log_probs = np.log(clipped)\n",
        "    # pick log prob of true class\n",
        "    true_log = log_probs[np.arange(n), y_true]\n",
        "    return -np.mean(true_log)\n",
        "\n",
        "\n",
        "def train_qcnn_supervised(circuit, X_train, y_train, backend, maxiter=50, verbose=False):\n",
        "    \"\"\"\n",
        "    Supervised training of the QCNN parameters using SVM classification loss (cross-entropy).\n",
        "    For a given parameter vector p:\n",
        "      - extract features for every train sample using the QCNN with params p\n",
        "      - train an SVM on those features\n",
        "      - compute cross-entropy loss of SVM predictions on the training set\n",
        "    Then minimize that loss w.r.t. p.\n",
        "    \"\"\"\n",
        "    all_params = list(circuit.parameters)\n",
        "    if len(all_params) < 5:\n",
        "        raise ValueError(\"Circuit must have at least 4 input parameters and 1 weight parameter.\")\n",
        "    input_params = all_params[:4]\n",
        "    weight_params = all_params[4:]\n",
        "\n",
        "    n_weight = len(weight_params)\n",
        "    initial_params = np.random.rand(n_weight) * 2 * np.pi - np.pi\n",
        "\n",
        "    # Precompute shapes\n",
        "    n_samples = len(X_train)\n",
        "    # objective that will be minimized\n",
        "    def objective(p):\n",
        "        # p is an array of length n_weight\n",
        "        # extract features using these params\n",
        "        features = extract_all_features(X_train, circuit, p, backend)  # list of lists\n",
        "        features_array = np.array(features)  # (n_samples, n_patches)\n",
        "        # train SVM on these features\n",
        "        clf = SVC(kernel='rbf', probability=True, C=1.0, gamma='scale')\n",
        "        try:\n",
        "            clf.fit(features_array, y_train)\n",
        "        except Exception as e:\n",
        "            # in case SVM fails due to degenerate features, return a large loss\n",
        "            if verbose:\n",
        "                print(\"SVM fit failed inside objective:\", e)\n",
        "            return 1e3\n",
        "\n",
        "        # predict probabilities on the same training set\n",
        "        try:\n",
        "            probs = clf.predict_proba(features_array)  # (n_samples, n_classes)\n",
        "        except Exception as e:\n",
        "            if verbose:\n",
        "                print(\"predict_proba failed:\", e)\n",
        "            return 1e3\n",
        "\n",
        "        # If number of classes predicted is less than expected,\n",
        "        # we need to expand probs with tiny probabilities for missing classes.\n",
        "        # But sklearn's predict_proba returns columns only for classes seen in training.\n",
        "        # Build full-prob matrix aligned to sorted unique classes\n",
        "        classes_seen = clf.classes_\n",
        "        n_classes_seen = len(classes_seen)\n",
        "        unique_classes = np.unique(y_train)\n",
        "        n_classes = len(unique_classes)\n",
        "        if n_classes_seen != n_classes:\n",
        "            # build expanded probs\n",
        "            expanded = np.full((probs.shape[0], n_classes), EPS)\n",
        "            class_to_idx = {c: i for i, c in enumerate(unique_classes)}\n",
        "            for j, c in enumerate(classes_seen):\n",
        "                expanded[:, class_to_idx[c]] = probs[:, j]\n",
        "            probs = expanded\n",
        "\n",
        "        loss = _cross_entropy_from_probs(probs, y_train)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Objective called, loss={loss:.6f}\")\n",
        "        return loss\n",
        "\n",
        "    # run classical optimizer\n",
        "    if verbose:\n",
        "        print(\"Starting supervised QCNN optimization (this may take a while)...\")\n",
        "    result = minimize(objective, initial_params, method='COBYLA', options={'maxiter': maxiter})\n",
        "    if verbose:\n",
        "        print(\"Optimization finished. success:\", result.success, \"message:\", result.message)\n",
        "    return result.x\n",
        "\n",
        "\n",
        "def ensemble_predict(X_test, circuits, param_list, classifiers, backend):\n",
        "    all_preds = []\n",
        "    all_probs = []\n",
        "\n",
        "    for circuit, params, clf in zip(circuits, param_list, classifiers):\n",
        "        # extract_all_features returns a list of feature lists (one per image)\n",
        "        features = extract_all_features(X_test, circuit, params, backend)\n",
        "        features_array = np.array(features)\n",
        "        preds = clf.predict(features_array)\n",
        "        try:\n",
        "            probs = clf.predict_proba(features_array)  # Shape: (num_samples, num_classes)\n",
        "        except Exception:\n",
        "            # fallback: create pseudo-probs from decision function (not ideal)\n",
        "            probs = np.zeros((features_array.shape[0], len(np.unique(clf.classes_))))\n",
        "            for i, pr in enumerate(preds):\n",
        "                probs[i, pr] = 1.0\n",
        "        all_preds.append(preds)\n",
        "        all_probs.append(probs)\n",
        "\n",
        "    final_preds = []\n",
        "    for i in range(len(X_test)):\n",
        "        votes = [model_preds[i] for model_preds in all_preds]\n",
        "        probs_for_sample = [model_probs[i] for model_probs in all_probs]  # list of np.arrays\n",
        "        from collections import Counter\n",
        "        vote_counts = Counter(votes)\n",
        "        # Check if we have a tie (3 unique votes)\n",
        "        if len(vote_counts) == 3:\n",
        "            # Resolve tie using highest confidence\n",
        "            best_class = None\n",
        "            best_conf = -1\n",
        "            for pred, prob_dist in zip(votes, probs_for_sample):\n",
        "                conf = prob_dist[pred]  # Get the confidence of the predicted class\n",
        "                if conf > best_conf:\n",
        "                    best_conf = conf\n",
        "                    best_class = pred\n",
        "            final_preds.append(best_class)\n",
        "        else:\n",
        "            # No tie, select majority class\n",
        "            most_common = vote_counts.most_common(1)[0][0]\n",
        "            final_preds.append(most_common)\n",
        "\n",
        "    return final_preds\n",
        "\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred) * 100)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"Starting supervised QCNN + SVM Ensemble for multi-class classification\")\n",
        "    X_train, y_train, X_test, y_test = prepare_dataset()\n",
        "\n",
        "    # Check the shapes of X_train and y_train\n",
        "    print(f\"Shape of X_train: {X_train.shape}\")\n",
        "    print(f\"Shape of y_train: {y_train.shape}\")\n",
        "\n",
        "    backend = Aer.get_backend('qasm_simulator')\n",
        "\n",
        "    circuit1 = create_qcnn_circuit_1()\n",
        "    circuit2 = create_qcnn_circuit_2()\n",
        "    circuit3 = create_qcnn_circuit_3()\n",
        "\n",
        "    print(\"Supervised training QCNN 1...\")\n",
        "    params1 = train_qcnn_supervised(circuit1, X_train, y_train, backend, maxiter=50, verbose=True)\n",
        "    print(\"Supervised training QCNN 2...\")\n",
        "    params2 = train_qcnn_supervised(circuit2, X_train, y_train, backend, maxiter=50, verbose=True)\n",
        "    print(\"Supervised training QCNN 3...\")\n",
        "    params3 = train_qcnn_supervised(circuit3, X_train, y_train, backend, maxiter=50, verbose=True)\n",
        "\n",
        "    print(\"Extracting features for training SVMs...\")\n",
        "    feat1 = extract_all_features(X_train, circuit1, params1, backend)\n",
        "    feat2 = extract_all_features(X_train, circuit2, params2, backend)\n",
        "    feat3 = extract_all_features(X_train, circuit3, params3, backend)\n",
        "\n",
        "    print(\"Training classifiers...\")\n",
        "    clf1 = train_classifier(feat1, y_train)\n",
        "    clf2 = train_classifier(feat2, y_train)\n",
        "    clf3 = train_classifier(feat3, y_train)\n",
        "\n",
        "    try:\n",
        "        with open('qcnn_ensemble_models.pkl', 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'params1': params1,\n",
        "                'params2': params2,\n",
        "                'params3': params3,\n",
        "                'clf1': clf1,\n",
        "                'clf2': clf2,\n",
        "                'clf3': clf3\n",
        "            }, f)\n",
        "        print(\"Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving models: {e}\")\n",
        "\n",
        "    print(\"Performing ensemble prediction...\")\n",
        "    final_preds = ensemble_predict(X_test, [circuit1, circuit2, circuit3], [params1, params2, params3], [clf1, clf2, clf3],\n",
        "                                   backend)\n",
        "\n",
        "    print(\"Evaluating results...\")\n",
        "    evaluate(y_test, final_preds)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import qiskit\n",
        "    print(f\"Qiskit version: {qiskit.__version__}\")\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXiJlVOBbUp9",
        "outputId": "9b95e254-07f2-4836-e6f5-909c20502c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qiskit version: 2.1.1\n",
            "Starting supervised QCNN + SVM Ensemble for multi-class classification\n",
            "Shape of X_train: (56, 576, 4)\n",
            "Shape of y_train: (56,)\n",
            "Supervised training QCNN 1...\n",
            "Starting supervised QCNN optimization (this may take a while)...\n",
            "Objective called, loss=3.572740\n",
            "Objective called, loss=3.599008\n",
            "Objective called, loss=3.660304\n",
            "Objective called, loss=3.753461\n",
            "Objective called, loss=4.594738\n",
            "Objective called, loss=0.989396\n",
            "Objective called, loss=0.559107\n",
            "Objective called, loss=0.447581\n",
            "Objective called, loss=3.185979\n",
            "Objective called, loss=0.451375\n",
            "Objective called, loss=0.423435\n",
            "Objective called, loss=0.234813\n",
            "Objective called, loss=0.177301\n",
            "Objective called, loss=0.210377\n",
            "Objective called, loss=0.154409\n",
            "Objective called, loss=0.501359\n",
            "Objective called, loss=0.500558\n",
            "Objective called, loss=0.345219\n",
            "Objective called, loss=0.096200\n",
            "Objective called, loss=0.195280\n",
            "Objective called, loss=0.331523\n",
            "Objective called, loss=0.059637\n",
            "Objective called, loss=2.701430\n",
            "Objective called, loss=4.753443\n",
            "Objective called, loss=0.101083\n",
            "Objective called, loss=0.094521\n",
            "Objective called, loss=1.591848\n",
            "Objective called, loss=2.488962\n",
            "Objective called, loss=0.050306\n",
            "Objective called, loss=4.249949\n",
            "Objective called, loss=0.157372\n",
            "Objective called, loss=0.073385\n",
            "Objective called, loss=0.102225\n",
            "Objective called, loss=0.927293\n",
            "Objective called, loss=0.282617\n",
            "Objective called, loss=0.184822\n",
            "Objective called, loss=0.041266\n",
            "Objective called, loss=1.977124\n",
            "Objective called, loss=0.214457\n",
            "Objective called, loss=1.141762\n",
            "Objective called, loss=0.071663\n",
            "Objective called, loss=0.078006\n",
            "Objective called, loss=0.043448\n",
            "Objective called, loss=0.414491\n",
            "Objective called, loss=0.116201\n",
            "Objective called, loss=0.060486\n",
            "Objective called, loss=0.033120\n",
            "Objective called, loss=0.133049\n",
            "Objective called, loss=0.115365\n",
            "Objective called, loss=0.099809\n",
            "Optimization finished. success: False message: Return from COBYLA because the objective function has been evaluated MAXFUN times.\n",
            "Supervised training QCNN 2...\n",
            "Starting supervised QCNN optimization (this may take a while)...\n",
            "Objective called, loss=0.327417\n",
            "Objective called, loss=0.368792\n",
            "Objective called, loss=0.458999\n",
            "Objective called, loss=0.311042\n",
            "Objective called, loss=0.507164\n",
            "Objective called, loss=0.577247\n",
            "Objective called, loss=0.482435\n",
            "Objective called, loss=0.525401\n",
            "Objective called, loss=0.470984\n",
            "Objective called, loss=0.409943\n",
            "Objective called, loss=0.269183\n",
            "Objective called, loss=0.238717\n",
            "Objective called, loss=0.552242\n",
            "Objective called, loss=0.366835\n",
            "Objective called, loss=0.508281\n",
            "Objective called, loss=0.290258\n",
            "Objective called, loss=0.245269\n",
            "Objective called, loss=0.232862\n",
            "Objective called, loss=0.320401\n",
            "Objective called, loss=0.312595\n",
            "Objective called, loss=0.471786\n",
            "Objective called, loss=0.317714\n",
            "Objective called, loss=0.346547\n",
            "Objective called, loss=0.366695\n",
            "Objective called, loss=0.303235\n",
            "Objective called, loss=0.308241\n",
            "Objective called, loss=0.221831\n",
            "Objective called, loss=0.254103\n",
            "Objective called, loss=0.369476\n",
            "Objective called, loss=0.377250\n",
            "Objective called, loss=0.289347\n",
            "Objective called, loss=0.273372\n",
            "Objective called, loss=0.251724\n",
            "Objective called, loss=0.292879\n",
            "Objective called, loss=0.328192\n",
            "Objective called, loss=0.315424\n",
            "Objective called, loss=0.200046\n",
            "Objective called, loss=0.371450\n",
            "Objective called, loss=0.311403\n",
            "Objective called, loss=0.348358\n",
            "Objective called, loss=0.412304\n",
            "Objective called, loss=0.281156\n",
            "Objective called, loss=0.242898\n",
            "Objective called, loss=0.347731\n",
            "Objective called, loss=0.292777\n",
            "Objective called, loss=0.205802\n",
            "Objective called, loss=0.254080\n",
            "Objective called, loss=0.253270\n",
            "Objective called, loss=0.247730\n",
            "Objective called, loss=0.264901\n",
            "Optimization finished. success: False message: Return from COBYLA because the objective function has been evaluated MAXFUN times.\n",
            "Supervised training QCNN 3...\n",
            "Starting supervised QCNN optimization (this may take a while)...\n",
            "Objective called, loss=0.456220\n",
            "Objective called, loss=0.555182\n",
            "Objective called, loss=0.358241\n",
            "Objective called, loss=0.443811\n",
            "Objective called, loss=0.352326\n",
            "Objective called, loss=0.425538\n",
            "Objective called, loss=0.269057\n",
            "Objective called, loss=0.321881\n",
            "Objective called, loss=1.451787\n",
            "Objective called, loss=0.284570\n",
            "Objective called, loss=0.403766\n",
            "Objective called, loss=0.450697\n",
            "Objective called, loss=0.256046\n",
            "Objective called, loss=0.071948\n",
            "Objective called, loss=0.421382\n",
            "Objective called, loss=0.144040\n",
            "Objective called, loss=0.123825\n",
            "Objective called, loss=0.569589\n",
            "Objective called, loss=0.280468\n",
            "Objective called, loss=4.725791\n",
            "Objective called, loss=0.840246\n",
            "Objective called, loss=0.905225\n",
            "Objective called, loss=0.695192\n",
            "Objective called, loss=1.331460\n",
            "Objective called, loss=0.675731\n",
            "Objective called, loss=0.046389\n",
            "Objective called, loss=0.219255\n",
            "Objective called, loss=0.331330\n",
            "Objective called, loss=0.592096\n",
            "Objective called, loss=0.563827\n",
            "Objective called, loss=3.370687\n",
            "Objective called, loss=1.975402\n",
            "Objective called, loss=0.251650\n",
            "Objective called, loss=1.541599\n",
            "Objective called, loss=0.800985\n",
            "Objective called, loss=1.179337\n",
            "Objective called, loss=0.231261\n",
            "Objective called, loss=0.147956\n",
            "Objective called, loss=0.229678\n",
            "Objective called, loss=0.346610\n",
            "Objective called, loss=0.088958\n",
            "Objective called, loss=0.390689\n",
            "Objective called, loss=0.287639\n",
            "Objective called, loss=1.031042\n",
            "Objective called, loss=1.210600\n",
            "Objective called, loss=1.208343\n",
            "Objective called, loss=3.375652\n",
            "Objective called, loss=0.105435\n",
            "Objective called, loss=0.695996\n",
            "Objective called, loss=0.073507\n",
            "Optimization finished. success: False message: Return from COBYLA because the objective function has been evaluated MAXFUN times.\n",
            "Extracting features for training SVMs...\n",
            "Training classifiers...\n",
            "SVM Classifier trained for 7 classes\n",
            "SVM Classifier trained for 7 classes\n",
            "SVM Classifier trained for 7 classes\n",
            "Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\n",
            "Performing ensemble prediction...\n",
            "Evaluating results...\n",
            "Accuracy: 80.95238095238095\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      1.00      0.75         3\n",
            "           1       1.00      0.67      0.80         3\n",
            "           2       1.00      0.67      0.80         3\n",
            "           3       1.00      0.67      0.80         3\n",
            "           4       1.00      1.00      1.00         3\n",
            "           5       1.00      0.67      0.80         3\n",
            "           6       0.60      1.00      0.75         3\n",
            "\n",
            "    accuracy                           0.81        21\n",
            "   macro avg       0.89      0.81      0.81        21\n",
            "weighted avg       0.89      0.81      0.81        21\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my = set()\n",
        "nu = [1,2,3]\n",
        "my.update([1,2,3])\n",
        "f =[]\n",
        "print(my)\n",
        "w = list((my))\n",
        "f.append(w)\n",
        "print(f)\n",
        "print(w)"
      ],
      "metadata": {
        "id": "0kzLcyEObUcZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b284d9e-ada5-4091-b3ba-ac55e87342ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1, 2, 3}\n",
            "[[1, 2, 3]]\n",
            "[1, 2, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Tk6BsiWrDKH2",
        "outputId": "b15716ef-9357-4a1d-d790-d7ce50c234fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-2.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit)\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.11/dist-packages (from qiskit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.16.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit) (0.3.8)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qiskit) (4.14.1)\n",
            "Collecting pbr>=2.0.0 (from stevedore>=3.0.0->qiskit)\n",
            "  Downloading pbr-6.1.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pbr>=2.0.0->stevedore>=3.0.0->qiskit) (75.2.0)\n",
            "Downloading qiskit-2.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.4.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pbr-6.1.1-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rustworkx, pbr, stevedore, qiskit\n",
            "Successfully installed pbr-6.1.1 qiskit-2.1.1 rustworkx-0.16.0 stevedore-5.4.1\n"
          ]
        }
      ],
      "source": [
        "pip install qiskit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Qez0dDBPDKEd",
        "outputId": "08e3aa87-d153-4d0d-b41f-b0f28b68ddfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit-aer\n",
            "  Downloading qiskit_aer-0.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: qiskit>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (2.1.1)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (1.16.1)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.0->qiskit-aer) (1.17.0)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (0.16.0)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (0.3.8)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (4.14.1)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from stevedore>=3.0.0->qiskit>=1.1.0->qiskit-aer) (6.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pbr>=2.0.0->stevedore>=3.0.0->qiskit>=1.1.0->qiskit-aer) (75.2.0)\n",
            "Downloading qiskit_aer-0.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: qiskit-aer\n",
            "Successfully installed qiskit-aer-0.17.1\n"
          ]
        }
      ],
      "source": [
        "pip install qiskit-aer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwesvMHvCip4",
        "outputId": "a70d3ae1-e262-4135-a817-d2ca043f9f80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Qiskit version: 2.1.0\n",
            "Starting 3-Qubit QCNN Ensemble for 15-Class Classification\n",
            "Shape of X_train: (135, 576, 4)\n",
            "Shape of y_train: (135,)\n",
            "Training QCNN 1...\n",
            "Training QCNN 2...\n",
            "Training QCNN 3...\n",
            "Extracting features...\n",
            "Training classifiers...\n",
            "SVM Classifier trained for 15 classes\n",
            "SVM Classifier trained for 15 classes\n",
            "SVM Classifier trained for 15 classes\n",
            "Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\n",
            "Performing ensemble prediction...\n",
            "Evaluating results...\n",
            "Accuracy: 76.66666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       0.00      0.00      0.00         2\n",
            "           3       1.00      1.00      1.00         2\n",
            "           4       1.00      1.00      1.00         2\n",
            "           5       0.50      1.00      0.67         2\n",
            "           6       1.00      0.50      0.67         2\n",
            "           7       0.33      0.50      0.40         2\n",
            "           8       0.33      0.50      0.40         2\n",
            "           9       1.00      1.00      1.00         2\n",
            "          10       1.00      1.00      1.00         2\n",
            "          11       1.00      1.00      1.00         2\n",
            "          12       1.00      1.00      1.00         2\n",
            "          13       1.00      1.00      1.00         2\n",
            "          14       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.77        30\n",
            "   macro avg       0.74      0.77      0.74        30\n",
            "weighted avg       0.74      0.77      0.74        30\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import mode\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit_aer import Aer\n",
        "from qiskit.circuit import Parameter\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "def prepare_dataset(dataset_path='/content/dataset'):\n",
        "    train_dir = os.path.join(dataset_path, 'train')\n",
        "    test_dir = os.path.join(dataset_path, 'test')\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    subjects = [f'subject{i:02d}' for i in range(1, 16)]\n",
        "    # Changed test_size to 2 to ensure 2 images per subject for testing\n",
        "    test_size_per_subject = 2\n",
        "\n",
        "    for subject in subjects:\n",
        "        all_items = [f for f in os.listdir(dataset_path)]\n",
        "        subject_files = [item for item in all_items if item.startswith(subject)]\n",
        "        # Ensure there are enough files for the split\n",
        "        if len(subject_files) < test_size_per_subject:\n",
        "            print(f\"Warning: Not enough files for subject {subject} to create test set. Skipping.\")\n",
        "            continue\n",
        "        train_files, test_files = train_test_split(subject_files, test_size=test_size_per_subject, random_state=42)\n",
        "\n",
        "        for file in train_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(train_dir, file))\n",
        "        for file in test_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(test_dir, file))\n",
        "\n",
        "    X_train, y_train = process_folder(train_dir)\n",
        "    X_test, y_test = process_folder(test_dir)\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "def process_folder(folder_path):\n",
        "    processed_images = []\n",
        "    labels = []\n",
        "    image_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path)]\n",
        "\n",
        "    subject_ids = set(os.path.basename(file).split('.')[0] for file in image_files)\n",
        "    subject_to_label = {subject: i for i, subject in enumerate(sorted(subject_ids))}\n",
        "\n",
        "    for file in image_files:\n",
        "        file_name = os.path.basename(file)\n",
        "        subject_id = file_name.split('.')[0]\n",
        "        label = subject_to_label[subject_id]\n",
        "\n",
        "        img = Image.open(file).convert('L').resize((48, 48))\n",
        "        img_array = np.array(img).astype(np.float32) / 255.0 * 2 * np.pi\n",
        "\n",
        "        patches = [img_array[i:i+2, j:j+2].flatten() for i in range(0, 48, 2) for j in range(0, 48, 2) if i+2 <= 48 and j+2 <= 48]\n",
        "        processed_images.append(patches)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(processed_images), np.array(labels)\n",
        "\n",
        "def create_qcnn_circuit_1():\n",
        "    qc = QuantumCircuit(4)\n",
        "    # --- Encoding Layer ---\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 1 ---\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'theta_conv1_{i}'), i)\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(1, 2)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 0)\n",
        "    for i in range(4):\n",
        "        qc.rz(Parameter(f'phi_conv1_{i}'), i)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 1 ---\n",
        "    qc.crx(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.crx(Parameter('theta_pool1_1'), 1, 3)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 2 ---\n",
        "    qc.ry(Parameter('theta_conv2_0'), 2)\n",
        "    qc.ry(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cz(2, 3)\n",
        "    qc.rz(Parameter('phi_conv2_0'), 2)\n",
        "    qc.rz(Parameter('phi_conv2_1'), 3)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 2 ---\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.ry(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "\n",
        "def create_qcnn_circuit_2():\n",
        "    qc = QuantumCircuit(4)\n",
        "    # --- Encoding Layer ---\n",
        "    for i in range(4):\n",
        "        qc.h(i)\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 1 ---\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(2, 3)\n",
        "    qc.ry(Parameter('theta_conv1_0'), 0)\n",
        "    qc.ry(Parameter('theta_conv1_1'), 2)\n",
        "    qc.ccx(0, 2, 1)\n",
        "    qc.ry(Parameter('theta_conv1_2'), 1)\n",
        "    qc.ccx(1, 2, 3)\n",
        "    qc.ry(Parameter('theta_conv1_3'), 3)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 1 ---\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 1)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 2, 3)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 2 ---\n",
        "    qc.ry(Parameter('theta_conv2_0'), 1)\n",
        "    qc.ry(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.rz(Parameter('phi_conv2_0'), 1)\n",
        "    qc.rz(Parameter('phi_conv2_1'), 3)\n",
        "    qc.barrier()\n",
        "    # --- Final Measurement Prep ---\n",
        "    qc.ry(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "def create_qcnn_circuit_3():\n",
        "    qc = QuantumCircuit(4)\n",
        "    # --- Encoding Layer ---\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 1 ---\n",
        "    qc.ry(Parameter('theta_conv1_0'), 0)\n",
        "    qc.rz(Parameter('phi_conv1_0'), 0)\n",
        "    qc.ry(Parameter('theta_conv1_1'), 1)\n",
        "    qc.rz(Parameter('phi_conv1_1'), 1)\n",
        "    qc.ry(Parameter('theta_conv1_2'), 2)\n",
        "    qc.rz(Parameter('phi_conv1_2'), 2)\n",
        "    qc.ry(Parameter('theta_conv1_3'), 3)\n",
        "    qc.rz(Parameter('phi_conv1_3'), 3)\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(1, 2)\n",
        "    qc.cx(2, 3)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 1 ---\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 1)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 2, 3)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 2 ---\n",
        "    qc.ry(Parameter('theta_conv2_0'), 1)\n",
        "    qc.rz(Parameter('phi_conv2_0'), 1)\n",
        "    qc.ry(Parameter('theta_conv2_1'), 3)\n",
        "    qc.rz(Parameter('phi_conv2_1'), 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 2 ---\n",
        "    qc.crx(Parameter('theta_pool2_0'), 1, 3)\n",
        "    qc.barrier()\n",
        "    # --- Final Measurement Prep ---\n",
        "    qc.ry(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "\n",
        "def execute_circuit(circuit, parameters, backend):\n",
        "    # parameters is a dictionary of {Parameter: value}\n",
        "    bound = circuit.assign_parameters(parameters)\n",
        "    meas = QuantumCircuit(4, 3)\n",
        "    meas.compose(bound, inplace=True)\n",
        "    meas.measure([3, 2, 1], [0, 1, 2])\n",
        "    job = backend.run(meas, shots=1024)\n",
        "    result = job.result()\n",
        "    return result.get_counts()\n",
        "\n",
        "def extract_features_from_image(image_patches, circuit, params, backend):\n",
        "    input_params = list(circuit.parameters)[:4]\n",
        "    weight_params = list(circuit.parameters)[4:]\n",
        "    features = []\n",
        "    for patch in image_patches:\n",
        "        bindings = {input_params[i]: float(patch[i]) for i in range(4)}\n",
        "        for i, param in enumerate(weight_params):\n",
        "            bindings[param] = float(params[i])\n",
        "\n",
        "        bound = circuit.assign_parameters(bindings)\n",
        "        meas_circuit = QuantumCircuit(4, 3)\n",
        "        meas_circuit.compose(bound, inplace=True)\n",
        "        meas_circuit.measure([3, 2, 1], [0, 1, 2])\n",
        "        job = backend.run(meas_circuit, shots=1024)\n",
        "        result = job.result()\n",
        "        counts = result.get_counts()\n",
        "\n",
        "        # Compute expectation value for Z⊗Z⊗Z on qubits 3,2,1\n",
        "        expectation = 0\n",
        "        for bitstring, count in counts.items():\n",
        "            bit_values = [1 if b == '0' else -1 for b in bitstring]\n",
        "            zz_product = bit_values[0] * bit_values[1] * bit_values[2]\n",
        "            expectation += zz_product * count / 1024\n",
        "\n",
        "        features.append(expectation)\n",
        "    return features\n",
        "\n",
        "\n",
        "def extract_all_features(X, circuit, params, backend):\n",
        "    # X contains a list of images, where each image is a list of patches.\n",
        "    all_features = []\n",
        "    for image_patches in X:\n",
        "         # extract_features_from_image already handles all patches for a single image\n",
        "        image_features = extract_features_from_image(image_patches, circuit, params, backend)\n",
        "        all_features.append(image_features)\n",
        "    return all_features\n",
        "\n",
        "\n",
        "def train_classifier(X_features, y_labels):\n",
        "    X_features_reshaped = np.array(X_features) # This should create a (num_images, num_patches) array\n",
        "\n",
        "    # Changed from LogisticRegression to SVC (Support Vector Classifier)\n",
        "    # Using RBF kernel which often works well for image classification\n",
        "    clf = SVC(kernel='rbf', probability=True, C=1.0, gamma='scale')\n",
        "    clf.fit(X_features_reshaped, y_labels)\n",
        "\n",
        "    # Verify the classifier is trained for the correct number of classes\n",
        "    n_classes = len(np.unique(y_labels))\n",
        "    print(f\"SVM Classifier trained for {n_classes} classes\")\n",
        "\n",
        "    return clf\n",
        "\n",
        "def cost_function(params, circuit, input_params, weight_params, x_batch, y_batch, backend):\n",
        "    cost = 0\n",
        "    # We need to iterate through each image in the batch.\n",
        "    for i in range(len(x_batch)):\n",
        "        # We need to process each patch for this image to calculate the cost.\n",
        "        image_patches = x_batch[i]\n",
        "        # Calculate cost for this image by averaging the cost over its patches.\n",
        "        image_cost = 0\n",
        "        for patch in image_patches:\n",
        "            # Create a dictionary binding each pixel value to its corresponding input parameter\n",
        "            param_dict = {input_params[j]: float(patch[j]) for j in range(4)}\n",
        "            # Add the weight parameters to the bindings dictionary\n",
        "            for j, param in enumerate(weight_params):\n",
        "                param_dict[param] = float(params[j])\n",
        "\n",
        "            counts = execute_circuit(circuit, param_dict, backend)\n",
        "            expectation = 0\n",
        "            for bitstring, count in counts.items():\n",
        "              if len(bitstring) < 3:\n",
        "                continue\n",
        "              bit_values = [1 if b == '0' else -1 for b in bitstring[:3]]\n",
        "              zz_product = bit_values[0] * bit_values[1] * bit_values[2]\n",
        "              expectation += zz_product * count / 1024\n",
        "            image_cost += (1 - expectation)\n",
        "\n",
        "        # Average cost over all patches in the image\n",
        "        cost += image_cost / len(image_patches)\n",
        "\n",
        "    # Average cost over all images in the batch\n",
        "    return cost / len(x_batch)\n",
        "\n",
        "\n",
        "def train_qcnn(circuit, X_train, y_train, backend, maxiter=75):\n",
        "    all_params = list(circuit.parameters)\n",
        "    # Ensure there are at least 4 input parameters and some weight parameters\n",
        "    if len(all_params) < 5:\n",
        "         raise ValueError(\"Circuit must have at least 4 input parameters and 1 weight parameter.\")\n",
        "    input_params = all_params[:4]\n",
        "    weight_params = all_params[4:]\n",
        "    initial_params = np.random.rand(len(weight_params)) * 2 * np.pi - np.pi\n",
        "    # Pass necessary parameters to the cost function\n",
        "    objective = lambda p: cost_function(p, circuit, input_params, weight_params, X_train, y_train, backend)\n",
        "    result = minimize(objective, initial_params, method='COBYLA', options={'maxiter': maxiter})\n",
        "    return result.x\n",
        "\n",
        "def ensemble_predict(X_test, circuits, param_list, classifiers, backend):\n",
        "    all_preds = []\n",
        "    all_probs = []\n",
        "\n",
        "    for circuit, params, clf in zip(circuits, param_list, classifiers):\n",
        "        # extract_all_features returns a list of feature lists (one per image)\n",
        "        features = extract_all_features(X_test, circuit, params, backend)\n",
        "        features_array = np.array(features)\n",
        "        preds = clf.predict(features_array)\n",
        "        probs = clf.predict_proba(features_array)  # Shape: (num_samples, num_classes)\n",
        "        all_preds.append(preds)\n",
        "        all_probs.append(probs)\n",
        "\n",
        "    final_preds = []\n",
        "    for i in range(len(X_test)):\n",
        "        votes = [model_preds[i] for model_preds in all_preds]\n",
        "        probs_for_sample = [model_probs[i] for model_probs in all_probs]  # list of np.arrays\n",
        "        from collections import Counter\n",
        "        vote_counts = Counter(votes)\n",
        "        # Check if we have a tie (3 unique votes)\n",
        "        if len(vote_counts) == 3:\n",
        "            # Resolve tie using highest confidence\n",
        "            best_class = None\n",
        "            best_conf = -1\n",
        "            for pred, prob_dist in zip(votes, probs_for_sample):\n",
        "                conf = prob_dist[pred]  # Get the confidence of the predicted class\n",
        "                if conf > best_conf:\n",
        "                    best_conf = conf\n",
        "                    best_class = pred\n",
        "            final_preds.append(best_class)\n",
        "        else:\n",
        "            most_common = vote_counts.most_common(1)[0][0]\n",
        "            final_preds.append(most_common)\n",
        "\n",
        "    return final_preds\n",
        "\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred) * 100)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "def main():\n",
        "    print(\"Starting 3-Qubit QCNN Ensemble for 15-Class Classification\")\n",
        "    X_train, y_train, X_test, y_test = prepare_dataset()\n",
        "\n",
        "    # Check the shapes of X_train and y_train\n",
        "    print(f\"Shape of X_train: {X_train.shape}\")\n",
        "    print(f\"Shape of y_train: {y_train.shape}\")\n",
        "\n",
        "    backend = Aer.get_backend('qasm_simulator')\n",
        "\n",
        "    circuit1 = create_qcnn_circuit_1()\n",
        "    circuit2 = create_qcnn_circuit_2()\n",
        "    circuit3 = create_qcnn_circuit_3()\n",
        "\n",
        "\n",
        "    print(\"Training QCNN 1...\")\n",
        "    params1 = train_qcnn(circuit1, X_train, y_train, backend)\n",
        "    print(\"Training QCNN 2...\")\n",
        "    params2 = train_qcnn(circuit2, X_train, y_train, backend)\n",
        "    print(\"Training QCNN 3...\")\n",
        "    params3 = train_qcnn(circuit3, X_train, y_train, backend)\n",
        "\n",
        "    print(\"Extracting features...\")\n",
        "    feat1 = extract_all_features(X_train, circuit1, params1, backend)\n",
        "    feat2 = extract_all_features(X_train, circuit2, params2, backend)\n",
        "    feat3 = extract_all_features(X_train, circuit3, params3, backend)\n",
        "\n",
        "    print(\"Training classifiers...\")\n",
        "    clf1 = train_classifier(feat1, y_train)\n",
        "    clf2 = train_classifier(feat2, y_train)\n",
        "    clf3 = train_classifier(feat3, y_train)\n",
        "\n",
        "    try:\n",
        "        with open('qcnn_ensemble_models.pkl', 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'params1': params1,\n",
        "                'params2': params2,\n",
        "                'params3': params3,\n",
        "                'clf1': clf1,\n",
        "                'clf2': clf2,\n",
        "                'clf3': clf3\n",
        "            }, f)\n",
        "        print(\"Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving models: {e}\")\n",
        "\n",
        "    print(\"Performing ensemble prediction...\")\n",
        "    final_preds = ensemble_predict(X_test, [circuit1, circuit2, circuit3], [params1, params2, params3], [clf1, clf2, clf3], backend)\n",
        "\n",
        "    print(\"Evaluating results...\")\n",
        "    evaluate(y_test, final_preds)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import qiskit\n",
        "    print(f\"Qiskit version: {qiskit.__version__}\")\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8xcZkaRBcjO",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a7b64e7-1912-417a-e350-8eb6f9ad1c26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-2.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit)\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.11/dist-packages (from qiskit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.16.0)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit) (0.3.8)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qiskit) (4.14.1)\n",
            "Collecting pbr>=2.0.0 (from stevedore>=3.0.0->qiskit)\n",
            "  Downloading pbr-6.1.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pbr>=2.0.0->stevedore>=3.0.0->qiskit) (75.2.0)\n",
            "Downloading qiskit-2.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.4.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pbr-6.1.1-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rustworkx, pbr, stevedore, qiskit\n",
            "Successfully installed pbr-6.1.1 qiskit-2.1.1 rustworkx-0.16.0 stevedore-5.4.1\n"
          ]
        }
      ],
      "source": [
        "pip install qiskit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAXvHkG4Bcf6",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "049a41cc-48cf-41d3-e16c-85f63434597c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit-aer\n",
            "  Downloading qiskit_aer-0.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: qiskit>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (2.1.1)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (1.16.0)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.0->qiskit-aer) (1.17.0)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (0.16.0)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (0.3.8)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (4.14.1)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from stevedore>=3.0.0->qiskit>=1.1.0->qiskit-aer) (6.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pbr>=2.0.0->stevedore>=3.0.0->qiskit>=1.1.0->qiskit-aer) (75.2.0)\n",
            "Downloading qiskit_aer-0.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: qiskit-aer\n",
            "Successfully installed qiskit-aer-0.17.1\n"
          ]
        }
      ],
      "source": [
        "pip install qiskit-aer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pjxlETHBfDd",
        "outputId": "00d9bfcc-cabf-462d-c067-a2f4a5377a68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qiskit version: 2.1.1\n",
            "Starting 3-Qubit QCNN Ensemble for 15-Class Classification\n",
            "Shape of X_train: (240, 576, 4)\n",
            "Shape of y_train: (240,)\n",
            "Training QCNN 1...\n",
            "Training QCNN 2...\n",
            "Training QCNN 3...\n",
            "Extracting features...\n",
            "Training classifiers...\n",
            "SVM Classifier trained for 15 classes\n",
            "SVM Classifier trained for 15 classes\n",
            "SVM Classifier trained for 15 classes\n",
            "Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\n",
            "Performing ensemble prediction...\n",
            "Evaluating results...\n",
            "Accuracy: 60.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      1.00      0.50         3\n",
            "           1       0.40      0.67      0.50         3\n",
            "           2       0.50      0.33      0.40         3\n",
            "           3       0.67      0.67      0.67         3\n",
            "           4       1.00      0.33      0.50         3\n",
            "           5       0.75      1.00      0.86         3\n",
            "           6       0.50      0.33      0.40         3\n",
            "           7       0.50      0.33      0.40         3\n",
            "           8       0.50      0.67      0.57         3\n",
            "           9       0.00      0.00      0.00         3\n",
            "          10       1.00      1.00      1.00         3\n",
            "          11       0.50      0.67      0.57         3\n",
            "          12       1.00      1.00      1.00         3\n",
            "          13       1.00      0.67      0.80         3\n",
            "          14       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.60        45\n",
            "   macro avg       0.64      0.60      0.58        45\n",
            "weighted avg       0.64      0.60      0.58        45\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import mode\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit_aer import Aer\n",
        "from qiskit.circuit import Parameter\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "\n",
        "def augment_image(image_path, num_augmentations=1):\n",
        "    img = Image.open(image_path).convert('L')\n",
        "    augmented_images = []\n",
        "\n",
        "    for _ in range(num_augmentations):\n",
        "        aug_img = img.copy()\n",
        "\n",
        "        # Choose ONE random augmentation to apply\n",
        "        choice = random.choice(['flip', 'rotate', 'brightness'])\n",
        "\n",
        "        if choice == 'flip':\n",
        "            aug_img = aug_img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "        elif choice == 'rotate':\n",
        "            angle = random.uniform(-10, 10)\n",
        "            aug_img = aug_img.rotate(angle, resample=Image.BICUBIC, expand=False)\n",
        "\n",
        "        elif choice == 'brightness':\n",
        "            brightness_factor = random.uniform(0.8, 1.2)\n",
        "            # Use ImageEnhance for better brightness control\n",
        "            from PIL import ImageEnhance\n",
        "            enhancer = ImageEnhance.Brightness(aug_img)\n",
        "            aug_img = enhancer.enhance(brightness_factor)\n",
        "\n",
        "        augmented_images.append(aug_img)\n",
        "    return augmented_images\n",
        "\n",
        "\n",
        "def prepare_dataset(dataset_path='/content/dataset'):\n",
        "    train_dir = os.path.join(dataset_path, 'train')\n",
        "    test_dir = os.path.join(dataset_path, 'test')\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    subjects = [f'subject{i:02d}' for i in range(1, 16)]\n",
        "    test_size_per_subject = 3\n",
        "\n",
        "    for subject in subjects:\n",
        "        all_items = [f for f in os.listdir(dataset_path)]\n",
        "        subject_files = [item for item in all_items if item.startswith(subject)]\n",
        "        if len(subject_files) < test_size_per_subject:\n",
        "            print(f\"Warning: Not enough files for subject {subject} to create test set. Skipping.\")\n",
        "            continue\n",
        "        train_files, test_files = train_test_split(subject_files, test_size=test_size_per_subject, random_state=42)\n",
        "\n",
        "        # Copy original training files\n",
        "        for file in train_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(train_dir, file))\n",
        "\n",
        "        # Augment training files and save them\n",
        "        for file in train_files:\n",
        "            original_path = os.path.join(dataset_path, file)\n",
        "            augmented_imgs = augment_image(original_path, num_augmentations=1)\n",
        "            base_name, ext = os.path.splitext(file)\n",
        "            for i, aug_img in enumerate(augmented_imgs):\n",
        "                aug_file_name = f\"{base_name}_aug{i}{ext}\"\n",
        "                aug_img.save(os.path.join(train_dir, aug_file_name))\n",
        "\n",
        "        for file in test_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(test_dir, file))\n",
        "\n",
        "    X_train, y_train = process_folder(train_dir)\n",
        "    X_test, y_test = process_folder(test_dir)\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "def process_folder(folder_path):\n",
        "    processed_images = []\n",
        "    labels = []\n",
        "    image_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path)]\n",
        "\n",
        "    subject_ids = set(os.path.basename(file).split('.')[0].split('_aug')[0] for file in image_files) # Modified to handle augmented file names\n",
        "    subject_to_label = {subject: i for i, subject in enumerate(sorted(subject_ids))}\n",
        "\n",
        "    for file in image_files:\n",
        "        file_name = os.path.basename(file)\n",
        "        subject_id = file_name.split('.')[0].split('_aug')[0] # Modified to handle augmented file names\n",
        "        label = subject_to_label[subject_id]\n",
        "\n",
        "        img = Image.open(file).convert('L').resize((48, 48))\n",
        "        img_array = np.array(img).astype(np.float32) / 255.0 * 2 * np.pi\n",
        "\n",
        "        patches = [img_array[i:i+2, j:j+2].flatten() for i in range(0, 48, 2) for j in range(0, 48, 2) if i+2 <= 48 and j+2 <= 48]\n",
        "        processed_images.append(patches)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(processed_images), np.array(labels)\n",
        "\n",
        "def create_qcnn_circuit_1():\n",
        "    qc = QuantumCircuit(4)\n",
        "    # --- Encoding Layer ---\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 1 ---\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'theta_conv1_{i}'), i)\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(1, 2)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 0)\n",
        "    for i in range(4):\n",
        "        qc.rz(Parameter(f'phi_conv1_{i}'), i)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 1 ---\n",
        "    qc.crx(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.crx(Parameter('theta_pool1_1'), 1, 3)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 2 ---\n",
        "    qc.ry(Parameter('theta_conv2_0'), 2)\n",
        "    qc.ry(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cz(2, 3)\n",
        "    qc.rz(Parameter('phi_conv2_0'), 2)\n",
        "    qc.rz(Parameter('phi_conv2_1'), 3)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 2 ---\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.ry(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "\n",
        "def create_qcnn_circuit_2():\n",
        "    qc = QuantumCircuit(4)\n",
        "    # --- Encoding Layer ---\n",
        "    for i in range(4):\n",
        "        qc.h(i)\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 1 ---\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(2, 3)\n",
        "    qc.ry(Parameter('theta_conv1_0'), 0)\n",
        "    qc.ry(Parameter('theta_conv1_1'), 2)\n",
        "    qc.ccx(0, 2, 1)\n",
        "    qc.ry(Parameter('theta_conv1_2'), 1)\n",
        "    qc.ccx(1, 2, 3)\n",
        "    qc.ry(Parameter('theta_conv1_3'), 3)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 1 ---\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 1)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 2, 3)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 2 ---\n",
        "    qc.ry(Parameter('theta_conv2_0'), 1)\n",
        "    qc.ry(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.rz(Parameter('phi_conv2_0'), 1)\n",
        "    qc.rz(Parameter('phi_conv2_1'), 3)\n",
        "    qc.barrier()\n",
        "    # --- Final Measurement Prep ---\n",
        "    qc.ry(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "def create_qcnn_circuit_3():\n",
        "    qc = QuantumCircuit(4)\n",
        "    # --- Encoding Layer ---\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 1 ---\n",
        "    qc.ry(Parameter('theta_conv1_0'), 0)\n",
        "    qc.rz(Parameter('phi_conv1_0'), 0)\n",
        "    qc.ry(Parameter('theta_conv1_1'), 1)\n",
        "    qc.rz(Parameter('phi_conv1_1'), 1)\n",
        "    qc.ry(Parameter('theta_conv1_2'), 2)\n",
        "    qc.rz(Parameter('phi_conv1_2'), 2)\n",
        "    qc.ry(Parameter('theta_conv1_3'), 3)\n",
        "    qc.rz(Parameter('phi_conv1_3'), 3)\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(1, 2)\n",
        "    qc.cx(2, 3)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 1 ---\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 1)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 2, 3)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 2 ---\n",
        "    qc.ry(Parameter('theta_conv2_0'), 1)\n",
        "    qc.rz(Parameter('phi_conv2_0'), 1)\n",
        "    qc.ry(Parameter('theta_conv2_1'), 3)\n",
        "    qc.rz(Parameter('phi_conv2_1'), 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 2 ---\n",
        "    qc.crx(Parameter('theta_pool2_0'), 1, 3)\n",
        "    qc.barrier()\n",
        "    # --- Final Measurement Prep ---\n",
        "    qc.ry(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "\n",
        "def execute_circuit(circuit, parameters, backend):\n",
        "    # parameters is a dictionary of {Parameter: value}\n",
        "    bound = circuit.assign_parameters(parameters)\n",
        "    meas = QuantumCircuit(4, 3)\n",
        "    meas.compose(bound, inplace=True)\n",
        "    meas.measure([3, 2, 1], [0, 1, 2])\n",
        "    job = backend.run(meas, shots=1024)\n",
        "    result = job.result()\n",
        "    return result.get_counts()\n",
        "\n",
        "def extract_features_from_image(image_patches, circuit, params, backend):\n",
        "    input_params = list(circuit.parameters)[:4]\n",
        "    weight_params = list(circuit.parameters)[4:]\n",
        "    features = []\n",
        "    for patch in image_patches:\n",
        "        bindings = {input_params[i]: float(patch[i]) for i in range(4)}\n",
        "        for i, param in enumerate(weight_params):\n",
        "            bindings[param] = float(params[i])\n",
        "\n",
        "        bound = circuit.assign_parameters(bindings)\n",
        "        meas_circuit = QuantumCircuit(4, 3)\n",
        "        meas_circuit.compose(bound, inplace=True)\n",
        "        meas_circuit.measure([3, 2, 1], [0, 1, 2])\n",
        "        job = backend.run(meas_circuit, shots=1024)\n",
        "        result = job.result()\n",
        "        counts = result.get_counts()\n",
        "\n",
        "        # Compute expectation value for Z⊗Z⊗Z on qubits 3,2,1\n",
        "        expectation = 0\n",
        "        for bitstring, count in counts.items():\n",
        "            bit_values = [1 if b == '0' else -1 for b in bitstring]\n",
        "            zz_product = bit_values[0] * bit_values[1] * bit_values[2]\n",
        "            expectation += zz_product * count / 1024\n",
        "\n",
        "        features.append(expectation)\n",
        "    return features\n",
        "\n",
        "\n",
        "def extract_all_features(X, circuit, params, backend):\n",
        "    # X contains a list of images, where each image is a list of patches.\n",
        "    all_features = []\n",
        "    for image_patches in X:\n",
        "         # extract_features_from_image already handles all patches for a single image\n",
        "        image_features = extract_features_from_image(image_patches, circuit, params, backend)\n",
        "        all_features.append(image_features)\n",
        "    return all_features\n",
        "\n",
        "\n",
        "def train_classifier(X_features, y_labels):\n",
        "    X_features_reshaped = np.array(X_features) # This should create a (num_images, num_patches) array\n",
        "\n",
        "    # Changed from LogisticRegression to SVC (Support Vector Classifier)\n",
        "    # Using RBF kernel which often works well for image classification\n",
        "    clf = SVC(kernel='rbf', probability=True, C=1.0, gamma='scale')\n",
        "    clf.fit(X_features_reshaped, y_labels)\n",
        "\n",
        "    # Verify the classifier is trained for the correct number of classes\n",
        "    n_classes = len(np.unique(y_labels))\n",
        "    print(f\"SVM Classifier trained for {n_classes} classes\")\n",
        "\n",
        "    return clf\n",
        "\n",
        "def cost_function(params, circuit, input_params, weight_params, x_batch, y_batch, backend):\n",
        "    cost = 0\n",
        "    # We need to iterate through each image in the batch.\n",
        "    for i in range(len(x_batch)):\n",
        "        # We need to process each patch for this image to calculate the cost.\n",
        "        image_patches = x_batch[i]\n",
        "        # Calculate cost for this image by averaging the cost over its patches.\n",
        "        image_cost = 0\n",
        "        for patch in image_patches:\n",
        "            # Create a dictionary binding each pixel value to its corresponding input parameter\n",
        "            param_dict = {input_params[j]: float(patch[j]) for j in range(4)}\n",
        "            # Add the weight parameters to the bindings dictionary\n",
        "            for j, param in enumerate(weight_params):\n",
        "                param_dict[param] = float(params[j])\n",
        "\n",
        "            counts = execute_circuit(circuit, param_dict, backend)\n",
        "            expectation = 0\n",
        "            for bitstring, count in counts.items():\n",
        "              if len(bitstring) < 3:\n",
        "                continue\n",
        "              bit_values = [1 if b == '0' else -1 for b in bitstring[:3]]\n",
        "              zz_product = bit_values[0] * bit_values[1] * bit_values[2]\n",
        "              expectation += zz_product * count / 1024\n",
        "            image_cost += (1 - expectation)\n",
        "\n",
        "        # Average cost over all patches in the image\n",
        "        cost += image_cost / len(image_patches)\n",
        "\n",
        "    # Average cost over all images in the batch\n",
        "    return cost / len(x_batch)\n",
        "\n",
        "\n",
        "def train_qcnn(circuit, X_train, y_train, backend, maxiter=80):\n",
        "    all_params = list(circuit.parameters)\n",
        "    # Ensure there are at least 4 input parameters and some weight parameters\n",
        "    if len(all_params) < 5:\n",
        "         raise ValueError(\"Circuit must have at least 4 input parameters and 1 weight parameter.\")\n",
        "    input_params = all_params[:4]\n",
        "    weight_params = all_params[4:]\n",
        "    initial_params = np.random.rand(len(weight_params)) * 2 * np.pi - np.pi\n",
        "    # Pass necessary parameters to the cost function\n",
        "    objective = lambda p: cost_function(p, circuit, input_params, weight_params, X_train, y_train, backend)\n",
        "    result = minimize(objective, initial_params, method='COBYLA', options={'maxiter': maxiter})\n",
        "    return result.x\n",
        "\n",
        "def ensemble_predict(X_test, circuits, param_list, classifiers, backend):\n",
        "    all_preds = []\n",
        "    all_probs = []\n",
        "\n",
        "    for circuit, params, clf in zip(circuits, param_list, classifiers):\n",
        "        # extract_all_features returns a list of feature lists (one per image)\n",
        "        features = extract_all_features(X_test, circuit, params, backend)\n",
        "        features_array = np.array(features)\n",
        "        preds = clf.predict(features_array)\n",
        "        probs = clf.predict_proba(features_array)  # Shape: (num_samples, num_classes)\n",
        "        all_preds.append(preds)\n",
        "        all_probs.append(probs)\n",
        "\n",
        "    final_preds = []\n",
        "    for i in range(len(X_test)):\n",
        "        votes = [model_preds[i] for model_preds in all_preds]\n",
        "        probs_for_sample = [model_probs[i] for model_probs in all_probs]  # list of np.arrays\n",
        "        from collections import Counter\n",
        "        vote_counts = Counter(votes)\n",
        "        # Check if we have a tie (3 unique votes)\n",
        "        if len(vote_counts) == 3:\n",
        "            # Resolve tie using highest confidence\n",
        "            best_class = None\n",
        "            best_conf = -1\n",
        "            for pred, prob_dist in zip(votes, probs_for_sample):\n",
        "                conf = prob_dist[pred]  # Get the confidence of the predicted class\n",
        "                if conf > best_conf:\n",
        "                    best_conf = conf\n",
        "                    best_class = pred\n",
        "            final_preds.append(best_class)\n",
        "        else:\n",
        "            most_common = vote_counts.most_common(1)[0][0]\n",
        "            final_preds.append(most_common)\n",
        "\n",
        "    return final_preds\n",
        "\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred) * 100)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "def main():\n",
        "    print(\"Starting 3-Qubit QCNN Ensemble for 15-Class Classification\")\n",
        "    X_train, y_train, X_test, y_test = prepare_dataset()\n",
        "\n",
        "    # Check the shapes of X_train and y_train\n",
        "    print(f\"Shape of X_train: {X_train.shape}\")\n",
        "    print(f\"Shape of y_train: {y_train.shape}\")\n",
        "\n",
        "    backend = Aer.get_backend('qasm_simulator')\n",
        "\n",
        "    circuit1 = create_qcnn_circuit_1()\n",
        "    circuit2 = create_qcnn_circuit_2()\n",
        "    circuit3 = create_qcnn_circuit_3()\n",
        "\n",
        "\n",
        "    print(\"Training QCNN 1...\")\n",
        "    params1 = train_qcnn(circuit1, X_train, y_train, backend)\n",
        "    print(\"Training QCNN 2...\")\n",
        "    params2 = train_qcnn(circuit2, X_train, y_train, backend)\n",
        "    print(\"Training QCNN 3...\")\n",
        "    params3 = train_qcnn(circuit3, X_train, y_train, backend)\n",
        "\n",
        "    print(\"Extracting features...\")\n",
        "    feat1 = extract_all_features(X_train, circuit1, params1, backend)\n",
        "    feat2 = extract_all_features(X_train, circuit2, params2, backend)\n",
        "    feat3 = extract_all_features(X_train, circuit3, params3, backend)\n",
        "\n",
        "    print(\"Training classifiers...\")\n",
        "    clf1 = train_classifier(feat1, y_train)\n",
        "    clf2 = train_classifier(feat2, y_train)\n",
        "    clf3 = train_classifier(feat3, y_train)\n",
        "\n",
        "    try:\n",
        "        with open('qcnn_ensemble_models.pkl', 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'params1': params1,\n",
        "                'params2': params2,\n",
        "                'params3': params3,\n",
        "                'clf1': clf1,\n",
        "                'clf2': clf2,\n",
        "                'clf3': clf3\n",
        "            }, f)\n",
        "        print(\"Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving models: {e}\")\n",
        "\n",
        "    print(\"Performing ensemble prediction...\")\n",
        "    final_preds = ensemble_predict(X_test, [circuit1, circuit2, circuit3], [params1, params2, params3], [clf1, clf2, clf3], backend)\n",
        "\n",
        "    print(\"Evaluating results...\")\n",
        "    evaluate(y_test, final_preds)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import qiskit\n",
        "    print(f\"Qiskit version: {qiskit.__version__}\")\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hrUoz1LQcP53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NENWH0OPcP2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import mode\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit_aer import Aer\n",
        "from qiskit.circuit import Parameter\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "\n",
        "def prepare_dataset(dataset_path='/content/dataset'):\n",
        "    train_dir = os.path.join(dataset_path, 'train')\n",
        "    test_dir = os.path.join(dataset_path, 'test')\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    subjects = [f'subject{i:02d}' for i in range(1, 16)]\n",
        "    test_size_per_subject = 3\n",
        "\n",
        "    for subject in subjects:\n",
        "        all_items = [f for f in os.listdir(dataset_path)]\n",
        "        subject_files = [item for item in all_items if item.startswith(subject)]\n",
        "        if len(subject_files) < test_size_per_subject:\n",
        "            print(f\"Warning: Not enough files for subject {subject} to create test set. Skipping.\")\n",
        "            continue\n",
        "        train_files, test_files = train_test_split(subject_files, test_size=test_size_per_subject, random_state=42)\n",
        "\n",
        "        # Copy original training files only\n",
        "        for file in train_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(train_dir, file))\n",
        "\n",
        "        # Copy test files\n",
        "        for file in test_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(test_dir, file))\n",
        "\n",
        "    X_train, y_train = process_folder(train_dir)\n",
        "    X_test, y_test = process_folder(test_dir)\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "def process_folder(folder_path):\n",
        "    processed_images = []\n",
        "    labels = []\n",
        "    image_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path)]\n",
        "\n",
        "    subject_ids = set(os.path.basename(file).split('.')[0].split('_aug')[0] for file in image_files) # Modified to handle augmented file names\n",
        "    subject_to_label = {subject: i for i, subject in enumerate(sorted(subject_ids))}\n",
        "\n",
        "    for file in image_files:\n",
        "        file_name = os.path.basename(file)\n",
        "        subject_id = file_name.split('.')[0].split('_aug')[0] # Modified to handle augmented file names\n",
        "        label = subject_to_label[subject_id]\n",
        "\n",
        "        img = Image.open(file).convert('L').resize((48, 48))\n",
        "        img_array = np.array(img).astype(np.float32) / 255.0 * 2 * np.pi\n",
        "\n",
        "        patches = [img_array[i:i+2, j:j+2].flatten() for i in range(0, 48, 2) for j in range(0, 48, 2) if i+2 <= 48 and j+2 <= 48]\n",
        "        processed_images.append(patches)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(processed_images), np.array(labels)\n",
        "\n",
        "def create_qcnn_circuit_1():\n",
        "    qc = QuantumCircuit(4)\n",
        "    # --- Encoding Layer ---\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 1 ---\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'theta_conv1_{i}'), i)\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(1, 2)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 0)\n",
        "    for i in range(4):\n",
        "        qc.rz(Parameter(f'phi_conv1_{i}'), i)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 1 ---\n",
        "    qc.crx(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.crx(Parameter('theta_pool1_1'), 1, 3)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 2 ---\n",
        "    qc.ry(Parameter('theta_conv2_0'), 2)\n",
        "    qc.ry(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cz(2, 3)\n",
        "    qc.rz(Parameter('phi_conv2_0'), 2)\n",
        "    qc.rz(Parameter('phi_conv2_1'), 3)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 2 ---\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.ry(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "\n",
        "def create_qcnn_circuit_2():\n",
        "    qc = QuantumCircuit(4)\n",
        "    # --- Encoding Layer ---\n",
        "    for i in range(4):\n",
        "        qc.h(i)\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 1 ---\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(2, 3)\n",
        "    qc.ry(Parameter('theta_conv1_0'), 0)\n",
        "    qc.ry(Parameter('theta_conv1_1'), 2)\n",
        "    qc.ccx(0, 2, 1)\n",
        "    qc.ry(Parameter('theta_conv1_2'), 1)\n",
        "    qc.ccx(1, 2, 3)\n",
        "    qc.ry(Parameter('theta_conv1_3'), 3)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 1 ---\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 1)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 2, 3)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 2 ---\n",
        "    qc.ry(Parameter('theta_conv2_0'), 1)\n",
        "    qc.ry(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.rz(Parameter('phi_conv2_0'), 1)\n",
        "    qc.rz(Parameter('phi_conv2_1'), 3)\n",
        "    qc.barrier()\n",
        "    # --- Final Measurement Prep ---\n",
        "    qc.ry(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "def create_qcnn_circuit_3():\n",
        "    qc = QuantumCircuit(4)\n",
        "    # --- Encoding Layer ---\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 1 ---\n",
        "    qc.ry(Parameter('theta_conv1_0'), 0)\n",
        "    qc.rz(Parameter('phi_conv1_0'), 0)\n",
        "    qc.ry(Parameter('theta_conv1_1'), 1)\n",
        "    qc.rz(Parameter('phi_conv1_1'), 1)\n",
        "    qc.ry(Parameter('theta_conv1_2'), 2)\n",
        "    qc.rz(Parameter('phi_conv1_2'), 2)\n",
        "    qc.ry(Parameter('theta_conv1_3'), 3)\n",
        "    qc.rz(Parameter('phi_conv1_3'), 3)\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(1, 2)\n",
        "    qc.cx(2, 3)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 1 ---\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 1)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 2, 3)\n",
        "    qc.barrier()\n",
        "    # --- Convolutional Layer 2 ---\n",
        "    qc.ry(Parameter('theta_conv2_0'), 1)\n",
        "    qc.rz(Parameter('phi_conv2_0'), 1)\n",
        "    qc.ry(Parameter('theta_conv2_1'), 3)\n",
        "    qc.rz(Parameter('phi_conv2_1'), 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.barrier()\n",
        "    # --- Pooling Layer 2 ---\n",
        "    qc.crx(Parameter('theta_pool2_0'), 1, 3)\n",
        "    qc.barrier()\n",
        "    # --- Final Measurement Prep ---\n",
        "    qc.ry(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "\n",
        "def execute_circuit(circuit, parameters, backend):\n",
        "    # parameters is a dictionary of {Parameter: value}\n",
        "    bound = circuit.assign_parameters(parameters)\n",
        "    meas = QuantumCircuit(4, 3)\n",
        "    meas.compose(bound, inplace=True)\n",
        "    meas.measure([3, 2, 1], [0, 1, 2])\n",
        "    job = backend.run(meas, shots=1024)\n",
        "    result = job.result()\n",
        "    return result.get_counts()\n",
        "\n",
        "def extract_features_from_image(image_patches, circuit, params, backend):\n",
        "    input_params = list(circuit.parameters)[:4]\n",
        "    weight_params = list(circuit.parameters)[4:]\n",
        "    features = []\n",
        "    for patch in image_patches:\n",
        "        bindings = {input_params[i]: float(patch[i]) for i in range(4)}\n",
        "        for i, param in enumerate(weight_params):\n",
        "            bindings[param] = float(params[i])\n",
        "\n",
        "        bound = circuit.assign_parameters(bindings)\n",
        "        meas_circuit = QuantumCircuit(4, 3)\n",
        "        meas_circuit.compose(bound, inplace=True)\n",
        "        meas_circuit.measure([3, 2, 1], [0, 1, 2])\n",
        "        job = backend.run(meas_circuit, shots=1024)\n",
        "        result = job.result()\n",
        "        counts = result.get_counts()\n",
        "\n",
        "        # Compute expectation value for Z⊗Z⊗Z on qubits 3,2,1\n",
        "        expectation = 0\n",
        "        for bitstring, count in counts.items():\n",
        "            bit_values = [1 if b == '0' else -1 for b in bitstring]\n",
        "            zz_product = bit_values[0] * bit_values[1] * bit_values[2]\n",
        "            expectation += zz_product * count / 1024\n",
        "\n",
        "        features.append(expectation)\n",
        "    return features\n",
        "\n",
        "\n",
        "def extract_all_features(X, circuit, params, backend):\n",
        "    # X contains a list of images, where each image is a list of patches.\n",
        "    all_features = []\n",
        "    for image_patches in X:\n",
        "         # extract_features_from_image already handles all patches for a single image\n",
        "        image_features = extract_features_from_image(image_patches, circuit, params, backend)\n",
        "        all_features.append(image_features)\n",
        "    return all_features\n",
        "\n",
        "\n",
        "def train_classifier(X_features, y_labels):\n",
        "    X_features_reshaped = np.array(X_features) # This should create a (num_images, num_patches) array\n",
        "\n",
        "    # Changed from LogisticRegression to SVC (Support Vector Classifier)\n",
        "    # Using RBF kernel which often works well for image classification\n",
        "    clf = SVC(kernel='rbf', probability=True, C=1.0, gamma='scale')\n",
        "    clf.fit(X_features_reshaped, y_labels)\n",
        "\n",
        "    # Verify the classifier is trained for the correct number of classes\n",
        "    n_classes = len(np.unique(y_labels))\n",
        "    print(f\"SVM Classifier trained for {n_classes} classes\")\n",
        "\n",
        "    return clf\n",
        "\n",
        "def cost_function(params, circuit, input_params, weight_params, x_batch, y_batch, backend):\n",
        "    cost = 0\n",
        "    # We need to iterate through each image in the batch.\n",
        "    for i in range(len(x_batch)):\n",
        "        # We need to process each patch for this image to calculate the cost.\n",
        "        image_patches = x_batch[i]\n",
        "        # Calculate cost for this image by averaging the cost over its patches.\n",
        "        image_cost = 0\n",
        "        for patch in image_patches:\n",
        "            # Create a dictionary binding each pixel value to its corresponding input parameter\n",
        "            param_dict = {input_params[j]: float(patch[j]) for j in range(4)}\n",
        "            # Add the weight parameters to the bindings dictionary\n",
        "            for j, param in enumerate(weight_params):\n",
        "                param_dict[param] = float(params[j])\n",
        "\n",
        "            counts = execute_circuit(circuit, param_dict, backend)\n",
        "            expectation = 0\n",
        "            for bitstring, count in counts.items():\n",
        "              if len(bitstring) < 3:\n",
        "                continue\n",
        "              bit_values = [1 if b == '0' else -1 for b in bitstring[:3]]\n",
        "              zz_product = bit_values[0] * bit_values[1] * bit_values[2]\n",
        "              expectation += zz_product * count / 1024\n",
        "            image_cost += (1 - expectation)\n",
        "\n",
        "        # Average cost over all patches in the image\n",
        "        cost += image_cost / len(image_patches)\n",
        "\n",
        "    # Average cost over all images in the batch\n",
        "    return cost / len(x_batch)\n",
        "\n",
        "\n",
        "def train_qcnn(circuit, X_train, y_train, backend, maxiter=80):\n",
        "    all_params = list(circuit.parameters)\n",
        "    # Ensure there are at least 4 input parameters and some weight parameters\n",
        "    if len(all_params) < 5:\n",
        "         raise ValueError(\"Circuit must have at least 4 input parameters and 1 weight parameter.\")\n",
        "    input_params = all_params[:4]\n",
        "    weight_params = all_params[4:]\n",
        "    initial_params = np.random.rand(len(weight_params)) * 2 * np.pi - np.pi\n",
        "    # Pass necessary parameters to the cost function\n",
        "    objective = lambda p: cost_function(p, circuit, input_params, weight_params, X_train, y_train, backend)\n",
        "    result = minimize(objective, initial_params, method='COBYLA', options={'maxiter': maxiter})\n",
        "    return result.x\n",
        "\n",
        "def ensemble_predict(X_test, circuits, param_list, classifiers, backend):\n",
        "    all_preds = []\n",
        "    all_probs = []\n",
        "\n",
        "    for circuit, params, clf in zip(circuits, param_list, classifiers):\n",
        "        # extract_all_features returns a list of feature lists (one per image)\n",
        "        features = extract_all_features(X_test, circuit, params, backend)\n",
        "        features_array = np.array(features)\n",
        "        preds = clf.predict(features_array)\n",
        "        probs = clf.predict_proba(features_array)  # Shape: (num_samples, num_classes)\n",
        "        all_preds.append(preds)\n",
        "        all_probs.append(probs)\n",
        "\n",
        "    final_preds = []\n",
        "    for i in range(len(X_test)):\n",
        "        votes = [model_preds[i] for model_preds in all_preds]\n",
        "        probs_for_sample = [model_probs[i] for model_probs in all_probs]  # list of np.arrays\n",
        "        from collections import Counter\n",
        "        vote_counts = Counter(votes)\n",
        "        # Check if we have a tie (3 unique votes)\n",
        "        if len(vote_counts) == 3:\n",
        "            # Resolve tie using highest confidence\n",
        "            best_class = None\n",
        "            best_conf = -1\n",
        "            for pred, prob_dist in zip(votes, probs_for_sample):\n",
        "                conf = prob_dist[pred]  # Get the confidence of the predicted class\n",
        "                if conf > best_conf:\n",
        "                    best_conf = conf\n",
        "                    best_class = pred\n",
        "            final_preds.append(best_class)\n",
        "        else:\n",
        "            most_common = vote_counts.most_common(1)[0][0]\n",
        "            final_preds.append(most_common)\n",
        "\n",
        "    return final_preds\n",
        "\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred) * 100)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "def main():\n",
        "    print(\"Starting 3-Qubit QCNN Ensemble for 15-Class Classification\")\n",
        "    X_train, y_train, X_test, y_test = prepare_dataset()\n",
        "\n",
        "    # Check the shapes of X_train and y_train\n",
        "    print(f\"Shape of X_train: {X_train.shape}\")\n",
        "    print(f\"Shape of y_train: {y_train.shape}\")\n",
        "\n",
        "    backend = Aer.get_backend('qasm_simulator')\n",
        "\n",
        "    circuit1 = create_qcnn_circuit_1()\n",
        "    circuit2 = create_qcnn_circuit_2()\n",
        "    circuit3 = create_qcnn_circuit_3()\n",
        "\n",
        "\n",
        "    print(\"Training QCNN 1...\")\n",
        "    params1 = train_qcnn(circuit1, X_train, y_train, backend)\n",
        "    print(\"Training QCNN 2...\")\n",
        "    params2 = train_qcnn(circuit2, X_train, y_train, backend)\n",
        "    print(\"Training QCNN 3...\")\n",
        "    params3 = train_qcnn(circuit3, X_train, y_train, backend)\n",
        "\n",
        "    print(\"Extracting features...\")\n",
        "    feat1 = extract_all_features(X_train, circuit1, params1, backend)\n",
        "    feat2 = extract_all_features(X_train, circuit2, params2, backend)\n",
        "    feat3 = extract_all_features(X_train, circuit3, params3, backend)\n",
        "\n",
        "    print(\"Training classifiers...\")\n",
        "    clf1 = train_classifier(feat1, y_train)\n",
        "    clf2 = train_classifier(feat2, y_train)\n",
        "    clf3 = train_classifier(feat3, y_train)\n",
        "\n",
        "    try:\n",
        "        with open('qcnn_ensemble_models.pkl', 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'params1': params1,\n",
        "                'params2': params2,\n",
        "                'params3': params3,\n",
        "                'clf1': clf1,\n",
        "                'clf2': clf2,\n",
        "                'clf3': clf3\n",
        "            }, f)\n",
        "        print(\"Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving models: {e}\")\n",
        "\n",
        "    print(\"Performing ensemble prediction...\")\n",
        "    final_preds = ensemble_predict(X_test, [circuit1, circuit2, circuit3], [params1, params2, params3], [clf1, clf2, clf3], backend)\n",
        "\n",
        "    print(\"Evaluating results...\")\n",
        "    evaluate(y_test, final_preds)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import qiskit\n",
        "    print(f\"Qiskit version: {qiskit.__version__}\")\n",
        "    main()"
      ],
      "metadata": {
        "id": "Isp0SK7g6vC2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "1e9796df-9c1e-484d-ff27-5e9b9a2967f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qiskit version: 2.1.1\n",
            "Starting 3-Qubit QCNN Ensemble for 15-Class Classification\n",
            "Shape of X_train: (120, 576, 4)\n",
            "Shape of y_train: (120,)\n",
            "Training QCNN 1...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4011698104.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Qiskit version: {qiskit.__version__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-4011698104.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training QCNN 1...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0mparams1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_qcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training QCNN 2...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mparams2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_qcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4011698104.py\u001b[0m in \u001b[0;36mtrain_qcnn\u001b[0;34m(circuit, X_train, y_train, backend, maxiter)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;31m# Pass necessary parameters to the cost function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'COBYLA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'maxiter'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    789\u001b[0m                             **options)\n\u001b[1;32m    790\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cobyla'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m         res = _minimize_cobyla(fun, x0, args, constraints, callback=callback,\n\u001b[0m\u001b[1;32m    792\u001b[0m                                bounds=bounds, **options)\n\u001b[1;32m    793\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cobyqa'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_cobyla_py.py\u001b[0m in \u001b[0;36m_minimize_cobyla\u001b[0;34m(fun, x0, args, constraints, rhobeg, tol, maxiter, disp, catol, f_target, callback, bounds, **unknown_options)\u001b[0m\n\u001b[1;32m    276\u001b[0m     }\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m     result = minimize(sf.fun, x0, method='cobyla', bounds=bounds,\n\u001b[0m\u001b[1;32m    279\u001b[0m                       \u001b[0mconstraints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwrapped_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m                       options=options)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/pyprima/__init__.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, bounds, constraints, callback, options)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'maxfev'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     result = cobyla(\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mcalcfc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlconstr0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/pyprima/cobyla/cobyla.py\u001b[0m in \u001b[0;36mcobyla\u001b[0;34m(calcfc, m_nlcon, x, Aineq, bineq, Aeq, beq, xl, xu, f0, nlconstr0, rhobeg, rhoend, ftarget, ctol, cweight, maxfun, iprint, eta1, eta2, gamma1, gamma2, maxhist, maxfilt, callback)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;31m# call cobylb, which performs the real calculations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m     x, f, constr, cstrv, nf, xhist, fhist, chist, conhist, info = cobylb(\n\u001b[0m\u001b[1;32m    462\u001b[0m         \u001b[0mcalcfc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/pyprima/cobyla/cobylb.py\u001b[0m in \u001b[0;36mcobylb\u001b[0;34m(calcfc, iprint, maxfilt, maxfun, amat, bvec, ctol, cweight, eta1, eta2, ftarget, gamma1, gamma2, rhobeg, rhoend, constr, f, x, maxhist, callback)\u001b[0m\n\u001b[1;32m    476\u001b[0m                 \u001b[0;31m# Evaluate the objective and constraints at X, taking care of possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;31m# inf/nan values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalcfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_nlcon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m                 \u001b[0mcstrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                 \u001b[0mnf\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/pyprima/common/evaluate.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(calcfc, x, m_nlcon, amat, bvec)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mconstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_nlcon\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm_lcon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalcfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoderatex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# Moderated extreme barrier: replace NaN/huge objective or constraint values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/pyprima/__init__.py\u001b[0m in \u001b[0;36mcalcfc\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcalcfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0mconstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lowest_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/_util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;31m# Send a copy because the user may overwrite it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;31m# The user of this class might want `x` to remain unchanged.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4011698104.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0minitial_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;31m# Pass necessary parameters to the cost function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'COBYLA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'maxiter'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4011698104.py\u001b[0m in \u001b[0;36mcost_function\u001b[0;34m(params, circuit, input_params, weight_params, x_batch, y_batch, backend)\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0mparam_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0mexpectation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbitstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4011698104.py\u001b[0m in \u001b[0;36mexecute_circuit\u001b[0;34m(circuit, parameters, backend)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mmeas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit_aer/jobs/utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_future\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJobError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job not submitted yet!. You have to .submit() first!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit_aer/jobs/aerjob.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCancelledError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mjob\u001b[0m \u001b[0mcancelled\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \"\"\"\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mrequires_submit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dZRJEBU56u_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c0TZd7Ib6u9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t2D5KRIGcP0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LLq1Ur2wcPxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HluJm8rKNHLT"
      },
      "source": [
        "# **Changed cost function and reamining function to deal with proper multiclass**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fC6UbaQCl5x",
        "outputId": "25d2870d-0d89-4b0a-8815-72e0ccdba02f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Qiskit version: 2.1.0\n",
            "Starting 1-Qubit QCNN Ensemble for 5-Class Classification\n",
            "Shape of X_train: (72, 576, 4)\n",
            "Shape of y_train: (72,)\n",
            "Training QCNN 1...\n",
            "Training QCNN 2...\n",
            "Training QCNN 3...\n",
            "Extracting features...\n",
            "Training classifiers...\n",
            "SVM Classifier trained for 8 classes\n",
            "SVM Classifier trained for 8 classes\n",
            "SVM Classifier trained for 8 classes\n",
            "Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\n",
            "Performing ensemble prediction...\n",
            "Evaluating results...\n",
            "Accuracy: 87.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      1.00      0.80         2\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      0.50      0.67         2\n",
            "           4       1.00      1.00      1.00         2\n",
            "           5       0.67      1.00      0.80         2\n",
            "           6       1.00      1.00      1.00         2\n",
            "           7       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.88        16\n",
            "   macro avg       0.92      0.88      0.87        16\n",
            "weighted avg       0.92      0.88      0.87        16\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import mode\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit_aer import Aer\n",
        "from qiskit.circuit import Parameter\n",
        "import pickle\n",
        "\n",
        "\n",
        "def prepare_dataset(dataset_path='/content/dataset'):\n",
        "    train_dir = os.path.join(dataset_path, 'train')\n",
        "    test_dir = os.path.join(dataset_path, 'test')\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    subjects = [f'subject{i:02d}' for i in range(1, 9)]\n",
        "    # Changed test_size to 2 to ensure 2 images per subject for testing\n",
        "    test_size_per_subject = 2\n",
        "\n",
        "    for subject in subjects:\n",
        "        all_items = [f for f in os.listdir(dataset_path)]\n",
        "        subject_files = [item for item in all_items if item.startswith(subject)]\n",
        "        # Ensure there are enough files for the split\n",
        "        if len(subject_files) < test_size_per_subject:\n",
        "            print(f\"Warning: Not enough files for subject {subject} to create test set. Skipping.\")\n",
        "            continue\n",
        "        train_files, test_files = train_test_split(subject_files, test_size=test_size_per_subject, random_state=42)\n",
        "\n",
        "        for file in train_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(train_dir, file))\n",
        "        for file in test_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(test_dir, file))\n",
        "\n",
        "    X_train, y_train = process_folder(train_dir)\n",
        "    X_test, y_test = process_folder(test_dir)\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "def process_folder(folder_path):\n",
        "    processed_images = []\n",
        "    labels = []\n",
        "    image_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path)]\n",
        "\n",
        "    subject_ids = set(os.path.basename(file).split('.')[0] for file in image_files)\n",
        "    subject_to_label = {subject: i for i, subject in enumerate(sorted(subject_ids))}\n",
        "\n",
        "    for file in image_files:\n",
        "        file_name = os.path.basename(file)\n",
        "        subject_id = file_name.split('.')[0]\n",
        "        label = subject_to_label[subject_id]\n",
        "\n",
        "        img = Image.open(file).convert('L').resize((48, 48))\n",
        "        img_array = np.array(img).astype(np.float32) / 255.0 * 2 * np.pi\n",
        "\n",
        "        patches = [img_array[i:i+2, j:j+2].flatten() for i in range(0, 48, 2) for j in range(0, 48, 2) if i+2 <= 48 and j+2 <= 48]\n",
        "        processed_images.append(patches)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(processed_images), np.array(labels)\n",
        "\n",
        "def create_qcnn_circuit_1():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'theta_conv1_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.cx(i, (i+1) % 4)\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.ry(Parameter('theta_conv2_0'), 2)\n",
        "    qc.ry(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.ry(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "def create_qcnn_circuit_2():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.rx(Parameter(f'theta_conv1_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.cx(i, (i+1) % 4)\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.rx(Parameter('theta_conv2_0'), 2)\n",
        "    qc.rx(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cz(2, 3)\n",
        "    qc.cz(3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.rx(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "def create_qcnn_circuit_3():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.rz(Parameter(f'theta_conv1_{i}'), i)\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(0, 2)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.rz(Parameter('theta_conv2_0'), 2)\n",
        "    qc.rz(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.rz(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "\n",
        "def execute_circuit(circuit, parameters, backend):\n",
        "    bound = circuit.assign_parameters(parameters)\n",
        "    meas = QuantumCircuit(4, 3)\n",
        "    meas.compose(bound, inplace=True)\n",
        "    meas.measure([3, 2, 1], [0, 1, 2])  # 3 qubit measurement\n",
        "    job = backend.run(meas, shots=1024)\n",
        "    result = job.result()\n",
        "    return result.get_counts()\n",
        "\n",
        "def extract_features_from_image(image_patches, circuit, params, backend):\n",
        "    input_params = list(circuit.parameters)[:4]\n",
        "    weight_params = list(circuit.parameters)[4:]\n",
        "    features = []\n",
        "\n",
        "    for patch in image_patches:\n",
        "        bindings = {input_params[i]: float(patch[i]) for i in range(4)}\n",
        "        for i, param in enumerate(weight_params):\n",
        "            bindings[param] = float(params[i])\n",
        "\n",
        "        bound = circuit.assign_parameters(bindings)\n",
        "        meas_circuit = QuantumCircuit(4, 3)\n",
        "        meas_circuit.compose(bound, inplace=True)\n",
        "        meas_circuit.measure([3, 2, 1], [0, 1, 2])  # 3 qubit measurement\n",
        "\n",
        "        job = backend.run(meas_circuit, shots=1024)\n",
        "        result = job.result()\n",
        "        counts = result.get_counts()\n",
        "\n",
        "        # Normalize 8-class probabilities\n",
        "        probs = np.zeros(8)\n",
        "        for outcome, count in counts.items():\n",
        "            idx = int(outcome, 2)\n",
        "            probs[idx] = count / 1024\n",
        "        features.append(probs)\n",
        "\n",
        "    # Flatten all patch vectors for SVM (num_patches x 8 → 1D feature vector)\n",
        "    return np.array(features).flatten()\n",
        "\n",
        "\n",
        "def extract_all_features(X, circuit, params, backend):\n",
        "    # X contains a list of images, where each image is a list of patches.\n",
        "    all_features = []\n",
        "    for image_patches in X:\n",
        "         # extract_features_from_image already handles all patches for a single image\n",
        "        image_features = extract_features_from_image(image_patches, circuit, params, backend)\n",
        "        all_features.append(image_features)\n",
        "    return all_features\n",
        "\n",
        "\n",
        "def train_classifier(X_features, y_labels):\n",
        "    X_features_reshaped = np.array(X_features) # This should create a (num_images, num_patches) array\n",
        "\n",
        "    # Changed from LogisticRegression to SVC (Support Vector Classifier)\n",
        "    # Using RBF kernel which often works well for image classification\n",
        "    clf = SVC(kernel='rbf', probability=True, C=1.0, gamma='scale')\n",
        "    clf.fit(X_features_reshaped, y_labels)\n",
        "\n",
        "    # Verify the classifier is trained for the correct number of classes\n",
        "    n_classes = len(np.unique(y_labels))\n",
        "    print(f\"SVM Classifier trained for {n_classes} classes\")\n",
        "\n",
        "    return clf\n",
        "\n",
        "def cost_function(params, circuit, input_params, weight_params, x_batch, y_batch, backend):\n",
        "    cost = 0\n",
        "    for i in range(len(x_batch)):\n",
        "        image_patches = x_batch[i]\n",
        "        true_class = y_batch[i]\n",
        "\n",
        "        patch_cost = 0\n",
        "        for patch in image_patches:\n",
        "            param_dict = {input_params[j]: float(patch[j]) for j in range(4)}\n",
        "            for j, param in enumerate(weight_params):\n",
        "                param_dict[param] = float(params[j])\n",
        "\n",
        "            counts = execute_circuit(circuit, param_dict, backend)\n",
        "            probs = np.zeros(8)\n",
        "            for outcome, count in counts.items():\n",
        "                idx = int(outcome, 2)\n",
        "                probs[idx] = count / 1024\n",
        "\n",
        "            # Multi-class cost: 1 - probability of true class\n",
        "            patch_cost += 1.0 - probs[true_class]\n",
        "\n",
        "        cost += patch_cost / len(image_patches)\n",
        "\n",
        "    return cost / len(x_batch)\n",
        "\n",
        "\n",
        "def train_qcnn(circuit, X_train, y_train, backend, maxiter=50):\n",
        "    all_params = list(circuit.parameters)\n",
        "    # Ensure there are at least 4 input parameters and some weight parameters\n",
        "    if len(all_params) < 5:\n",
        "         raise ValueError(\"Circuit must have at least 4 input parameters and 1 weight parameter.\")\n",
        "    input_params = all_params[:4]\n",
        "    weight_params = all_params[4:]\n",
        "    initial_params = np.random.rand(len(weight_params)) * 2 * np.pi - np.pi\n",
        "    # Pass necessary parameters to the cost function\n",
        "    objective = lambda p: cost_function(p, circuit, input_params, weight_params, X_train, y_train, backend)\n",
        "    result = minimize(objective, initial_params, method='COBYLA', options={'maxiter': maxiter})\n",
        "    return result.x\n",
        "\n",
        "def ensemble_predict(X_test, circuits, param_list, classifiers, backend):\n",
        "    all_preds = []\n",
        "    for circuit, params, clf in zip(circuits, param_list, classifiers):\n",
        "        # extract_all_features returns a list of feature lists (one per image)\n",
        "        features = extract_all_features(X_test, circuit, params, backend)\n",
        "        # Convert features to a NumPy array for the classifier\n",
        "        features_array = np.array(features)\n",
        "        preds = clf.predict(features_array)\n",
        "        all_preds.append(preds)\n",
        "\n",
        "    final_preds = []\n",
        "    for i in range(len(X_test)):\n",
        "        votes = [model_preds[i] for model_preds in all_preds]\n",
        "\n",
        "        # Simple fix: convert to a list and use the most common value\n",
        "        votes_list = list(votes)\n",
        "        # Count occurrences of each value\n",
        "        from collections import Counter\n",
        "        most_common = Counter(votes_list).most_common(1)[0][0]\n",
        "        final_preds.append(most_common)\n",
        "\n",
        "    return final_preds\n",
        "\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred) * 100)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "def main():\n",
        "    print(\"Starting 1-Qubit QCNN Ensemble for 5-Class Classification\")\n",
        "    X_train, y_train, X_test, y_test = prepare_dataset()\n",
        "\n",
        "    # Check the shapes of X_train and y_train\n",
        "    print(f\"Shape of X_train: {X_train.shape}\")\n",
        "    print(f\"Shape of y_train: {y_train.shape}\")\n",
        "\n",
        "    backend = Aer.get_backend('qasm_simulator')\n",
        "\n",
        "    circuit1 = create_qcnn_circuit_1()\n",
        "    circuit2 = create_qcnn_circuit_2()\n",
        "    circuit3 = create_qcnn_circuit_3()\n",
        "\n",
        "\n",
        "    print(\"Training QCNN 1...\")\n",
        "    params1 = train_qcnn(circuit1, X_train, y_train, backend)\n",
        "    print(\"Training QCNN 2...\")\n",
        "    params2 = train_qcnn(circuit2, X_train, y_train, backend)\n",
        "    print(\"Training QCNN 3...\")\n",
        "    params3 = train_qcnn(circuit3, X_train, y_train, backend)\n",
        "\n",
        "    print(\"Extracting features...\")\n",
        "    feat1 = extract_all_features(X_train, circuit1, params1, backend)\n",
        "    feat2 = extract_all_features(X_train, circuit2, params2, backend)\n",
        "    feat3 = extract_all_features(X_train, circuit3, params3, backend)\n",
        "\n",
        "    print(\"Training classifiers...\")\n",
        "    clf1 = train_classifier(feat1, y_train)\n",
        "    clf2 = train_classifier(feat2, y_train)\n",
        "    clf3 = train_classifier(feat3, y_train)\n",
        "\n",
        "    try:\n",
        "        with open('qcnn_ensemble_models.pkl', 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'params1': params1,\n",
        "                'params2': params2,\n",
        "                'params3': params3,\n",
        "                'clf1': clf1,\n",
        "                'clf2': clf2,\n",
        "                'clf3': clf3\n",
        "            }, f)\n",
        "        print(\"Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving models: {e}\")\n",
        "\n",
        "    print(\"Performing ensemble prediction...\")\n",
        "    final_preds = ensemble_predict(X_test, [circuit1, circuit2, circuit3], [params1, params2, params3], [clf1, clf2, clf3], backend)\n",
        "\n",
        "    print(\"Evaluating results...\")\n",
        "    evaluate(y_test, final_preds)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import qiskit\n",
        "    print(f\"Qiskit version: {qiskit.__version__}\")\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uz4lYI3bLON"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgXk6TLybLK1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VhpgCXkAbLr9",
        "outputId": "3368b3df-56c6-47f5-d867-363a920f726b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Qiskit version: 2.1.0\n",
            "Starting 1-Qubit QCNN Ensemble for 5-Class Classification\n",
            "Shape of X_train: (120, 576, 4)\n",
            "Shape of y_train: (120,)\n",
            "Training QCNN 1...\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training QCNN 2...\n",
            "Training QCNN 3...\n",
            "Extracting features...\n",
            "Training classifiers...\n",
            "SVM Classifier trained for 15 classes\n",
            "SVM Classifier trained for 15 classes\n",
            "SVM Classifier trained for 15 classes\n",
            "Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\n",
            "Performing ensemble prediction...\n",
            "Evaluating results...\n",
            "Accuracy: 71.11111111111111\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      1.00      0.75         3\n",
            "           1       1.00      0.33      0.50         3\n",
            "           2       1.00      1.00      1.00         3\n",
            "           3       1.00      0.33      0.50         3\n",
            "           4       1.00      0.67      0.80         3\n",
            "           5       0.50      1.00      0.67         3\n",
            "           6       1.00      0.67      0.80         3\n",
            "           7       0.40      0.67      0.50         3\n",
            "           8       1.00      0.33      0.50         3\n",
            "           9       1.00      0.67      0.80         3\n",
            "          10       1.00      1.00      1.00         3\n",
            "          11       0.75      1.00      0.86         3\n",
            "          12       1.00      0.67      0.80         3\n",
            "          13       1.00      0.33      0.50         3\n",
            "          14       0.43      1.00      0.60         3\n",
            "\n",
            "    accuracy                           0.71        45\n",
            "   macro avg       0.85      0.71      0.70        45\n",
            "weighted avg       0.85      0.71      0.70        45\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import mode\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit_aer import Aer\n",
        "from qiskit.circuit import Parameter\n",
        "import pickle\n",
        "\n",
        "\n",
        "cost_history = []\n",
        "\n",
        "def prepare_dataset(dataset_path='/content/dataset'):\n",
        "    train_dir = os.path.join(dataset_path, 'train')\n",
        "    test_dir = os.path.join(dataset_path, 'test')\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    subjects = [f'subject{i:02d}' for i in range(1, 16)]\n",
        "    # Changed test_size to 2 to ensure 2 images per subject for testing\n",
        "    test_size_per_subject = 3\n",
        "\n",
        "    for subject in subjects:\n",
        "        all_items = [f for f in os.listdir(dataset_path)]\n",
        "        subject_files = [item for item in all_items if item.startswith(subject)]\n",
        "        # Ensure there are enough files for the split\n",
        "        if len(subject_files) < test_size_per_subject:\n",
        "            print(f\"Warning: Not enough files for subject {subject} to create test set. Skipping.\")\n",
        "            continue\n",
        "        train_files, test_files = train_test_split(subject_files, test_size=test_size_per_subject, random_state=42)\n",
        "\n",
        "        for file in train_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(train_dir, file))\n",
        "        for file in test_files:\n",
        "            shutil.copy(os.path.join(dataset_path, file), os.path.join(test_dir, file))\n",
        "\n",
        "    X_train, y_train = process_folder(train_dir)\n",
        "    X_test, y_test = process_folder(test_dir)\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "def process_folder(folder_path):\n",
        "    processed_images = []\n",
        "    labels = []\n",
        "    image_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path)]\n",
        "\n",
        "    subject_ids = set(os.path.basename(file).split('.')[0] for file in image_files)\n",
        "    subject_to_label = {subject: i for i, subject in enumerate(sorted(subject_ids))}\n",
        "\n",
        "    for file in image_files:\n",
        "        file_name = os.path.basename(file)\n",
        "        subject_id = file_name.split('.')[0]\n",
        "        label = subject_to_label[subject_id]\n",
        "\n",
        "        img = Image.open(file).convert('L').resize((48, 48))\n",
        "        img_array = np.array(img).astype(np.float32) / 255.0 * 2 * np.pi\n",
        "\n",
        "        patches = [img_array[i:i+2, j:j+2].flatten() for i in range(0, 48, 2) for j in range(0, 48, 2) if i+2 <= 48 and j+2 <= 48]\n",
        "        processed_images.append(patches)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(processed_images), np.array(labels)\n",
        "\n",
        "def create_qcnn_circuit_1():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'theta_conv1_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.cx(i, (i+1) % 4)\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.ry(Parameter('theta_conv2_0'), 2)\n",
        "    qc.ry(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.ry(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "def create_qcnn_circuit_2():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.rx(Parameter(f'theta_conv1_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.cx(i, (i+1) % 4)\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.rx(Parameter('theta_conv2_0'), 2)\n",
        "    qc.rx(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cz(2, 3)\n",
        "    qc.cz(3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.rx(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "def create_qcnn_circuit_3():\n",
        "    qc = QuantumCircuit(4)\n",
        "    for i in range(4):\n",
        "        qc.ry(Parameter(f'pixel_{i}'), i)\n",
        "    for i in range(4):\n",
        "        qc.rz(Parameter(f'theta_conv1_{i}'), i)\n",
        "    qc.cx(0, 1)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(0, 2)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_0'), 0, 2)\n",
        "    qc.cx(0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_1'), 0, 2)\n",
        "    qc.crz(Parameter('theta_pool1_2'), 1, 3)\n",
        "    qc.cx(1, 3)\n",
        "    qc.crz(Parameter('theta_pool1_3'), 1, 3)\n",
        "    qc.rz(Parameter('theta_conv2_0'), 2)\n",
        "    qc.rz(Parameter('theta_conv2_1'), 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.cx(3, 2)\n",
        "    qc.crz(Parameter('theta_pool2_0'), 2, 3)\n",
        "    qc.cx(2, 3)\n",
        "    qc.crz(Parameter('theta_pool2_1'), 2, 3)\n",
        "    qc.rz(Parameter('theta_final'), 3)\n",
        "    return qc\n",
        "\n",
        "\n",
        "def execute_circuit(circuit, parameters, backend):\n",
        "    bound = circuit.assign_parameters(parameters)\n",
        "    meas = QuantumCircuit(4, 4)\n",
        "    meas.compose(bound, inplace=True)\n",
        "    meas.measure([3, 2, 1, 0], [0, 1, 2, 3])  # 4-qubit measurement\n",
        "    job = backend.run(meas, shots=1024)\n",
        "    result = job.result()\n",
        "    return result.get_counts()\n",
        "\n",
        "\n",
        "def extract_features_from_image(image_patches, circuit, params, backend):\n",
        "    input_params = list(circuit.parameters)[:4]\n",
        "    weight_params = list(circuit.parameters)[4:]\n",
        "    features = []\n",
        "\n",
        "    for patch in image_patches:\n",
        "        bindings = {input_params[i]: float(patch[i]) for i in range(4)}\n",
        "        for i, param in enumerate(weight_params):\n",
        "            bindings[param] = float(params[i])\n",
        "\n",
        "        bound = circuit.assign_parameters(bindings)\n",
        "        meas_circuit = QuantumCircuit(4, 4)\n",
        "        meas_circuit.compose(bound, inplace=True)\n",
        "        meas_circuit.measure([3, 2, 1, 0], [0, 1, 2, 3])  # 4-qubit measurement\n",
        "\n",
        "        job = backend.run(meas_circuit, shots=1024)\n",
        "        result = job.result()\n",
        "        counts = result.get_counts()\n",
        "\n",
        "        probs = np.zeros(16)\n",
        "        for outcome, count in counts.items():\n",
        "            idx = int(outcome, 2)\n",
        "            probs[idx] = count / 1024\n",
        "\n",
        "        features.append(probs[:15])  # Only keep first 15 for classification\n",
        "\n",
        "    return np.array(features).flatten()\n",
        "\n",
        "\n",
        "\n",
        "def extract_all_features(X, circuit, params, backend):\n",
        "    # X contains a list of images, where each image is a list of patches.\n",
        "    all_features = []\n",
        "    for image_patches in X:\n",
        "         # extract_features_from_image already handles all patches for a single image\n",
        "        image_features = extract_features_from_image(image_patches, circuit, params, backend)\n",
        "        all_features.append(image_features)\n",
        "    return all_features\n",
        "\n",
        "\n",
        "def train_classifier(X_features, y_labels):\n",
        "    X_features_reshaped = np.array(X_features) # This should create a (num_images, num_patches) array\n",
        "\n",
        "    # Changed from LogisticRegression to SVC (Support Vector Classifier)\n",
        "    # Using RBF kernel which often works well for image classification\n",
        "    clf = SVC(kernel='rbf', probability=True, C=1.0, gamma='scale')\n",
        "    clf.fit(X_features_reshaped, y_labels)\n",
        "\n",
        "    # Verify the classifier is trained for the correct number of classes\n",
        "    n_classes = len(np.unique(y_labels))\n",
        "    print(f\"SVM Classifier trained for {n_classes} classes\")\n",
        "\n",
        "    return clf\n",
        "\n",
        "def cost_function(params, circuit, input_params, weight_params, x_batch, y_batch, backend):\n",
        "    cost = 0\n",
        "    epsilon = 1e-9\n",
        "    for i in range(len(x_batch)):\n",
        "        image_patches = x_batch[i]\n",
        "        true_class = y_batch[i]\n",
        "        patch_cost = 0\n",
        "        for patch in image_patches:\n",
        "            param_dict = {input_params[j]: float(patch[j]) for j in range(4)}\n",
        "            for j, param in enumerate(weight_params):\n",
        "                param_dict[param] = float(params[j])\n",
        "\n",
        "            counts = execute_circuit(circuit, param_dict, backend)\n",
        "            probs = np.zeros(16)\n",
        "            for outcome, count in counts.items():\n",
        "                idx = int(outcome, 2)\n",
        "                probs[idx] = count / 1024\n",
        "\n",
        "            patch_cost += -np.log(probs[true_class] + epsilon)\n",
        "        cost += patch_cost / len(image_patches)\n",
        "\n",
        "    final_cost = cost / len(x_batch)\n",
        "\n",
        "    # Record cost for plotting\n",
        "    cost_history.append(final_cost)\n",
        "\n",
        "    return final_cost\n",
        "\n",
        "\n",
        "def train_qcnn(circuit, X_train, y_train, backend, maxiter=100):\n",
        "    all_params = list(circuit.parameters)\n",
        "    if len(all_params) < 5:\n",
        "        raise ValueError(\"Circuit must have at least 4 input parameters and 1 weight parameter.\")\n",
        "    input_params = all_params[:4]\n",
        "    weight_params = all_params[4:]\n",
        "    initial_params = np.random.rand(len(weight_params)) * 2 * np.pi - np.pi\n",
        "    objective = lambda p: cost_function(p, circuit, input_params, weight_params, X_train, y_train, backend)\n",
        "    result = minimize(objective, initial_params, method='COBYLA', options={'maxiter': maxiter})\n",
        "    return result.x\n",
        "\n",
        "\n",
        "def ensemble_predict(X_test, circuits, param_list, classifiers, backend):\n",
        "    all_preds = []\n",
        "    for circuit, params, clf in zip(circuits, param_list, classifiers):\n",
        "        # extract_all_features returns a list of feature lists (one per image)\n",
        "        features = extract_all_features(X_test, circuit, params, backend)\n",
        "        # Convert features to a NumPy array for the classifier\n",
        "        features_array = np.array(features)\n",
        "        preds = clf.predict(features_array)\n",
        "        all_preds.append(preds)\n",
        "\n",
        "    final_preds = []\n",
        "    for i in range(len(X_test)):\n",
        "        votes = [model_preds[i] for model_preds in all_preds]\n",
        "\n",
        "        # Simple fix: convert to a list and use the most common value\n",
        "        votes_list = list(votes)\n",
        "        # Count occurrences of each value\n",
        "        from collections import Counter\n",
        "        most_common = Counter(votes_list).most_common(1)[0][0]\n",
        "        final_preds.append(most_common)\n",
        "\n",
        "    return final_preds\n",
        "\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred) * 100)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "def main():\n",
        "    print(\"Starting 1-Qubit QCNN Ensemble for 5-Class Classification\")\n",
        "    X_train, y_train, X_test, y_test = prepare_dataset()\n",
        "\n",
        "    # Check the shapes of X_train and y_train\n",
        "    print(f\"Shape of X_train: {X_train.shape}\")\n",
        "    print(f\"Shape of y_train: {y_train.shape}\")\n",
        "\n",
        "    backend = Aer.get_backend('qasm_simulator')\n",
        "\n",
        "    circuit1 = create_qcnn_circuit_1()\n",
        "    circuit2 = create_qcnn_circuit_2()\n",
        "    circuit3 = create_qcnn_circuit_3()\n",
        "\n",
        "\n",
        "    print(\"Training QCNN 1...\")\n",
        "    params1 = train_qcnn(circuit1, X_train, y_train, backend)\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(cost_history, label='QCNN 1 Cost')\n",
        "    plt.xlabel('Iteration')\n",
        "    plt.ylabel('Cost')\n",
        "    plt.title('Cost vs Iteration for QCNN 1')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    cost_history.clear()\n",
        "    print(\"Training QCNN 2...\")\n",
        "    params2 = train_qcnn(circuit2, X_train, y_train, backend)\n",
        "    print(\"Training QCNN 3...\")\n",
        "    params3 = train_qcnn(circuit3, X_train, y_train, backend)\n",
        "\n",
        "    print(\"Extracting features...\")\n",
        "    feat1 = extract_all_features(X_train, circuit1, params1, backend)\n",
        "    feat2 = extract_all_features(X_train, circuit2, params2, backend)\n",
        "    feat3 = extract_all_features(X_train, circuit3, params3, backend)\n",
        "\n",
        "    print(\"Training classifiers...\")\n",
        "    clf1 = train_classifier(feat1, y_train)\n",
        "    clf2 = train_classifier(feat2, y_train)\n",
        "    clf3 = train_classifier(feat3, y_train)\n",
        "\n",
        "    try:\n",
        "        with open('qcnn_ensemble_models.pkl', 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'params1': params1,\n",
        "                'params2': params2,\n",
        "                'params3': params3,\n",
        "                'clf1': clf1,\n",
        "                'clf2': clf2,\n",
        "                'clf3': clf3\n",
        "            }, f)\n",
        "        print(\"Trained models and parameters saved successfully to 'qcnn_ensemble_models.pkl'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving models: {e}\")\n",
        "\n",
        "    print(\"Performing ensemble prediction...\")\n",
        "    final_preds = ensemble_predict(X_test, [circuit1, circuit2, circuit3], [params1, params2, params3], [clf1, clf2, clf3], backend)\n",
        "\n",
        "    print(\"Evaluating results...\")\n",
        "    evaluate(y_test, final_preds)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import qiskit\n",
        "    print(f\"Qiskit version: {qiskit.__version__}\")\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i662noYKGX4J"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}